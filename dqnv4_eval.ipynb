{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b197691-b458-4cbf-943f-14c353d9da30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading NQ_1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "250000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "from MultiTimeframeCandleManager import MultiTimeframeCandleManager\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from save_and_load import *\n",
    "from Candle import Candle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "candles = obj_load(\"NQ_1\")[600000:]\n",
    "len(candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a46f09d-bcd5-4f57-a637-d75e36e4bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_actions = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "390662b5-22d2-4aa9-a457-d598fdb81fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 79)]         0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 60, 79)       0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 60, 83)       0           ['input_3[0][0]',                \n",
      "                                                                  'lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 60, 256)      21504       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        multiple             0           ['dense[0][0]',                  \n",
      "                                                                  'dense_1[0][0]',                \n",
      "                                                                  'dense_2[0][0]',                \n",
      "                                                                  'dense_3[0][0]',                \n",
      "                                                                  'dense_4[0][0]',                \n",
      "                                                                  'dense_5[0][0]',                \n",
      "                                                                  'dense_6[0][0]',                \n",
      "                                                                  'dense_7[0][0]',                \n",
      "                                                                  'dense_8[0][0]',                \n",
      "                                                                  'dense_9[0][0]',                \n",
      "                                                                  'dense_10[0][0]',               \n",
      "                                                                  'dense_11[0][0]',               \n",
      "                                                                  'dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 60, 256)      65792       ['leaky_re_lu[6][0]']            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 60, 83)       0           ['input_2[0][0]',                \n",
      "                                                                  'lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 60, 256)      65792       ['leaky_re_lu[7][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 60, 256)      21504       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 60, 256)      65792       ['leaky_re_lu[3][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 60, 83)       0           ['input_1[0][0]',                \n",
      "                                                                  'lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 60, 256)      65792       ['leaky_re_lu[4][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 60, 256)      21504       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 60, 256)      65792       ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 60, 256)      65792       ['leaky_re_lu[1][0]']            \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 8)         11520       ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 240)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 240)          0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 240)          0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 8)            0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " gru_2 (GRU)                    (None, 128)          148224      ['leaky_re_lu[8][0]']            \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, 128)          148224      ['leaky_re_lu[5][0]']            \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, 128)          148224      ['leaky_re_lu[2][0]']            \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 1194)         0           ['flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]',              \n",
      "                                                                  'flatten_3[0][0]',              \n",
      "                                                                  'input_4[0][0]',                \n",
      "                                                                  'flatten[0][0]',                \n",
      "                                                                  'input_5[0][0]',                \n",
      "                                                                  'gru_2[0][0]',                  \n",
      "                                                                  'gru_1[0][0]',                  \n",
      "                                                                  'gru[0][0]']                    \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 8192)         9789440     ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 8192)         67117056    ['leaky_re_lu[9][0]']            \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 8192)         67117056    ['leaky_re_lu[10][0]']           \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 8192)         67117056    ['leaky_re_lu[11][0]']           \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 1)            8193        ['leaky_re_lu[12][0]']           \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 3)            24579       ['leaky_re_lu[12][0]']           \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 3)            0           ['dense_13[0][0]',               \n",
      "                                                                  'dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 3)            0           ['lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 212,088,836\n",
      "Trainable params: 212,088,836\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lrelu = tf.keras.layers.LeakyReLU(0.05)\n",
    "\n",
    "\n",
    "chart_m15 = tf.keras.layers.Input(shape = (60,4))\n",
    "chart_m5 = tf.keras.layers.Input(shape = (60,4))\n",
    "chart_m1 = tf.keras.layers.Input(shape = (60,4))\n",
    "\n",
    "pdas = tf.keras.layers.Input(shape = (19+12*5,))\n",
    "\n",
    "current_position = tf.keras.layers.Input(shape = (3,))\n",
    "\n",
    "minutes = tf.keras.layers.Input(shape = (1,))\n",
    "minutes_embed = tf.keras.layers.Embedding(input_dim=60*24, output_dim=8)(minutes)\n",
    "minutes_embed_flat = tf.keras.layers.Flatten()(minutes_embed)\n",
    "\n",
    "f15 = tf.keras.layers.Flatten()(chart_m15)\n",
    "f5 = tf.keras.layers.Flatten()(chart_m5)\n",
    "f1 = tf.keras.layers.Flatten()(chart_m1)\n",
    "\n",
    "pdas_repeated = tf.keras.layers.Lambda(\n",
    "lambda inputs: tf.repeat(tf.expand_dims(inputs, axis = 1), repeats=60, axis=1)\n",
    ")(pdas)\n",
    "\n",
    "concatenated_m15_at = tf.keras.layers.Concatenate(axis=-1)([chart_m15, pdas_repeated])\n",
    "m15_at = tf.keras.layers.Dense(256)(concatenated_m15_at)\n",
    "m15_at = lrelu(m15_at)\n",
    "m15_at = tf.keras.layers.Dense(256)(m15_at)\n",
    "m15_at = lrelu(m15_at)\n",
    "m15_at = tf.keras.layers.Dense(256)(m15_at)\n",
    "m15_at = lrelu(m15_at)\n",
    "m15_rnn = tf.keras.layers.GRU(128)(m15_at)\n",
    "\n",
    "concatenated_m5_at = tf.keras.layers.Concatenate(axis=-1)([chart_m5, pdas_repeated])\n",
    "m5_at = tf.keras.layers.Dense(256)(concatenated_m5_at)\n",
    "m5_at = lrelu(m5_at)\n",
    "m5_at = tf.keras.layers.Dense(256)(m5_at)\n",
    "m5_at = lrelu(m5_at)\n",
    "m5_at = tf.keras.layers.Dense(256)(m5_at)\n",
    "m5_at = lrelu(m5_at)\n",
    "m5_rnn = tf.keras.layers.GRU(128)(m5_at)\n",
    "\n",
    "concatenated_m1_at = tf.keras.layers.Concatenate(axis=-1)([chart_m1, pdas_repeated])\n",
    "m1_at = tf.keras.layers.Dense(256)(concatenated_m1_at)\n",
    "m1_at = lrelu(m1_at)\n",
    "m1_at = tf.keras.layers.Dense(256)(m1_at)\n",
    "m1_at = lrelu(m1_at)\n",
    "m1_at = tf.keras.layers.Dense(256)(m1_at)\n",
    "m1_at = lrelu(m1_at)\n",
    "m1_rnn = tf.keras.layers.GRU(128)(m1_at)\n",
    "\n",
    "#c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, scaled_open_profit])\n",
    "c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, m1_rnn, m5_rnn, m15_rnn])\n",
    "\n",
    "d = tf.keras.layers.Dense(1024*8)(c)\n",
    "d = lrelu(d)\n",
    "d = tf.keras.layers.Dense(1024*8)(d)\n",
    "d = lrelu(d)\n",
    "d = tf.keras.layers.Dense(1024*8)(d)\n",
    "d = lrelu(d)\n",
    "d = tf.keras.layers.Dense(1024*8)(d)\n",
    "d = lrelu(d)\n",
    "\n",
    "\n",
    "value = tf.keras.layers.Dense(1, activation=\"linear\")(d)\n",
    "advantage = tf.keras.layers.Dense(num_actions, activation=\"linear\")(d)\n",
    "\n",
    "q_values = tf.keras.layers.Lambda(\n",
    "lambda inputs: inputs[0] + (inputs[1] - tf.reduce_mean(inputs[1], axis=1, keepdims=True))\n",
    ")([value, advantage])\n",
    "\n",
    "outputs = tf.keras.layers.Activation('linear', dtype='float32')(q_values)\n",
    "\n",
    "model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = outputs)\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f0d295f-6269-46ed-b746-07b90f99c47e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer count mismatch when loading weights from file. Model expected 19 layers, found 0 saved layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel.weights.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\hft_dqn\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\Desktop\\hft_dqn\\.venv\\lib\\site-packages\\keras\\saving\\hdf5_format.py:817\u001b[0m, in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, model)\u001b[0m\n\u001b[0;32m    815\u001b[0m layer_names \u001b[38;5;241m=\u001b[39m filtered_layer_names\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layer_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(filtered_layers):\n\u001b[1;32m--> 817\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    818\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer count mismatch when loading weights from file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    819\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(filtered_layers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m layers, found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(layer_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m saved layers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    821\u001b[0m     )\n\u001b[0;32m    823\u001b[0m \u001b[38;5;66;03m# We batch weight value assignments in a single backend call\u001b[39;00m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;66;03m# which provides a speedup in TensorFlow.\u001b[39;00m\n\u001b[0;32m    825\u001b[0m weight_value_tuples \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: Layer count mismatch when loading weights from file. Model expected 19 layers, found 0 saved layers."
     ]
    }
   ],
   "source": [
    "model.load_weights(\"model.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f069d41-781f-439b-b12a-59bd3e1f29e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def relative (value, center, r):\n",
    "        return (value - center) / r\n",
    "\n",
    "def ret_to_scaled_inputs(ret):\n",
    "\n",
    "    midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "\n",
    "\n",
    "    center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
    "    r = max(0.0001,(midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
    "\n",
    "    pda_rel = []\n",
    "    pda_rel.append(relative(midnight_open, center, r))\n",
    "    for pda in pdas[0:18]:\n",
    "        pda_rel.append(relative(pda, center, r))\n",
    "    for index in range(18,18+5*12):\n",
    "        ## highs lows are like this [h, h_taken, l, l_taken]\n",
    "        ## the bools should not be scaled\n",
    "        if (index - 18) % 2 == 0:\n",
    "            pda_rel.append(relative(pdas[index], center, r))\n",
    "        else:\n",
    "            pda_rel.append(pdas[index])\n",
    "\n",
    "    pda_np = np.array(pda_rel)\n",
    "\n",
    "    current_minutes = current_time.hour * 60 + current_time.minute\n",
    "\n",
    "    charts_array = []\n",
    "    for candlesticks in charts:\n",
    "        charts_array.append([])\n",
    "        for candle in candlesticks:\n",
    "            o = relative(candle.o, center, r)\n",
    "            h = relative(candle.h, center, r)\n",
    "            l = relative(candle.l, center, r)\n",
    "            c = relative(candle.c, center, r)\n",
    "            charts_array[-1].append([o,h,l,c])\n",
    "\n",
    "    m15_np = np.array(charts_array[0])\n",
    "    m5_np = np.array(charts_array[1])\n",
    "    m1_np = np.array(charts_array[2])\n",
    "\n",
    "    return [m15_np, m5_np, m1_np, pda_np, current_minutes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd5699d-6072-4afe-8e58-f529f228ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Order:\n",
    "    def __init__(self, limit, stop, tp, direction):\n",
    "        self.entry = limit\n",
    "        self.tp = tp\n",
    "        self.sl = stop\n",
    "        self.direction = direction\n",
    "\n",
    "class Position:\n",
    "    def __init__(self, entry, stop, tp, direction):\n",
    "        self.entry = entry\n",
    "        self.tp = tp\n",
    "        self.sl = stop\n",
    "        self.direction = direction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1b7326-2b0f-49e6-86b1-815fd4ef4c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MultiTimeframeCandleManager()\n",
    "\n",
    "current_position = Position(0,0,0,0)\n",
    "current_order = None\n",
    "\n",
    "equity = 0\n",
    "equity_L = [0]\n",
    "\n",
    "outputs = []\n",
    "\n",
    "cmm = 1\n",
    "\n",
    "for index in tqdm(range(10000)):\n",
    "\n",
    "    \n",
    "        ret = m.push_m1_candle(candles[index])\n",
    "        midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "        center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
    "        r = max(0.0001, (midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
    "\n",
    "\n",
    "\n",
    "        current_candle_m1 = charts[2][-1]\n",
    "        #### check tp before filling order so that the same m1 candle will not trigger tp - it is not sure if the candle hit first limit and later tp or reve3rse        \n",
    "        if current_position.direction == 1:\n",
    "            if current_candle_m1.h >= current_position.tp:\n",
    "                pnl = (current_position.tp - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "        if current_position.direction == -1:\n",
    "            if current_candle_m1.l <= current_position.tp:\n",
    "                pnl = (current_position.tp - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "                \n",
    "        #### check order\n",
    "        if current_order != None:\n",
    "            if  current_order.direction == 1:\n",
    "                if current_candle_m1.l < current_order.entry:\n",
    "                    current_position = Position(current_order.entry, current_order.sl, current_order.tp, current_order.direction)\n",
    "                    #print(\"fill long order:\",current_order.entry, current_order.sl, current_order.tp)\n",
    "                    equity -= cmm\n",
    "                    current_order = None\n",
    "        if current_order != None:\n",
    "            if  current_order.direction == -1:\n",
    "                if current_candle_m1.h > current_order.entry:\n",
    "                    current_position = Position(current_order.entry, current_order.sl, current_order.tp, current_order.direction)\n",
    "                    #print(\"fill short order:\",current_order.entry, current_order.sl, current_order.tp)\n",
    "                    equity -= cmm\n",
    "                    current_order = None\n",
    "\n",
    "        #### check sl\n",
    "        if current_position.direction == 1:\n",
    "            if current_candle_m1.l <= current_position.sl:\n",
    "                pnl = (current_position.sl - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "        if current_position.direction == -1:\n",
    "            if current_candle_m1.h >= current_position.sl:\n",
    "                pnl = (current_position.sl - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "        if(len(m.fps) == 3 and len(m.opening_range_gaps) == 3 and len(m.asia_highs_lows) == 3 and len(m.london_highs_lows) == 3 and len(m.ny_am_highs_lows) == 3 and len(m.ny_lunch_highs_lows) == 3 and len(m.ny_pm_highs_lows) == 3):\n",
    "\n",
    "            \n",
    "            open_profit = (current_close - current_position.entry) * current_position.direction\n",
    "\n",
    "            scaled_entry_diff  =  0\n",
    "            scaled_sl_diff  =  0\n",
    "            if(current_position.direction != 0):\n",
    "                scaled_entry_diff = (current_close - current_position.entry) / r\n",
    "                scaled_sl_diff = (current_close - current_position.sl) / r\n",
    "\n",
    "            state = ret_to_scaled_inputs(ret) + [np.array([current_position.direction, scaled_entry_diff, scaled_sl_diff])]\n",
    "            m15_np, m5_np, m1_np, pda_np, current_minutes, pos_info = state\n",
    "\n",
    "            equity_L.append(equity+open_profit)\n",
    "            \n",
    "\n",
    "            output = model([\n",
    "                    tf.expand_dims(m15_np, 0),\n",
    "                    tf.expand_dims(m5_np, 0),\n",
    "                    tf.expand_dims(m1_np, 0),\n",
    "                    tf.expand_dims(pda_np, 0),\n",
    "                    tf.expand_dims(current_minutes, 0),\n",
    "                    tf.expand_dims(pos_info, 0)\n",
    "            ])\n",
    "\n",
    "            last_action = np.argmax(output)\n",
    "\n",
    "\n",
    "            last_action = np.argmax(output)\n",
    "            outputs.append(output[0])\n",
    "            \n",
    "\n",
    "            if(last_action == 2 and current_position.direction != 0):    \n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "            \n",
    "            if(last_action == 0 and current_position.direction == 1):    \n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "            if(last_action == 0 and current_position.direction == 0):\n",
    "                last_candle_low = charts[2][-2].l\n",
    "                if ( last_candle_low < current_close ):\n",
    "                    last_candle_low = None\n",
    "                    \n",
    "                pdas = m.normal_pdas ## (low, high)\n",
    "                \n",
    "                ## ignore pdas with low below close\n",
    "                pdas_filtered = []\n",
    "                for pda in pdas:\n",
    "                        if(pda[0] > current_close):\n",
    "                            pdas_filtered.append(pda)\n",
    "                ### sort\n",
    "                sorted_by_high = sorted(pdas_filtered, key = lambda x:x[1])\n",
    "                sorted_by_low = sorted(pdas_filtered, key = lambda x:x[0])\n",
    "\n",
    "                if(len(pdas_filtered) >= 3):\n",
    "                    ### sl is the high of 3 pdas\n",
    "                    sl = sorted_by_high[2][1]\n",
    "\n",
    "                    ### entry is lowest i can get or immediate rebalance\n",
    "                    entry = sorted_by_low[0][0]\n",
    "                    if(last_candle_low != None):\n",
    "                        entry = min(entry, last_candle_low)\n",
    "\n",
    "                    tp = entry  -  abs(entry-sl) * 1000\n",
    "\n",
    "                    current_order = Order(entry, sl, tp, -1)\n",
    "                    #print(\"set short order:\",entry,sl,tp)\n",
    "\n",
    "                    \n",
    "\n",
    "            if(last_action == 1 and current_position.direction == -1):    \n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "            if(last_action == 1 and current_position.direction == 0):\n",
    "                last_candle_high = charts[2][-2].h\n",
    "                if ( last_candle_high > current_close ):\n",
    "                    last_candle_high = None\n",
    "                pdas = m.normal_pdas ## (low, high)\n",
    "                \n",
    "                ## ignore pdas with low below close\n",
    "                pdas_filtered = []\n",
    "                for pda in pdas:\n",
    "                        if(pda[1] < current_close):\n",
    "                            pdas_filtered.append(pda)\n",
    "                ### sort\n",
    "                sorted_by_high = sorted(pdas_filtered, key = lambda x:x[1], reverse=True)\n",
    "                sorted_by_low = sorted(pdas_filtered, key = lambda x:x[0], reverse=True)\n",
    "\n",
    "                if(len(pdas_filtered) >= 3):\n",
    "                    ### sl is the high of 3 pdas\n",
    "                    sl = sorted_by_low[2][0]\n",
    "\n",
    "                    ### entry is lowest i can get or immediate rebalance\n",
    "                    entry = sorted_by_high[0][1]\n",
    "                    if(last_candle_high != None):\n",
    "                        entry = max(entry, last_candle_high)\n",
    "\n",
    "                    tp = entry  +  abs(entry-sl) * 1000\n",
    "\n",
    "                    current_order = Order(entry, sl, tp, 1)\n",
    "                    #print(\"set long order:\",entry,sl,tp)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de95bb89-390f-4c60-8e0b-da9382e3b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x.c for x in m.m1_candles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c729e82-3b29-43a4-be4e-927efbd34b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(equity_L[-60:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd706ba5-8f9c-4889-a382-46f25bc9653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot([x[0] for x in outputs][-60:], color=\"r\")\n",
    "#plt.plot([x[1] for x in outputs][-60:], color=\"g\")\n",
    "#plt.plot([x[2] for x in outputs][-60:], color=\"b\")\n",
    "\n",
    "plt.plot([x[1]-x[0] for x in outputs], color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5b3f0b-f6a8-4b12-9bc1-74330da8575a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b536a1d7-a655-4d08-9e9d-c8cbf420a885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a89278c-2823-4e36-8746-908718c80748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7355fab-87a0-4bf6-9558-f6c3bcc2ac5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792e7414-ae3f-447f-bdc6-9b4ef97f5d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(equity_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c09e849-898b-4636-bb36-53b91b1932da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96721f8d-ce0b-4bc8-9792-68a298f454d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceae9d4-4a97-4372-bd5a-a5f05e86466c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00173ba-8b69-4d06-9e7b-02115e3d666d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e63d7-5a3a-4d8e-879c-7b8ed34bcf99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704c2bc2-bed6-43af-8b2a-d0363ae47b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
