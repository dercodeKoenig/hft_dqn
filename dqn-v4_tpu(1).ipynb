{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dercodeKoenig/hft_dqn/blob/main/dqn-v4_tpu(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O1TcBIpbReKM"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iw9L3PcRHypQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b21e12-3a71-4343-f3d7-cb52a5f936e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hft_dqn'...\n",
            "remote: Enumerating objects: 247, done.\u001b[K\n",
            "remote: Counting objects: 100% (167/167), done.\u001b[K\n",
            "remote: Compressing objects: 100% (134/134), done.\u001b[K\n",
            "remote: Total 247 (delta 98), reused 83 (delta 32), pack-reused 80 (from 1)\u001b[K\n",
            "Receiving objects: 100% (247/247), 62.46 MiB | 31.74 MiB/s, done.\n",
            "Resolving deltas: 100% (131/131), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dercodeKoenig/hft_dqn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_GOXl2HpH0M4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab845936-f71c-42ed-aa2f-22e7ec5408b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hft_dqn\n"
          ]
        }
      ],
      "source": [
        "%cd hft_dqn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "srO8OLjtH1Zq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d168de5-4e46-4601-b8cb-4946ac519a97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.10)\n",
            "Dataset URL: https://www.kaggle.com/datasets/bpwqsdd/us-futures-1-minute-candlesticks\n",
            "License(s): unknown\n",
            "Downloading us-futures-1-minute-candlesticks.zip to /content/hft_dqn\n",
            " 91% 82.0M/89.7M [00:00<00:00, 221MB/s]\n",
            "100% 89.7M/89.7M [00:00<00:00, 210MB/s]\n",
            "Archive:  us-futures-1-minute-candlesticks.zip\n",
            "  inflating: ES_2                    \n",
            "  inflating: EURUSD_2                \n",
            "  inflating: GBPUSD_2                \n",
            "  inflating: NQ_2                    \n",
            "  inflating: YM_2                    \n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "!kaggle datasets download bpwqsdd/us-futures-1-minute-candlesticks\n",
        "!unzip us-futures-1-minute-candlesticks.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1b197691-b458-4cbf-943f-14c353d9da30"
      },
      "outputs": [],
      "source": [
        "\n",
        "from MultiTimeframeCandleManager import MultiTimeframeCandleManager\n",
        "from datetime import datetime, timedelta\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "import copy\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from save_and_load import *\n",
        "from Candle import Candle\n",
        "import matplotlib.pyplot as plt\n",
        "#from tensorflow.keras import mixed_precision\n",
        "#mixed_precision.set_global_policy('mixed_float16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eu8rj9GMIGCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8320064-01dc-4d13-c1ba-6495c55eabf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use tpu strategy\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.distribute.tpu_strategy.TPUStrategyV2 at 0x7e10b545a950>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "try:\n",
        "    cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"local\")\n",
        "    tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "    strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "    print(\"use tpu strategy\")\n",
        "except:\n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1a46f09d-bcd5-4f57-a637-d75e36e4bfe0"
      },
      "outputs": [],
      "source": [
        "gamma = 0.995\n",
        "memory_len = 2000000\n",
        "sarts_memory = deque(maxlen = memory_len)\n",
        "batch_size = 64\n",
        "e = 2\n",
        "slm = 1.5\n",
        "\n",
        "min_memory_size = batch_size * 20\n",
        "\n",
        "num_actions = 3\n",
        "\n",
        "path = \"./\"\n",
        "\n",
        "ep_len = 1000\n",
        "\n",
        "m1 = np.eye(num_actions, dtype=\"float32\")\n",
        "num_model_inputs = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "390662b5-22d2-4aa9-a457-d598fdb81fe2",
        "outputId": "ff1a1f1e-3ec7-44e3-a57e-582f2d520ecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_9             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m94\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_8             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m94\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m98\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m12,672\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                           │                        │                │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                           │                        │                │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                           │                        │                │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                           │                        │                │ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                           │                        │                │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                           │                        │                │ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                           │                        │                │ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                           │                        │                │ dense_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_7             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m16,512\u001b[0m │ leaky_re_lu_1[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m98\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │          \u001b[38;5;34m4,128\u001b[0m │ leaky_re_lu_1[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m12,672\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m16,512\u001b[0m │ leaky_re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_11            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │          \u001b[38;5;34m4,128\u001b[0m │ leaky_re_lu_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_6             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │         \u001b[38;5;34m11,520\u001b[0m │ input_layer_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_10            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │          \u001b[38;5;34m6,336\u001b[0m │ leaky_re_lu_1[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │          \u001b[38;5;34m6,336\u001b[0m │ leaky_re_lu_1[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m889\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ flatten_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ flatten_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ flatten_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ input_layer_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ flatten_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ input_layer_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                           │                        │                │ gru_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
              "│                           │                        │                │ gru_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │        \u001b[38;5;34m911,360\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m1,049,600\u001b[0m │ leaky_re_lu_1[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m1,049,600\u001b[0m │ leaky_re_lu_1[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │          \u001b[38;5;34m1,025\u001b[0m │ leaky_re_lu_1[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │          \u001b[38;5;34m3,075\u001b[0m │ leaky_re_lu_1[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ dense_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                           │                        │                │ dense_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ lambda_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_9             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_8             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,672</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                           │                        │                │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                           │                        │                │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                           │                        │                │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                           │                        │                │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                           │                        │                │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                           │                        │                │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                           │                        │                │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                           │                        │                │ dense_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_7             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ leaky_re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ leaky_re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,672</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ leaky_re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_11            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ leaky_re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_6             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">11,520</span> │ input_layer_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_10            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,336</span> │ leaky_re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,336</span> │ leaky_re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">889</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ flatten_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ flatten_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ flatten_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                           │                        │                │ gru_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
              "│                           │                        │                │ gru_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">911,360</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │ leaky_re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │ leaky_re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,025</span> │ leaky_re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,075</span> │ leaky_re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                           │                        │                │ dense_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,105,476\u001b[0m (11.85 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,105,476</span> (11.85 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,105,476\u001b[0m (11.85 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,105,476</span> (11.85 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "\n",
        "  lrelu = tf.keras.layers.LeakyReLU(0.05)\n",
        "\n",
        "\n",
        "  chart_m15 = tf.keras.layers.Input(shape = (60,4))\n",
        "  chart_m5 = tf.keras.layers.Input(shape = (60,4))\n",
        "  chart_m1 = tf.keras.layers.Input(shape = (60,4))\n",
        "\n",
        "  pdas = tf.keras.layers.Input(shape = (3*3+3*3+1+12*5+5*3,))\n",
        "\n",
        "  current_position = tf.keras.layers.Input(shape = (3,))\n",
        "\n",
        "  minutes = tf.keras.layers.Input(shape = (1,))\n",
        "  minutes_embed = tf.keras.layers.Embedding(input_dim=60*24, output_dim=8)(minutes)\n",
        "  minutes_embed_flat = tf.keras.layers.Flatten()(minutes_embed)\n",
        "\n",
        "  f15 = tf.keras.layers.Flatten()(chart_m15)\n",
        "  f5 = tf.keras.layers.Flatten()(chart_m5)\n",
        "  f1 = tf.keras.layers.Flatten()(chart_m1)\n",
        "\n",
        "  pdas_repeated = tf.keras.layers.Lambda(\n",
        "  lambda inputs: tf.repeat(tf.expand_dims(inputs, axis = 1), repeats=60, axis=1)\n",
        "  )(pdas)\n",
        "\n",
        "  concatenated_m5_at = tf.keras.layers.Concatenate(axis=-1)([chart_m5, pdas_repeated])\n",
        "  m5_at = tf.keras.layers.Dense(128)(concatenated_m5_at)\n",
        "  m5_at = lrelu(m5_at)\n",
        "  m5_at = tf.keras.layers.Dense(128)(m5_at)\n",
        "  m5_at = lrelu(m5_at)\n",
        "  m5_at = tf.keras.layers.Dense(32)(m5_at)\n",
        "  m5_at = lrelu(m5_at)\n",
        "  m5_rnn = tf.keras.layers.GRU(32)(m5_at)\n",
        "\n",
        "  concatenated_m1_at = tf.keras.layers.Concatenate(axis=-1)([chart_m1, pdas_repeated])\n",
        "  m1_at = tf.keras.layers.Dense(128)(concatenated_m1_at)\n",
        "  m1_at = lrelu(m1_at)\n",
        "  m1_at = tf.keras.layers.Dense(128)(m1_at)\n",
        "  m1_at = lrelu(m1_at)\n",
        "  m1_at = tf.keras.layers.Dense(32)(m1_at)\n",
        "  m1_at = lrelu(m1_at)\n",
        "  m1_rnn = tf.keras.layers.GRU(32)(m1_at)\n",
        "\n",
        "  #c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, scaled_open_profit])\n",
        "  c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, m1_rnn, m5_rnn])\n",
        "\n",
        "  d = tf.keras.layers.Dense(1024*1)(c)\n",
        "  d = lrelu(d)\n",
        "  d = tf.keras.layers.Dense(1024*1)(d)\n",
        "  d = lrelu(d)\n",
        "  d = tf.keras.layers.Dense(1024*1)(d)\n",
        "  d = lrelu(d)\n",
        "\n",
        "\n",
        "  value = tf.keras.layers.Dense(1, activation=\"linear\")(d)\n",
        "  advantage = tf.keras.layers.Dense(num_actions, activation=\"linear\")(d)\n",
        "\n",
        "  q_values = tf.keras.layers.Lambda(\n",
        "  lambda inputs: inputs[0] + (inputs[1] - tf.reduce_mean(inputs[1], axis=1, keepdims=True))\n",
        "  )([value, advantage])\n",
        "\n",
        "  outputs = tf.keras.layers.Activation('linear', dtype='float32')(q_values)\n",
        "\n",
        "  model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = outputs)\n",
        "  target_model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = outputs)\n",
        "\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate = 0.000001)\n",
        "\n",
        "\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8f069d41-781f-439b-b12a-59bd3e1f29e7"
      },
      "outputs": [],
      "source": [
        "\n",
        "def relative (value, center, r):\n",
        "        return (value - center) / r\n",
        "\n",
        "def ret_to_scaled_inputs(ret):\n",
        "\n",
        "    midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
        "\n",
        "\n",
        "    center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
        "    r = max(0.0001,(midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
        "\n",
        "    pda_rel = []\n",
        "    pda_rel.append(relative(midnight_open, center, r))\n",
        "    for pda in pdas[0:9+9+15]:\n",
        "        pda_rel.append(relative(pda, center, r))\n",
        "    for index in range(9+9+15,9+9+15+5*12):\n",
        "        ## highs lows are like this [h, h_taken, l, l_taken]\n",
        "        ## the bools should not be scaled\n",
        "        if (index - 9+9+15) % 2 == 0:\n",
        "            pda_rel.append(relative(pdas[index], center, r))\n",
        "        else:\n",
        "            pda_rel.append(pdas[index])\n",
        "\n",
        "    pda_np = np.array(pda_rel)\n",
        "\n",
        "    current_minutes = current_time.hour * 60 + current_time.minute\n",
        "\n",
        "    charts_array = []\n",
        "    for candlesticks in charts:\n",
        "        charts_array.append([])\n",
        "        for candle in candlesticks:\n",
        "            o = relative(candle.o, center, r)\n",
        "            h = relative(candle.h, center, r)\n",
        "            l = relative(candle.l, center, r)\n",
        "            c = relative(candle.c, center, r)\n",
        "            charts_array[-1].append([o,h,l,c])\n",
        "\n",
        "    m15_np = np.array(charts_array[0])\n",
        "    m5_np = np.array(charts_array[1])\n",
        "    m1_np = np.array(charts_array[2])\n",
        "\n",
        "    return [m15_np, m5_np, m1_np, pda_np, current_minutes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3cd5699d-6072-4afe-8e58-f529f228ad0b"
      },
      "outputs": [],
      "source": [
        "class Order:\n",
        "    def __init__(self, limit, stop, tp, direction):\n",
        "        self.entry = limit\n",
        "        self.tp = tp\n",
        "        self.sl = stop\n",
        "        self.direction = direction\n",
        "\n",
        "class Position:\n",
        "    def __init__(self, entry, stop, tp, direction):\n",
        "        self.entry = entry\n",
        "        self.tp = tp\n",
        "        self.sl = stop\n",
        "        self.direction = direction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0c1b7326-2b0f-49e6-86b1-815fd4ef4c87",
        "outputId": "7f6cdced-9835-4ecd-e0f2-3dc949f78204",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading EURUSD_2\n",
            "env reset, using data: ('EURUSD_2', 0.00015)\n"
          ]
        }
      ],
      "source": [
        "equity = 0\n",
        "equity_L = [0]\n",
        "\n",
        "inputs = [\n",
        "    (\"NQ_2\", 1),\n",
        "    (\"ES_2\", 0.75),\n",
        "    (\"YM_2\", 1.5),\n",
        "    (\"EURUSD_2\", 0.00015),\n",
        "    (\"GBPUSD_2\", 0.00015)\n",
        "]\n",
        "\n",
        "candles = []\n",
        "cmm = 0\n",
        "def reset():\n",
        "    global index, last_state, last_action, current_position, current_order, equity, m, candles, cmm\n",
        "\n",
        "    ob = random.choice(inputs)\n",
        "    candles = obj_load(ob[0])\n",
        "    cmm = ob[1]\n",
        "\n",
        "    m = MultiTimeframeCandleManager()\n",
        "\n",
        "    current_position = Position(0,0,0,0)\n",
        "    current_order = None\n",
        "\n",
        "    last_state = None\n",
        "    last_action = 0\n",
        "\n",
        "    index = 0\n",
        "\n",
        "    print(\"env reset, using data:\", ob)\n",
        "\n",
        "\n",
        "@tf.function()\n",
        "def inference_step(m15_np, m5_np, m1_np, pda_np, current_minutes, pos_info):\n",
        "    return model([\n",
        "        m15_np,\n",
        "        m5_np,\n",
        "        m1_np,\n",
        "        pda_np,\n",
        "        current_minutes,\n",
        "        pos_info,\n",
        "    ])\n",
        "\n",
        "\n",
        "def step():\n",
        "\n",
        "    global index, last_state, last_action, current_position, current_order, equity, m\n",
        "\n",
        "\n",
        "    sarts = None\n",
        "    while  sarts == None:\n",
        "\n",
        "        ret = m.push_m1_candle(candles[index])\n",
        "        midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
        "        center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
        "        r = max(0.0001, (midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
        "\n",
        "\n",
        "\n",
        "        current_candle_m1 = charts[2][-1]\n",
        "        #### check tp before filling order so that the same m1 candle will not trigger tp - it is not sure if the candle hit first limit and later tp or reve3rse\n",
        "        if current_position.direction == 1:\n",
        "            if current_candle_m1.h >= current_position.tp:\n",
        "                pnl = (current_position.tp - current_position.entry) * current_position.direction\n",
        "                equity += pnl\n",
        "                current_position = Position(0,0,0,0)\n",
        "        if current_position.direction == -1:\n",
        "            if current_candle_m1.l <= current_position.tp:\n",
        "                pnl = (current_position.tp - current_position.entry) * current_position.direction\n",
        "                equity += pnl\n",
        "                current_position = Position(0,0,0,0)\n",
        "\n",
        "        #### check order\n",
        "        if current_order != None:\n",
        "            if  current_order.direction == 1:\n",
        "                if current_candle_m1.l < current_order.entry:\n",
        "                    current_position = Position(current_order.entry, current_order.sl, current_order.tp, current_order.direction)\n",
        "                    #print(\"fill long order:\",current_order.entry, current_order.sl, current_order.tp)\n",
        "                    equity -= cmm\n",
        "                    current_order = None\n",
        "        if current_order != None:\n",
        "            if  current_order.direction == -1:\n",
        "                if current_candle_m1.h > current_order.entry:\n",
        "                    current_position = Position(current_order.entry, current_order.sl, current_order.tp, current_order.direction)\n",
        "                    #print(\"fill short order:\",current_order.entry, current_order.sl, current_order.tp)\n",
        "                    equity -= cmm\n",
        "                    current_order = None\n",
        "\n",
        "        #### check sl\n",
        "        if current_position.direction == 1:\n",
        "            if current_candle_m1.l <= current_position.sl:\n",
        "                pnl = (current_position.sl - current_position.entry) * current_position.direction\n",
        "                equity += pnl\n",
        "                current_position = Position(0,0,0,0)\n",
        "        if current_position.direction == -1:\n",
        "            if current_candle_m1.h >= current_position.sl:\n",
        "                pnl = (current_position.sl - current_position.entry) * current_position.direction\n",
        "                equity += pnl\n",
        "                current_position = Position(0,0,0,0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if(len(m.ndogs) == 5 and len(m.fps) == 3 and len(m.opening_range_gaps) == 3 and len(m.asia_highs_lows) == 3 and len(m.london_highs_lows) == 3 and len(m.ny_am_highs_lows) == 3 and len(m.ny_lunch_highs_lows) == 3 and len(m.ny_pm_highs_lows) == 3):\n",
        "\n",
        "\n",
        "            open_profit = (current_close - current_position.entry) * current_position.direction\n",
        "\n",
        "            scaled_entry_diff  =  0\n",
        "            scaled_sl_diff  =  0\n",
        "            if(current_position.direction != 0):\n",
        "                scaled_entry_diff = (current_close - current_position.entry) / r\n",
        "                scaled_sl_diff = (current_close - current_position.sl) / r\n",
        "\n",
        "            state = ret_to_scaled_inputs(ret) + [np.array([current_position.direction, scaled_entry_diff, scaled_sl_diff])]\n",
        "            m15_np, m5_np, m1_np, pda_np, current_minutes, pos_info = state\n",
        "\n",
        "            if(last_state != None):\n",
        "                diff = (equity+open_profit) - equity_L[-1]\n",
        "                equity_L.append(equity+open_profit)\n",
        "                reward =  (diff) / r\n",
        "                terminal = 0\n",
        "                if(index+1 == len(candles)):\n",
        "                    terminal = 1\n",
        "\n",
        "                sarts = last_state, last_action, reward, terminal, state\n",
        "\n",
        "\n",
        "            if(random.randint(0,100) > e):\n",
        "                with tf.device(\"/TPU:0\"):\n",
        "                    output = inference_step(\n",
        "                        tf.expand_dims(m15_np, 0),\n",
        "                        tf.expand_dims(m5_np, 0),\n",
        "                        tf.expand_dims(m1_np, 0),\n",
        "                        tf.expand_dims(pda_np, 0),\n",
        "                        tf.expand_dims(current_minutes, 0),\n",
        "                        tf.expand_dims(pos_info, 0)\n",
        "                    )\n",
        "\n",
        "                last_action = np.argmax(output)\n",
        "            else:\n",
        "                last_action = random.randint(0,num_actions-1)\n",
        "\n",
        "            last_state = state\n",
        "\n",
        "            current_order = None\n",
        "\n",
        "            avg_candle_range = np.mean([ i.h - i.l for i in list(charts[2])[55:60]])\n",
        "\n",
        "            if(last_action == 2 and current_position.direction != 0):\n",
        "                equity += open_profit\n",
        "                current_position = Position(0,0,0,0)\n",
        "\n",
        "            if(last_action == 0 and current_position.direction == 1):\n",
        "                equity += open_profit\n",
        "                current_position = Position(0,0,0,0)\n",
        "\n",
        "            if(last_action == 0 and current_position.direction == 0):\n",
        "                last_candle_low = charts[2][-2].l\n",
        "                if ( last_candle_low < current_close ):\n",
        "                    last_candle_low = None\n",
        "\n",
        "                pdas = m.normal_pdas ## (low, high)\n",
        "\n",
        "                ## ignore pdas with low below close\n",
        "                pdas_filtered = []\n",
        "                for pda in pdas:\n",
        "                        if(pda[0] > current_close):\n",
        "                            pdas_filtered.append(pda)\n",
        "                ### sort\n",
        "                sorted_by_high = sorted(pdas_filtered, key = lambda x:x[1])\n",
        "                sorted_by_low = sorted(pdas_filtered, key = lambda x:x[0])\n",
        "\n",
        "                if(len(pdas_filtered) > 0):\n",
        "\n",
        "                    ### entry is lowest i can get or immediate rebalance\n",
        "                    entry = sorted_by_low[0][0]\n",
        "                    if(last_candle_low != None):\n",
        "                        entry = min(entry, last_candle_low)\n",
        "\n",
        "\n",
        "                    sl = entry + avg_candle_range * slm\n",
        "                    tp = entry  -  abs(entry-sl) * 1000\n",
        "\n",
        "\n",
        "                    current_order = Order(entry, sl, tp, -1)\n",
        "                    #print(\"set short order:\",entry,sl,tp)\n",
        "\n",
        "\n",
        "\n",
        "            if(last_action == 1 and current_position.direction == -1):\n",
        "                equity += open_profit\n",
        "                current_position = Position(0,0,0,0)\n",
        "\n",
        "            if(last_action == 1 and current_position.direction == 0):\n",
        "                last_candle_high = charts[2][-2].h\n",
        "                if ( last_candle_high > current_close ):\n",
        "                    last_candle_high = None\n",
        "                pdas = m.normal_pdas ## (low, high)\n",
        "\n",
        "                ## ignore pdas with low below close\n",
        "                pdas_filtered = []\n",
        "                for pda in pdas:\n",
        "                        if(pda[1] < current_close):\n",
        "                            pdas_filtered.append(pda)\n",
        "                ### sort\n",
        "                sorted_by_high = sorted(pdas_filtered, key = lambda x:x[1], reverse=True)\n",
        "                sorted_by_low = sorted(pdas_filtered, key = lambda x:x[0], reverse=True)\n",
        "\n",
        "                if(len(pdas_filtered) > 0):\n",
        "                    ### entry is lowest i can get or immediate rebalance\n",
        "                    entry = sorted_by_high[0][1]\n",
        "                    if(last_candle_high != None):\n",
        "                        entry = max(entry, last_candle_high)\n",
        "\n",
        "                    sl = entry - avg_candle_range * slm\n",
        "                    tp = entry  +  abs(entry-sl) * 1000\n",
        "\n",
        "                    current_order = Order(entry, sl, tp, 1)\n",
        "                    #print(\"set long order:\",entry,sl,tp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        index += 1\n",
        "        if(index == len(candles)):\n",
        "            reset()\n",
        "\n",
        "    return sarts\n",
        "\n",
        "reset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmgpAWSMReK4"
      },
      "source": [
        "def plot_candles(candles):\n",
        "    for index in range(len(candles)):\n",
        "        candle = candles[index]\n",
        "        c = \"green\" if candle.c > candle.o else \"black\"\n",
        "        plt.plot([index, index], [candle.l, candle.h], linewidth=1, color = \"black\")\n",
        "        plt.plot([index, index], [candle.c, candle.o], linewidth=3, color = c)\n",
        "\n",
        "sarts = step()\n",
        "\n",
        "plot_candles(m.m1_candles)\n",
        "if(current_position.direction != 0):\n",
        "    plt.axhline(current_position.entry, color = \"g\" if current_position.direction == 1 else \"r\")\n",
        "    plt.axhline(current_position.sl, color = \"orange\")\n",
        "\n",
        "if(current_order != None):\n",
        "    plt.axhline(current_order.entry, color = \"g\" if current_order.direction == 1 else \"r\")\n",
        "    plt.axhline(current_order.sl, color = \"orange\")\n",
        "\n",
        "\n",
        "print(sarts[1], sarts[2], current_position.direction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "d92f99f8-68df-4fbd-bc4d-218a2a43f865"
      },
      "outputs": [],
      "source": [
        "@tf.function(jit_compile=True)\n",
        "def get_target_q(next_states, rewards, terminals):\n",
        "            estimated_q_values_next = target_model(next_states)\n",
        "            q_batch = tf.math.reduce_max(estimated_q_values_next, axis=1)\n",
        "            target_q_values = q_batch * gamma * (1-terminals) + rewards\n",
        "            return target_q_values\n",
        "\n",
        "@tf.function(jit_compile=True)\n",
        "def tstep(data):\n",
        "    states, masks, rewards, terminals, next_states = data\n",
        "\n",
        "    target_q_values = get_target_q(next_states, rewards, terminals)\n",
        "\n",
        "    with tf.GradientTape() as t:\n",
        "        model_return = model(states, training=True)\n",
        "        mask_return = model_return * masks\n",
        "        estimated_q_values = tf.math.reduce_sum(mask_return, axis=1)\n",
        "        #print(estimated_q_values, mask_return, model_return, masks)\n",
        "        loss_e = tf.math.square(target_q_values - estimated_q_values)\n",
        "        loss = tf.reduce_mean(loss_e)\n",
        "\n",
        "\n",
        "    gradient = t.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
        "\n",
        "    return loss, tf.reduce_mean(estimated_q_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fd706ba5-8f9c-4889-a382-46f25bc9653c"
      },
      "outputs": [],
      "source": [
        "def get_data(n):\n",
        "        r = random.randint(0, len(sarts_memory) - batch_size)\n",
        "        sarts_sample = [sarts_memory[i] for i in range(r, r + batch_size)]\n",
        "\n",
        "\n",
        "\n",
        "        states = [x[0] for x in sarts_sample]\n",
        "        actions = [x[1] for x in sarts_sample]\n",
        "        rewards = np.array([x[2] for x in sarts_sample], dtype=\"float32\")\n",
        "        terminals = np.array([x[3] for x in sarts_sample], dtype=\"float32\")\n",
        "        next_states = [x[4] for x in sarts_sample]\n",
        "\n",
        "        next_states_array = []\n",
        "        for i in range(num_model_inputs):\n",
        "            next_states_array.append(np.array([x[i] for x in next_states], dtype = \"float32\"))\n",
        "\n",
        "\n",
        "        states_array = []\n",
        "        for i in range(num_model_inputs):\n",
        "            states_array.append(np.array([x[i] for x in states], dtype = \"float32\"))\n",
        "\n",
        "\n",
        "        masks = np.array(m1[actions], dtype=\"float32\")\n",
        "\n",
        "\n",
        "        return states_array, masks, rewards, terminals, next_states_array\n",
        "\n",
        "def run():\n",
        "    sarts = step()\n",
        "    sarts_memory.append(sarts)\n",
        "\n",
        "    if(len(sarts_memory) > min_memory_size):\n",
        "\n",
        "        distributed_data = (strategy.experimental_distribute_values_from_function(get_data))\n",
        "        loss, q = strategy.reduce(tf.distribute.ReduceOp.MEAN, strategy.run(tstep, args = (distributed_data,)), axis = None)\n",
        "\n",
        "        return loss, q, sarts[2], sarts[1]\n",
        "\n",
        "    else :\n",
        "        return 0,0, sarts[2], sarts[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9c5b3f0b-f6a8-4b12-9bc1-74330da8575a",
        "outputId": "2b3bb39e-1cf1-4801-d1cf-179a670ec250",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unable to load data\n"
          ]
        }
      ],
      "source": [
        "loss_mean = []\n",
        "q_mean = []\n",
        "rewards = []\n",
        "\n",
        "try:\n",
        "    model.load_weights(path+\"model.weights.h5\")\n",
        "    target_model.load_weights(path+\"model.weights.h5\")\n",
        "\n",
        "    loss_mean = obj_load(path+\"loss\")\n",
        "    q_mean = obj_load(path+\"q\")\n",
        "    rewards = obj_load(path+\"rewards\")\n",
        "except:\n",
        "    print(\"unable to load data\")\n",
        "\n",
        "\n",
        "def save():\n",
        "            model.save_weights(path+\"model.weights.h5\")\n",
        "            obj_save(loss_mean, path+\"loss\")\n",
        "            obj_save(q_mean, path+\"q\")\n",
        "            obj_save(rewards, path+\"rewards\")\n",
        "            print(\"saved progress\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a15d1bbb-b532-45b5-92bb-3bb84375b744",
        "outputId": "6e29f02a-6c38-4218-9479-958c47277b4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 7.1046 - qv: 76.1712 - reward: -0.0564 - avg_action: 1.5580\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 5.5849 - qv: 65.6487 - reward: -0.0893 - avg_action: 1.2050\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 12.9455 - qv: 80.1641 - reward: -0.1312 - avg_action: 1.4500\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 5.3041 - qv: 74.7786 - reward: -0.1203 - avg_action: 1.4270\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 5.6153 - qv: 80.0420 - reward: -0.0669 - avg_action: 1.5230\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 4.9633 - qv: 64.2993 - reward: -0.2005 - avg_action: 1.6750\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 6.1832 - qv: 77.5930 - reward: -0.0179 - avg_action: 1.1300\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 5.3564 - qv: 71.0936 - reward: -0.0014 - avg_action: 1.4760\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 9.5453 - qv: 73.3651 - reward: 0.0043 - avg_action: 1.3490\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 5.1186 - qv: 70.2342 - reward: -0.0175 - avg_action: 0.8000\n",
            "saved progress\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 4.7885 - qv: 67.3624 - reward: -0.0159 - avg_action: 1.2310\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 6.1625 - qv: 67.6526 - reward: -0.0063 - avg_action: 1.2750\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 8.5473 - qv: 77.0112 - reward: -0.0273 - avg_action: 0.5090\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 11.5157 - qv: 77.3505 - reward: -0.0076 - avg_action: 1.0060\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 5.3533 - qv: 78.0735 - reward: 0.0027 - avg_action: 1.2980\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 5.8010 - qv: 76.7391 - reward: 1.8400e-04 - avg_action: 1.2560\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 8.5289 - qv: 69.6662 - reward: -0.0084 - avg_action: 0.9630\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 6.3085 - qv: 80.9294 - reward: -0.0184 - avg_action: 0.4770\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 8.4229 - qv: 75.0348 - reward: -0.0163 - avg_action: 0.8160\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 5.1043 - qv: 68.0490 - reward: -0.0104 - avg_action: 0.8360\n",
            "saved progress\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 62ms/step - loss: 8.4645 - qv: 76.0706 - reward: -0.0065 - avg_action: 0.9990\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - loss: 4.9388 - qv: 64.2174 - reward: -6.9600e-04 - avg_action: 1.1160\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 5.3233 - qv: 72.3138 - reward: -7.9400e-04 - avg_action: 0.4640\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 5.7831 - qv: 65.8949 - reward: -0.0012 - avg_action: 0.7140\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 5.7120 - qv: 75.3172 - reward: -3.1400e-04 - avg_action: 0.8510\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 4.8123 - qv: 66.6660 - reward: 6.9333e-05 - avg_action: 0.5940\n",
            "\u001b[1m 171/1000\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 61ms/step - loss: 3.8123 - qv: 57.5421 - reward: -0.0014 - avg_action: 0.4386"
          ]
        }
      ],
      "source": [
        "save_eps = 10\n",
        "eps_c = 0\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        eps_c += 1\n",
        "        loss = []\n",
        "        q = []\n",
        "        rewards_tmp = []\n",
        "        actions = []\n",
        "        progbar = tf.keras.utils.Progbar(ep_len)\n",
        "        for i in range(ep_len):\n",
        "            c_loss, c_q, c_rewards, c_action = run()\n",
        "            loss.append(c_loss)\n",
        "            q.append(c_q)\n",
        "            rewards_tmp.append(c_rewards)\n",
        "            actions.append(c_action)\n",
        "\n",
        "            progbar.update(i+1, values = [(\"loss\", c_loss), (\"qv\", c_q), (\"reward\", c_rewards), (\"avg_action\", c_action)])\n",
        "\n",
        "        loss_mean.append(np.mean(loss))\n",
        "        q_mean.append(np.mean(q))\n",
        "        #rewards.append(np.mean(rewards_tmp))\n",
        "        rewards.extend(rewards_tmp)\n",
        "\n",
        "        #progbar.update(ep_len, values = [(\"loss\", np.mean(loss)), (\"qv\", np.mean(q)), (\"reward\", np.mean(rewards_tmp)), (\"avg_action\", np.mean(actions))])\n",
        "\n",
        "        target_model.set_weights(model.get_weights())\n",
        "\n",
        "\n",
        "        #if time.time() - start_time > 60*60*8.8:\n",
        "            #break\n",
        "        if(eps_c >=save_eps):\n",
        "          eps_c=0\n",
        "          save()\n",
        "\n",
        "    except    KeyboardInterrupt:\n",
        "        print(\"\")\n",
        "        print(\"exit\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "b536a1d7-a655-4d08-9e9d-c8cbf420a885",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dbc92d5-4b30-4ae0-eb30-292f7c7b4316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved progress\n"
          ]
        }
      ],
      "source": [
        "save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4a89278c-2823-4e36-8746-908718c80748"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "tpu1vmV38",
      "dataSources": [],
      "dockerImageVersionId": 30841,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}