{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iw9L3PcRHypQ"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/dercodeKoenig/hft_dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GOXl2HpH0M4"
   },
   "outputs": [],
   "source": [
    "%cd hft_dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "srO8OLjtH1Zq"
   },
   "outputs": [],
   "source": [
    "!pip install kaggle\n",
    "!kaggle datasets download bpwqsdd/us-futures-1-minute-candlesticks\n",
    "!unzip us-futures-1-minute-candlesticks.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1b197691-b458-4cbf-943f-14c353d9da30"
   },
   "outputs": [],
   "source": [
    "\n",
    "from MultiTimeframeCandleManager import MultiTimeframeCandleManager\n",
    "from datetime import datetime, timedelta\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from save_and_load import *\n",
    "from Candle import Candle\n",
    "import matplotlib.pyplot as plt\n",
    "#from tensorflow.keras import mixed_precision\n",
    "#mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eu8rj9GMIGCL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n",
      "INFO:tensorflow:Initializing the TPU system: local\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy at 0x1b759c1fd60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"local\")\n",
    "    tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
    "    strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
    "    print(\"use tpu strategy\")\n",
    "except:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1a46f09d-bcd5-4f57-a637-d75e36e4bfe0"
   },
   "outputs": [],
   "source": [
    "gamma = 0.995\n",
    "memory_len = 500000\n",
    "sarts_memory = deque(maxlen = memory_len)\n",
    "batch_size = 256\n",
    "e = 2\n",
    "slm = 1.5\n",
    "\n",
    "min_memory_size = 1024\n",
    "\n",
    "num_actions = 3\n",
    "\n",
    "path = \"./\"\n",
    "\n",
    "ep_len = 1000\n",
    "\n",
    "m1 = np.eye(num_actions, dtype=\"float32\")\n",
    "num_model_inputs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "390662b5-22d2-4aa9-a457-d598fdb81fe2",
    "outputId": "0a51d9cc-6cbc-4850-8fc6-36423e56f33d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 94)]         0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 60, 94)       0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 60, 98)       0           ['input_3[0][0]',                \n",
      "                                                                  'lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 60, 256)      25344       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        multiple             0           ['dense[0][0]',                  \n",
      "                                                                  'dense_1[0][0]',                \n",
      "                                                                  'dense_2[0][0]',                \n",
      "                                                                  'dense_3[0][0]',                \n",
      "                                                                  'dense_4[0][0]',                \n",
      "                                                                  'dense_5[0][0]',                \n",
      "                                                                  'dense_6[0][0]',                \n",
      "                                                                  'dense_7[0][0]',                \n",
      "                                                                  'dense_8[0][0]',                \n",
      "                                                                  'dense_9[0][0]',                \n",
      "                                                                  'dense_10[0][0]',               \n",
      "                                                                  'dense_11[0][0]',               \n",
      "                                                                  'dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 60, 256)      65792       ['leaky_re_lu[6][0]']            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 60, 98)       0           ['input_2[0][0]',                \n",
      "                                                                  'lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 60, 256)      65792       ['leaky_re_lu[7][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 60, 256)      25344       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 60, 256)      65792       ['leaky_re_lu[3][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 60, 98)       0           ['input_1[0][0]',                \n",
      "                                                                  'lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 60, 256)      65792       ['leaky_re_lu[4][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 60, 256)      25344       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 60, 256)      65792       ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 60, 256)      65792       ['leaky_re_lu[1][0]']            \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 8)         11520       ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 240)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 240)          0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 240)          0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 8)            0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " gru_2 (GRU)                    (None, 128)          148224      ['leaky_re_lu[8][0]']            \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, 128)          148224      ['leaky_re_lu[5][0]']            \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, 128)          148224      ['leaky_re_lu[2][0]']            \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 1209)         0           ['flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]',              \n",
      "                                                                  'flatten_3[0][0]',              \n",
      "                                                                  'input_4[0][0]',                \n",
      "                                                                  'flatten[0][0]',                \n",
      "                                                                  'input_5[0][0]',                \n",
      "                                                                  'gru_2[0][0]',                  \n",
      "                                                                  'gru_1[0][0]',                  \n",
      "                                                                  'gru[0][0]']                    \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 8192)         9912320     ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 8192)         67117056    ['leaky_re_lu[9][0]']            \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 8192)         67117056    ['leaky_re_lu[10][0]']           \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 8192)         67117056    ['leaky_re_lu[11][0]']           \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 1)            8193        ['leaky_re_lu[12][0]']           \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 3)            24579       ['leaky_re_lu[12][0]']           \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 3)            0           ['dense_13[0][0]',               \n",
      "                                                                  'dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 3)            0           ['lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 212,223,236\n",
      "Trainable params: 212,223,236\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "  lrelu = tf.keras.layers.LeakyReLU(0.05)\n",
    "\n",
    "\n",
    "  chart_m15 = tf.keras.layers.Input(shape = (60,4))\n",
    "  chart_m5 = tf.keras.layers.Input(shape = (60,4))\n",
    "  chart_m1 = tf.keras.layers.Input(shape = (60,4))\n",
    "\n",
    "  pdas = tf.keras.layers.Input(shape = (3*3+3*3+1+12*5+5*3,))\n",
    "\n",
    "  current_position = tf.keras.layers.Input(shape = (3,))\n",
    "\n",
    "  minutes = tf.keras.layers.Input(shape = (1,))\n",
    "  minutes_embed = tf.keras.layers.Embedding(input_dim=60*24, output_dim=8)(minutes)\n",
    "  minutes_embed_flat = tf.keras.layers.Flatten()(minutes_embed)\n",
    "\n",
    "  f15 = tf.keras.layers.Flatten()(chart_m15)\n",
    "  f5 = tf.keras.layers.Flatten()(chart_m5)\n",
    "  f1 = tf.keras.layers.Flatten()(chart_m1)\n",
    "\n",
    "  pdas_repeated = tf.keras.layers.Lambda(\n",
    "  lambda inputs: tf.repeat(tf.expand_dims(inputs, axis = 1), repeats=60, axis=1)\n",
    "  )(pdas)\n",
    "\n",
    "  concatenated_m15_at = tf.keras.layers.Concatenate(axis=-1)([chart_m15, pdas_repeated])\n",
    "  m15_at = tf.keras.layers.Dense(256)(concatenated_m15_at)\n",
    "  m15_at = lrelu(m15_at)\n",
    "  m15_at = tf.keras.layers.Dense(256)(m15_at)\n",
    "  m15_at = lrelu(m15_at)\n",
    "  m15_at = tf.keras.layers.Dense(256)(m15_at)\n",
    "  m15_at = lrelu(m15_at)\n",
    "  m15_rnn = tf.keras.layers.GRU(128)(m15_at)\n",
    "\n",
    "  concatenated_m5_at = tf.keras.layers.Concatenate(axis=-1)([chart_m5, pdas_repeated])\n",
    "  m5_at = tf.keras.layers.Dense(256)(concatenated_m5_at)\n",
    "  m5_at = lrelu(m5_at)\n",
    "  m5_at = tf.keras.layers.Dense(256)(m5_at)\n",
    "  m5_at = lrelu(m5_at)\n",
    "  m5_at = tf.keras.layers.Dense(256)(m5_at)\n",
    "  m5_at = lrelu(m5_at)\n",
    "  m5_rnn = tf.keras.layers.GRU(128)(m5_at)\n",
    "\n",
    "  concatenated_m1_at = tf.keras.layers.Concatenate(axis=-1)([chart_m1, pdas_repeated])\n",
    "  m1_at = tf.keras.layers.Dense(256)(concatenated_m1_at)\n",
    "  m1_at = lrelu(m1_at)\n",
    "  m1_at = tf.keras.layers.Dense(256)(m1_at)\n",
    "  m1_at = lrelu(m1_at)\n",
    "  m1_at = tf.keras.layers.Dense(256)(m1_at)\n",
    "  m1_at = lrelu(m1_at)\n",
    "  m1_rnn = tf.keras.layers.GRU(128)(m1_at)\n",
    "\n",
    "  #c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, scaled_open_profit])\n",
    "  c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, m1_rnn, m5_rnn, m15_rnn])\n",
    "\n",
    "  d = tf.keras.layers.Dense(1024*8)(c)\n",
    "  d = lrelu(d)\n",
    "  d = tf.keras.layers.Dense(1024*8)(d)\n",
    "  d = lrelu(d)\n",
    "  d = tf.keras.layers.Dense(1024*8)(d)\n",
    "  d = lrelu(d)\n",
    "  d = tf.keras.layers.Dense(1024*8)(d)\n",
    "  d = lrelu(d)\n",
    "\n",
    "\n",
    "  value = tf.keras.layers.Dense(1, activation=\"linear\")(d)\n",
    "  advantage = tf.keras.layers.Dense(num_actions, activation=\"linear\")(d)\n",
    "\n",
    "  q_values = tf.keras.layers.Lambda(\n",
    "  lambda inputs: inputs[0] + (inputs[1] - tf.reduce_mean(inputs[1], axis=1, keepdims=True))\n",
    "  )([value, advantage])\n",
    "\n",
    "  outputs = tf.keras.layers.Activation('linear', dtype='float32')(q_values)\n",
    "\n",
    "  model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = outputs)\n",
    "  target_model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = outputs)\n",
    "\n",
    "\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate = 0.000001)\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8f069d41-781f-439b-b12a-59bd3e1f29e7"
   },
   "outputs": [],
   "source": [
    "\n",
    "def relative (value, center, r):\n",
    "        return (value - center) / r\n",
    "\n",
    "def ret_to_scaled_inputs(ret):\n",
    "\n",
    "    midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "\n",
    "\n",
    "    center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
    "    r = max(0.0001,(midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
    "\n",
    "    pda_rel = []\n",
    "    pda_rel.append(relative(midnight_open, center, r))\n",
    "    for pda in pdas[0:9+9+15]:\n",
    "        pda_rel.append(relative(pda, center, r))\n",
    "    for index in range(9+9+15,9+9+15+5*12):\n",
    "        ## highs lows are like this [h, h_taken, l, l_taken]\n",
    "        ## the bools should not be scaled\n",
    "        if (index - 9+9+15) % 2 == 0:\n",
    "            pda_rel.append(relative(pdas[index], center, r))\n",
    "        else:\n",
    "            pda_rel.append(pdas[index])\n",
    "\n",
    "    pda_np = np.array(pda_rel)\n",
    "\n",
    "    current_minutes = current_time.hour * 60 + current_time.minute\n",
    "\n",
    "    charts_array = []\n",
    "    for candlesticks in charts:\n",
    "        charts_array.append([])\n",
    "        for candle in candlesticks:\n",
    "            o = relative(candle.o, center, r)\n",
    "            h = relative(candle.h, center, r)\n",
    "            l = relative(candle.l, center, r)\n",
    "            c = relative(candle.c, center, r)\n",
    "            charts_array[-1].append([o,h,l,c])\n",
    "\n",
    "    m15_np = np.array(charts_array[0])\n",
    "    m5_np = np.array(charts_array[1])\n",
    "    m1_np = np.array(charts_array[2])\n",
    "\n",
    "    return [m15_np, m5_np, m1_np, pda_np, current_minutes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3cd5699d-6072-4afe-8e58-f529f228ad0b"
   },
   "outputs": [],
   "source": [
    "class Order:\n",
    "    def __init__(self, limit, stop, tp, direction):\n",
    "        self.entry = limit\n",
    "        self.tp = tp\n",
    "        self.sl = stop\n",
    "        self.direction = direction\n",
    "\n",
    "class Position:\n",
    "    def __init__(self, entry, stop, tp, direction):\n",
    "        self.entry = entry\n",
    "        self.tp = tp\n",
    "        self.sl = stop\n",
    "        self.direction = direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0c1b7326-2b0f-49e6-86b1-815fd4ef4c87",
    "outputId": "8cb639ea-8439-4efa-c4ab-9b64cbcc7675"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading NQ_2\n",
      "env reset, using data: ('NQ_2', 1)\n"
     ]
    }
   ],
   "source": [
    "equity = 0\n",
    "equity_L = [0]\n",
    "\n",
    "inputs = [\n",
    "    (\"NQ_2\", 1),\n",
    "    (\"ES_2\", 0.75),\n",
    "    (\"YM_2\", 1.5),\n",
    "    (\"EURUSD_2\", 0.00015),\n",
    "    (\"GBPUSD_2\", 0.00015)\n",
    "]\n",
    "\n",
    "candles = []\n",
    "cmm = 0\n",
    "def reset():\n",
    "    global index, last_state, last_action, current_position, current_order, equity, m, candles, cmm\n",
    "\n",
    "    ob = random.choice(inputs)\n",
    "    candles = obj_load(ob[0])\n",
    "    cmm = ob[1]\n",
    "\n",
    "    m = MultiTimeframeCandleManager()\n",
    "\n",
    "    current_position = Position(0,0,0,0)\n",
    "    current_order = None\n",
    "\n",
    "    last_state = None\n",
    "    last_action = 0\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    print(\"env reset, using data:\", ob)\n",
    "\n",
    "\n",
    "@tf.function()\n",
    "def inference_step(m15_np, m5_np, m1_np, pda_np, current_minutes, pos_info):\n",
    "    return model([\n",
    "        m15_np, \n",
    "        m5_np, \n",
    "        m1_np, \n",
    "        pda_np, \n",
    "        current_minutes, \n",
    "        pos_info,\n",
    "    ])\n",
    "    \n",
    "\n",
    "def step():\n",
    "\n",
    "    global index, last_state, last_action, current_position, current_order, equity, m\n",
    "\n",
    "\n",
    "    sarts = None\n",
    "    while  sarts == None:\n",
    "\n",
    "        ret = m.push_m1_candle(candles[index])\n",
    "        midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "        center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
    "        r = max(0.0001, (midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
    "\n",
    "\n",
    "\n",
    "        current_candle_m1 = charts[2][-1]\n",
    "        #### check tp before filling order so that the same m1 candle will not trigger tp - it is not sure if the candle hit first limit and later tp or reve3rse\n",
    "        if current_position.direction == 1:\n",
    "            if current_candle_m1.h >= current_position.tp:\n",
    "                pnl = (current_position.tp - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "        if current_position.direction == -1:\n",
    "            if current_candle_m1.l <= current_position.tp:\n",
    "                pnl = (current_position.tp - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "        #### check order\n",
    "        if current_order != None:\n",
    "            if  current_order.direction == 1:\n",
    "                if current_candle_m1.l < current_order.entry:\n",
    "                    current_position = Position(current_order.entry, current_order.sl, current_order.tp, current_order.direction)\n",
    "                    #print(\"fill long order:\",current_order.entry, current_order.sl, current_order.tp)\n",
    "                    equity -= cmm\n",
    "                    current_order = None\n",
    "        if current_order != None:\n",
    "            if  current_order.direction == -1:\n",
    "                if current_candle_m1.h > current_order.entry:\n",
    "                    current_position = Position(current_order.entry, current_order.sl, current_order.tp, current_order.direction)\n",
    "                    #print(\"fill short order:\",current_order.entry, current_order.sl, current_order.tp)\n",
    "                    equity -= cmm\n",
    "                    current_order = None\n",
    "\n",
    "        #### check sl\n",
    "        if current_position.direction == 1:\n",
    "            if current_candle_m1.l <= current_position.sl:\n",
    "                pnl = (current_position.sl - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "        if current_position.direction == -1:\n",
    "            if current_candle_m1.h >= current_position.sl:\n",
    "                pnl = (current_position.sl - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if(len(m.ndogs) == 5 and len(m.fps) == 3 and len(m.opening_range_gaps) == 3 and len(m.asia_highs_lows) == 3 and len(m.london_highs_lows) == 3 and len(m.ny_am_highs_lows) == 3 and len(m.ny_lunch_highs_lows) == 3 and len(m.ny_pm_highs_lows) == 3):\n",
    "\n",
    "\n",
    "            open_profit = (current_close - current_position.entry) * current_position.direction\n",
    "\n",
    "            scaled_entry_diff  =  0\n",
    "            scaled_sl_diff  =  0\n",
    "            if(current_position.direction != 0):\n",
    "                scaled_entry_diff = (current_close - current_position.entry) / r\n",
    "                scaled_sl_diff = (current_close - current_position.sl) / r\n",
    "\n",
    "            state = ret_to_scaled_inputs(ret) + [np.array([current_position.direction, scaled_entry_diff, scaled_sl_diff])]\n",
    "            m15_np, m5_np, m1_np, pda_np, current_minutes, pos_info = state\n",
    "\n",
    "            if(last_state != None):\n",
    "                diff = (equity+open_profit) - equity_L[-1]\n",
    "                equity_L.append(equity+open_profit)\n",
    "                reward =  (diff) / r\n",
    "                terminal = 0\n",
    "                if(index+1 == len(candles)):\n",
    "                    terminal = 1\n",
    "\n",
    "                sarts = last_state, last_action, reward, terminal, state\n",
    "\n",
    "\n",
    "            if(random.randint(0,100) > e):\n",
    "                with tf.device(\"/TPU:0\"):\n",
    "                    output = inference_step(\n",
    "                        tf.expand_dims(m15_np, 0),\n",
    "                        tf.expand_dims(m5_np, 0),\n",
    "                        tf.expand_dims(m1_np, 0),\n",
    "                        tf.expand_dims(pda_np, 0),\n",
    "                        tf.expand_dims(current_minutes, 0),\n",
    "                        tf.expand_dims(pos_info, 0)\n",
    "                    )\n",
    "\n",
    "                last_action = np.argmax(output)\n",
    "            else:\n",
    "                last_action = random.randint(0,num_actions-1)\n",
    "\n",
    "            last_state = state\n",
    "            \n",
    "            current_order = None\n",
    "\n",
    "            avg_candle_range = np.mean([ i.h - i.l for i in list(charts[2])[55:60]])\n",
    "           \n",
    "            if(last_action == 2 and current_position.direction != 0):    \n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "            \n",
    "            if(last_action == 0 and current_position.direction == 1):    \n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "            if(last_action == 0 and current_position.direction == 0):\n",
    "                last_candle_low = charts[2][-2].l\n",
    "                if ( last_candle_low < current_close ):\n",
    "                    last_candle_low = None\n",
    "                    \n",
    "                pdas = m.normal_pdas ## (low, high)\n",
    "                \n",
    "                ## ignore pdas with low below close\n",
    "                pdas_filtered = []\n",
    "                for pda in pdas:\n",
    "                        if(pda[0] > current_close):\n",
    "                            pdas_filtered.append(pda)\n",
    "                ### sort\n",
    "                sorted_by_high = sorted(pdas_filtered, key = lambda x:x[1])\n",
    "                sorted_by_low = sorted(pdas_filtered, key = lambda x:x[0])\n",
    "\n",
    "                if(len(pdas_filtered) > 0):\n",
    "\n",
    "                    ### entry is lowest i can get or immediate rebalance\n",
    "                    entry = sorted_by_low[0][0]\n",
    "                    if(last_candle_low != None):\n",
    "                        entry = min(entry, last_candle_low)\n",
    "\n",
    "\n",
    "                    sl = entry + avg_candle_range * slm\n",
    "                    tp = entry  -  abs(entry-sl) * 1000\n",
    "\n",
    "\n",
    "                    current_order = Order(entry, sl, tp, -1)\n",
    "                    #print(\"set short order:\",entry,sl,tp)\n",
    "\n",
    "                    \n",
    "\n",
    "            if(last_action == 1 and current_position.direction == -1):    \n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "            if(last_action == 1 and current_position.direction == 0):\n",
    "                last_candle_high = charts[2][-2].h\n",
    "                if ( last_candle_high > current_close ):\n",
    "                    last_candle_high = None\n",
    "                pdas = m.normal_pdas ## (low, high)\n",
    "                \n",
    "                ## ignore pdas with low below close\n",
    "                pdas_filtered = []\n",
    "                for pda in pdas:\n",
    "                        if(pda[1] < current_close):\n",
    "                            pdas_filtered.append(pda)\n",
    "                ### sort\n",
    "                sorted_by_high = sorted(pdas_filtered, key = lambda x:x[1], reverse=True)\n",
    "                sorted_by_low = sorted(pdas_filtered, key = lambda x:x[0], reverse=True)\n",
    "\n",
    "                if(len(pdas_filtered) > 0):\n",
    "                    ### entry is lowest i can get or immediate rebalance\n",
    "                    entry = sorted_by_high[0][1]\n",
    "                    if(last_candle_high != None):\n",
    "                        entry = max(entry, last_candle_high)\n",
    "\n",
    "                    sl = entry - avg_candle_range * slm\n",
    "                    tp = entry  +  abs(entry-sl) * 1000\n",
    "\n",
    "                    current_order = Order(entry, sl, tp, 1)\n",
    "                    #print(\"set long order:\",entry,sl,tp)\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        index += 1\n",
    "        if(index == len(candles)):\n",
    "            reset()\n",
    "\n",
    "    return sarts\n",
    "\n",
    "reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_candles(candles):\n",
    "    for index in range(len(candles)):\n",
    "        candle = candles[index]\n",
    "        c = \"green\" if candle.c > candle.o else \"black\"\n",
    "        plt.plot([index, index], [candle.l, candle.h], linewidth=1, color = \"black\")\n",
    "        plt.plot([index, index], [candle.c, candle.o], linewidth=3, color = c)\n",
    "\n",
    "sarts = step()\n",
    "\n",
    "plot_candles(m.m1_candles)\n",
    "if(current_position.direction != 0):\n",
    "    plt.axhline(current_position.entry, color = \"g\" if current_position.direction == 1 else \"r\")\n",
    "    plt.axhline(current_position.sl, color = \"orange\")\n",
    "\n",
    "if(current_order != None):\n",
    "    plt.axhline(current_order.entry, color = \"g\" if current_order.direction == 1 else \"r\")\n",
    "    plt.axhline(current_order.sl, color = \"orange\")\n",
    "\n",
    "\n",
    "print(sarts[1], sarts[2], current_position.direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "d92f99f8-68df-4fbd-bc4d-218a2a43f865"
   },
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def get_target_q(next_states, rewards, terminals):\n",
    "            estimated_q_values_next = target_model(next_states)\n",
    "            q_batch = tf.math.reduce_max(estimated_q_values_next, axis=1)\n",
    "            target_q_values = q_batch * gamma * (1-terminals) + rewards\n",
    "            return target_q_values\n",
    "\n",
    "@tf.function()\n",
    "def tstep(data):\n",
    "    states, masks, rewards, terminals, next_states = data\n",
    "\n",
    "    target_q_values = get_target_q(next_states, rewards, terminals)\n",
    "\n",
    "    with tf.GradientTape() as t:\n",
    "        model_return = model(states, training=True)\n",
    "        mask_return = model_return * masks\n",
    "        estimated_q_values = tf.math.reduce_sum(mask_return, axis=1)\n",
    "        #print(estimated_q_values, mask_return, model_return, masks)\n",
    "        loss_e = tf.math.square(target_q_values - estimated_q_values)\n",
    "        loss = tf.reduce_mean(loss_e)\n",
    "\n",
    "\n",
    "    gradient = t.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
    "\n",
    "    return loss, tf.reduce_mean(estimated_q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fd706ba5-8f9c-4889-a382-46f25bc9653c"
   },
   "outputs": [],
   "source": [
    "def get_data(n):\n",
    "        r = random.randint(0, len(sarts_memory) - batch_size)\n",
    "        sarts_sample = [sarts_memory[i] for i in range(r, r + batch_size)]\n",
    "\n",
    "\n",
    "\n",
    "        states = [x[0] for x in sarts_sample]\n",
    "        actions = [x[1] for x in sarts_sample]\n",
    "        rewards = np.array([x[2] for x in sarts_sample], dtype=\"float32\")\n",
    "        terminals = np.array([x[3] for x in sarts_sample], dtype=\"float32\")\n",
    "        next_states = [x[4] for x in sarts_sample]\n",
    "\n",
    "        next_states_array = []\n",
    "        for i in range(num_model_inputs):\n",
    "            next_states_array.append(np.array([x[i] for x in next_states], dtype = \"float32\"))\n",
    "\n",
    "\n",
    "        states_array = []\n",
    "        for i in range(num_model_inputs):\n",
    "            states_array.append(np.array([x[i] for x in states], dtype = \"float32\"))\n",
    "\n",
    "\n",
    "        masks = np.array(m1[actions], dtype=\"float32\")\n",
    "\n",
    "\n",
    "        return states_array, masks, rewards, terminals, next_states_array\n",
    "\n",
    "def run():\n",
    "    sarts = step()\n",
    "    sarts_memory.append(sarts)\n",
    "\n",
    "    if(len(sarts_memory) > min_memory_size):\n",
    "\n",
    "        distributed_data = (strategy.experimental_distribute_values_from_function(get_data))\n",
    "        loss, q = strategy.reduce(tf.distribute.ReduceOp.MEAN, strategy.run(tstep, args = (distributed_data,)), axis = None)\n",
    "\n",
    "        return loss, q, sarts[2], sarts[1]\n",
    "\n",
    "    else :\n",
    "        return 0,0, sarts[2], sarts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9c5b3f0b-f6a8-4b12-9bc1-74330da8575a",
    "outputId": "e461fe28-ac50-486b-8c53-cbd730520515"
   },
   "outputs": [],
   "source": [
    "loss_mean = []\n",
    "q_mean = []\n",
    "rewards = []\n",
    "\n",
    "try:\n",
    "    model.load_weights(path+\"model.weights.h5\")\n",
    "    target_model.load_weights(path+\"model.weights.h5\")\n",
    "\n",
    "    loss_mean = obj_load(path+\"loss\")\n",
    "    q_mean = obj_load(path+\"q\")\n",
    "    rewards = obj_load(path+\"rewards\")\n",
    "except:\n",
    "    print(\"unable to load data\")\n",
    "\n",
    "\n",
    "def save():\n",
    "            model.save_weights(path+\"model.weights.h5\")\n",
    "            obj_save(loss_mean, path+\"loss\")\n",
    "            obj_save(q_mean, path+\"q\")\n",
    "            obj_save(rewards, path+\"rewards\")\n",
    "            print(\"saved progress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a15d1bbb-b532-45b5-92bb-3bb84375b744",
    "outputId": "0a7f8401-23c3-495d-b695-3fa47d49907a"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        loss = []\n",
    "        q = []\n",
    "        rewards_tmp = []\n",
    "        actions = []\n",
    "        progbar = tf.keras.utils.Progbar(ep_len)\n",
    "        for i in range(ep_len):\n",
    "            c_loss, c_q, c_rewards, c_action = run()\n",
    "            loss.append(c_loss)\n",
    "            q.append(c_q)\n",
    "            #rewards_tmp.append(c_rewards)\n",
    "            rewards.append(c_rewards)\n",
    "            actions.append(c_action)\n",
    "\n",
    "            progbar.update(i+1, values = [(\"loss\", c_loss), (\"qv\", c_q), (\"reward\", c_rewards), (\"avg_action\", c_action)])\n",
    "\n",
    "        loss_mean.append(np.mean(loss))\n",
    "        q_mean.append(np.mean(q))\n",
    "        #rewards.append(np.mean(rewards_tmp))\n",
    "\n",
    "        #progbar.update(ep_len, values = [(\"loss\", np.mean(loss)), (\"qv\", np.mean(q)), (\"reward\", np.mean(rewards)), (\"avg_action\", np.mean(actions))])\n",
    "\n",
    "        target_model.set_weights(model.get_weights())\n",
    "\n",
    "\n",
    "        if time.time() - start_time > 60*60*8.8:\n",
    "            break\n",
    "    \n",
    "    except    KeyboardInterrupt:\n",
    "        print(\"\")\n",
    "        print(\"exit\")\n",
    "        save()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b536a1d7-a655-4d08-9e9d-c8cbf420a885"
   },
   "outputs": [],
   "source": [
    "save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4a89278c-2823-4e36-8746-908718c80748"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "include_colab_link": true,
   "provenance": []
  },
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [],
   "dockerImageVersionId": 30841,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
