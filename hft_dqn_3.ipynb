{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b197691-b458-4cbf-943f-14c353d9da30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading NQ_2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MultiTimeframeCandleManager import MultiTimeframeCandleManager\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from save_and_load import *\n",
    "from Candle import Candle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "candles = obj_load(\"NQ_2\")\n",
    "len(candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a46f09d-bcd5-4f57-a637-d75e36e4bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.99\n",
    "memory_len = 100000\n",
    "batch_size = 512\n",
    "e = 2\n",
    "\n",
    "num_actions = 3\n",
    "\n",
    "path = \"./\"\n",
    "\n",
    "ep_len = 1000\n",
    "\n",
    "m1 = np.eye(num_actions, dtype=\"float32\")\n",
    "num_model_inputs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "390662b5-22d2-4aa9-a457-d598fdb81fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 8)         11520       ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 240)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 240)          0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 240)          0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 79)]         0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 8)            0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 808)          0           ['flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]',              \n",
      "                                                                  'flatten_3[0][0]',              \n",
      "                                                                  'input_4[0][0]',                \n",
      "                                                                  'flatten[0][0]',                \n",
      "                                                                  'input_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4096)         3313664     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 4096)         0           ['dense[0][0]',                  \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4096)         16781312    ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            4097        ['leaky_re_lu[1][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 3)            12291       ['leaky_re_lu[1][0]']            \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 3)            0           ['dense_2[0][0]',                \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20,122,884\n",
      "Trainable params: 20,122,884\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "chart_m15 = tf.keras.layers.Input(shape = (60,4))\n",
    "chart_m5 = tf.keras.layers.Input(shape = (60,4))\n",
    "chart_m1 = tf.keras.layers.Input(shape = (60,4))\n",
    "\n",
    "pdas = tf.keras.layers.Input(shape = (19+12*5,))\n",
    "\n",
    "current_position = tf.keras.layers.Input(shape = (1,))\n",
    "#scaled_open_profit = tf.keras.layers.Input(shape = (1,))\n",
    "\n",
    "minutes = tf.keras.layers.Input(shape = (1,))\n",
    "minutes_embed = tf.keras.layers.Embedding(input_dim=60*24, output_dim=8)(minutes)\n",
    "minutes_embed_flat = tf.keras.layers.Flatten()(minutes_embed)\n",
    "\n",
    "f15 = tf.keras.layers.Flatten()(chart_m15)\n",
    "f5 = tf.keras.layers.Flatten()(chart_m5)\n",
    "f1 = tf.keras.layers.Flatten()(chart_m1)\n",
    "\n",
    "#c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, scaled_open_profit])\n",
    "c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position])\n",
    "\n",
    "lrelu = tf.keras.layers.LeakyReLU(0.05)\n",
    "\n",
    "d = tf.keras.layers.Dense(1024*4)(c)\n",
    "d = lrelu(d)\n",
    "d = tf.keras.layers.Dense(1024*4)(d)\n",
    "d = lrelu(d)\n",
    "\n",
    "\n",
    "value = tf.keras.layers.Dense(1, activation=\"linear\")(d)\n",
    "advantage = tf.keras.layers.Dense(num_actions, activation=\"linear\")(d)\n",
    "\n",
    "q_values = tf.keras.layers.Lambda(\n",
    "lambda inputs: inputs[0] + (inputs[1] - tf.reduce_mean(inputs[1], axis=1, keepdims=True))\n",
    ")([value, advantage])\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = q_values)\n",
    "target_model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = q_values)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.000001)\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f0d295f-6269-46ed-b746-07b90f99c47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f069d41-781f-439b-b12a-59bd3e1f29e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def relative (value, center, r):\n",
    "        return (value - center) / r\n",
    "\n",
    "def ret_to_scaled_inputs(ret):\n",
    "\n",
    "    midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "    \n",
    "\n",
    "    center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
    "    r = max(0.0001,(midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
    "\n",
    "    pda_rel = []\n",
    "    pda_rel.append(relative(midnight_open, center, r))\n",
    "    for pda in pdas[0:18]:\n",
    "        pda_rel.append(relative(pda, center, r))\n",
    "    for index in range(18,18+5*12):\n",
    "        ## highs lows are like this [h, h_taken, l, l_taken]\n",
    "        ## the bools should not be scaled\n",
    "        if (index - 18) % 2 == 0:\n",
    "            pda_rel.append(relative(pdas[index], center, r))\n",
    "        else:\n",
    "            pda_rel.append(pdas[index])\n",
    "    \n",
    "    pda_np = np.array(pda_rel)\n",
    "\n",
    "    current_minutes = current_time.hour * 60 + current_time.minute\n",
    "\n",
    "    charts_array = []\n",
    "    for candlesticks in charts:\n",
    "        charts_array.append([])\n",
    "        for candle in candlesticks:\n",
    "            o = relative(candle.o, center, r)\n",
    "            h = relative(candle.h, center, r)\n",
    "            l = relative(candle.l, center, r)\n",
    "            c = relative(candle.c, center, r)\n",
    "            charts_array[-1].append([o,h,l,c])\n",
    "\n",
    "    m15_np = np.array(charts_array[0])\n",
    "    m5_np = np.array(charts_array[1])\n",
    "    m1_np = np.array(charts_array[2])\n",
    "\n",
    "    return [m15_np, m5_np, m1_np, pda_np, current_minutes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd5699d-6072-4afe-8e58-f529f228ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Order:\n",
    "    def __init__(self, limit, stop, tp, direction):\n",
    "        self.entry = limit\n",
    "        self.tp = tp\n",
    "        self.sl = stop\n",
    "        self.direction = direction\n",
    "\n",
    "class Position:\n",
    "    def __init__(self, entry, stop, tp, direction):\n",
    "        self.entry = entry\n",
    "        self.tp = tp\n",
    "        self.sl = stop\n",
    "        self.direction = direction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c1b7326-2b0f-49e6-86b1-815fd4ef4c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MultiTimeframeCandleManager()\n",
    "\n",
    "current_position = Position(0,0,0,0)\n",
    "current_order = None\n",
    "\n",
    "equity = 0\n",
    "equity_L = [0]\n",
    "\n",
    "cmm = 0.5\n",
    "\n",
    "last_state = None\n",
    "last_action = 0\n",
    "\n",
    "index = 0\n",
    "\n",
    "def step():\n",
    "\n",
    "    global index, last_state, last_action, current_position, current_order, equity, m\n",
    "\n",
    "\n",
    "    sarts = None\n",
    "    while  sarts == None:\n",
    "\n",
    "        ret = m.push_m1_candle(candles[index])\n",
    "        midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "        center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
    "        r = max(0.0001, (midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
    "\n",
    "\n",
    "\n",
    "        current_candle_m1 = charts[2][-1]\n",
    "        #### check tp before filling order so that the same m1 candle will not trigger tp - it is not sure if the candle hit first limit and later tp or reve3rse        \n",
    "        if current_position.direction == 1:\n",
    "            if current_candle_m1.h >= current_position.tp:\n",
    "                pnl = (current_position.tp - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "        if current_position.direction == -1:\n",
    "            if current_candle_m1.l <= current_position.tp:\n",
    "                pnl = (current_position.tp - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "                \n",
    "        #### check order\n",
    "        if current_order != None:\n",
    "            if  current_order.direction == 1:\n",
    "                if current_candle_m1.l < current_order.entry:\n",
    "                    current_position = Position(current_order.entry, current_order.sl, current_order.tp, current_order.direction)\n",
    "                    #print(\"fill long order:\",current_order.entry, current_order.sl, current_order.tp)\n",
    "                    equity -= cmm\n",
    "                    current_order = None\n",
    "        if current_order != None:\n",
    "            if  current_order.direction == -1:\n",
    "                if current_candle_m1.h > current_order.entry:\n",
    "                    current_position = Position(current_order.entry, current_order.sl, current_order.tp, current_order.direction)\n",
    "                    #print(\"fill short order:\",current_order.entry, current_order.sl, current_order.tp)\n",
    "                    equity -= cmm\n",
    "                    current_order = None\n",
    "\n",
    "        #### check sl\n",
    "        if current_position.direction == 1:\n",
    "            if current_candle_m1.l <= current_position.sl:\n",
    "                pnl = (current_position.sl - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "        if current_position.direction == -1:\n",
    "            if current_candle_m1.h >= current_position.sl:\n",
    "                pnl = (current_position.sl - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "        if(len(m.fps) == 3 and len(m.opening_range_gaps) == 3 and len(m.asia_highs_lows) == 3 and len(m.london_highs_lows) == 3 and len(m.ny_am_highs_lows) == 3 and len(m.ny_lunch_highs_lows) == 3 and len(m.ny_pm_highs_lows) == 3):\n",
    "\n",
    "            \n",
    "            open_profit = (current_close - current_position.entry) * current_position.direction\n",
    "\n",
    "\n",
    "            state = ret_to_scaled_inputs(ret) + [current_position.direction]\n",
    "            m15_np, m5_np, m1_np, pda_np, current_minutes, pos = state\n",
    "\n",
    "            if(last_state != None):\n",
    "                diff = (equity+open_profit) - equity_L[-1]\n",
    "                equity_L.append(equity+open_profit)\n",
    "                reward =  (diff) / r\n",
    "                terminal = 0\n",
    "                if(index+1 == len(candles)):\n",
    "                    terminal = 1\n",
    "\n",
    "                sarts = last_state, last_action, reward, terminal, state\n",
    "\n",
    "\n",
    "            if(random.randint(0,100) > e):\n",
    "                output = model([\n",
    "                    tf.expand_dims(m15_np, 0),\n",
    "                    tf.expand_dims(m5_np, 0),\n",
    "                    tf.expand_dims(m1_np, 0),\n",
    "                    tf.expand_dims(pda_np, 0),\n",
    "                    tf.expand_dims(current_minutes, 0),\n",
    "                    tf.expand_dims(pos, 0)\n",
    "                ])\n",
    "\n",
    "                last_action = np.argmax(output)\n",
    "            else:\n",
    "                last_action = random.randint(0,num_actions-1)\n",
    "\n",
    "            last_state = state\n",
    "\n",
    "            if(last_action == 2 and current_position.direction != 0):    \n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "            \n",
    "            if(last_action == 0 and current_position.direction == 1):    \n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "            if(last_action == 0 and current_position.direction == 0):\n",
    "                last_candle_low = charts[2][-2].l\n",
    "                if ( last_candle_low < current_close ):\n",
    "                    last_candle_low = None\n",
    "                    \n",
    "                pdas = m.normal_pdas ## (low, high)\n",
    "                \n",
    "                ## ignore pdas with low below close\n",
    "                pdas_filtered = []\n",
    "                for pda in pdas:\n",
    "                        if(pda[0] > current_close):\n",
    "                            pdas_filtered.append(pda)\n",
    "                ### sort\n",
    "                sorted_by_high = sorted(pdas_filtered, key = lambda x:x[1])\n",
    "                sorted_by_low = sorted(pdas_filtered, key = lambda x:x[0])\n",
    "\n",
    "                if(len(pdas_filtered) >= 3):\n",
    "                    ### sl is the high of 3 pdas\n",
    "                    sl = sorted_by_high[2][1]\n",
    "\n",
    "                    ### entry is lowest i can get or immediate rebalance\n",
    "                    entry = sorted_by_low[0][0]\n",
    "                    if(last_candle_low != None):\n",
    "                        entry = min(entry, last_candle_low)\n",
    "\n",
    "                    tp = entry  -  abs(entry-sl) * 1000\n",
    "\n",
    "                    current_order = Order(entry, sl, tp, -1)\n",
    "                    #print(\"set short order:\",entry,sl,tp)\n",
    "\n",
    "                    \n",
    "\n",
    "            if(last_action == 1 and current_position.direction == -1):    \n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "            if(last_action == 1 and current_position.direction == 0):\n",
    "                last_candle_high = charts[2][-2].h\n",
    "                if ( last_candle_high > current_close ):\n",
    "                    last_candle_high = None\n",
    "                pdas = m.normal_pdas ## (low, high)\n",
    "                \n",
    "                ## ignore pdas with low below close\n",
    "                pdas_filtered = []\n",
    "                for pda in pdas:\n",
    "                        if(pda[1] < current_close):\n",
    "                            pdas_filtered.append(pda)\n",
    "                ### sort\n",
    "                sorted_by_high = sorted(pdas_filtered, key = lambda x:x[1], reverse=True)\n",
    "                sorted_by_low = sorted(pdas_filtered, key = lambda x:x[0], reverse=True)\n",
    "\n",
    "                if(len(pdas_filtered) >= 3):\n",
    "                    ### sl is the high of 3 pdas\n",
    "                    sl = sorted_by_low[2][0]\n",
    "\n",
    "                    ### entry is lowest i can get or immediate rebalance\n",
    "                    entry = sorted_by_high[0][1]\n",
    "                    if(last_candle_high != None):\n",
    "                        entry = max(entry, last_candle_high)\n",
    "\n",
    "                    tp = entry  +  abs(entry-sl) * 1000\n",
    "\n",
    "                    current_order = Order(entry, sl, tp, 1)\n",
    "                    #print(\"set long order:\",entry,sl,tp)\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        index += 1\n",
    "        if(index == len(candles)):\n",
    "            index = 0\n",
    "            current_position = Position(0,0,0,0)\n",
    "            last_state = None\n",
    "            last_action = 0\n",
    "            m = MultiTimeframeCandleManager()\n",
    "            print(\"env reset\")\n",
    "\n",
    "    return sarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de95bb89-390f-4c60-8e0b-da9382e3b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_candles(candles):\n",
    "    for index in range(len(candles)):\n",
    "        candle = candles[index]    \n",
    "        c = \"green\" if candle.c > candle.o else \"black\"\n",
    "        plt.plot([index, index], [candle.c, candle.o], linewidth=3, color = c)\n",
    "        plt.plot([index, index], [candle.l, candle.h], linewidth=1, color = \"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c729e82-3b29-43a4-be4e-927efbd34b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.0 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sarts = step()\n",
    "\n",
    "plot_candles(m.m1_candles)\n",
    "if(current_position.direction != 0):\n",
    "    plt.axhline(current_position.entry, color = \"g\" if current_position.direction == 1 else \"r\")\n",
    "    plt.axhline(current_position.sl, color = \"orange\")\n",
    "\n",
    "if(current_order != None):\n",
    "    plt.axhline(current_order.entry, color = \"g\" if current_order.direction == 1 else \"r\")\n",
    "    plt.axhline(current_order.sl, color = \"orange\")\n",
    "\n",
    "\n",
    "print(sarts[1], sarts[2], current_position.direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92f99f8-68df-4fbd-bc4d-218a2a43f865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd706ba5-8f9c-4889-a382-46f25bc9653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def get_target_q(next_states, rewards, terminals):\n",
    "            estimated_q_values_next = target_model(next_states)\n",
    "            q_batch = tf.math.reduce_max(estimated_q_values_next, axis=1)\n",
    "            target_q_values = q_batch * gamma * (1-terminals) + rewards\n",
    "            return target_q_values\n",
    "\n",
    "@tf.function()\n",
    "def tstep(states, masks, rewards, terminals, next_states):\n",
    "\n",
    "    target_q_values = get_target_q(next_states, rewards, terminals)\n",
    "\n",
    "    with tf.GradientTape() as t:\n",
    "        model_return = model(states, training=True)\n",
    "        mask_return = model_return * masks\n",
    "        estimated_q_values = tf.math.reduce_sum(mask_return, axis=1)\n",
    "        #print(estimated_q_values, mask_return, model_return, masks)\n",
    "        loss_e = tf.math.square(target_q_values - estimated_q_values)\n",
    "        loss = tf.reduce_mean(loss_e)\n",
    "\n",
    "\n",
    "    gradient = t.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
    "\n",
    "    return loss, tf.reduce_mean(estimated_q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c5b3f0b-f6a8-4b12-9bc1-74330da8575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    sarts = step()\n",
    "    sarts_memory.append(sarts)\n",
    "\n",
    "    if(len(sarts_memory) > batch_size):\n",
    "        #sarts_sample = random.sample(sarts_memory, batch_size)\n",
    "        \n",
    "        r = random.randint(0, len(sarts_memory) - batch_size)\n",
    "        sarts_sample = [sarts_memory[i] for i in range(r, r + batch_size)]\n",
    "\n",
    "    \n",
    "        states = [x[0] for x in sarts_sample]\n",
    "        actions = [x[1] for x in sarts_sample]\n",
    "        rewards = np.array([x[2] for x in sarts_sample], dtype=\"float32\")\n",
    "        terminals = np.array([x[3] for x in sarts_sample], dtype=\"float32\")\n",
    "        next_states = [x[4] for x in sarts_sample]\n",
    "    \n",
    "        next_states_array = []\n",
    "        for i in range(num_model_inputs):\n",
    "            next_states_array.append(np.array([x[i] for x in next_states], dtype = \"float32\"))\n",
    "    \n",
    "    \n",
    "        states_array = []\n",
    "        for i in range(num_model_inputs):\n",
    "            states_array.append(np.array([x[i] for x in states], dtype = \"float32\"))\n",
    "    \n",
    "    \n",
    "        masks = np.array(m1[actions], dtype=\"float32\")\n",
    "    \n",
    "        loss, q = tstep(states_array, masks, rewards, terminals, next_states_array)\n",
    "\n",
    "        return loss, q, sarts[2], sarts[1]\n",
    "    else :\n",
    "        return 0,0,0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b536a1d7-a655-4d08-9e9d-c8cbf420a885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ./loss\n",
      "loading ./q\n",
      "loading ./rewards\n"
     ]
    }
   ],
   "source": [
    "sarts_memory = deque(maxlen = memory_len)\n",
    "\n",
    "loss_mean = []\n",
    "q_mean = []\n",
    "rewards = []\n",
    "\n",
    "try:\n",
    "    model.load_weights(path+\"model.weights.h5\")\n",
    "    target_model.load_weights(path+\"model.weights.h5\")\n",
    "\n",
    "    loss_mean = obj_load(path+\"loss\")\n",
    "    q_mean = obj_load(path+\"q\")\n",
    "    rewards = obj_load(path+\"rewards\")\n",
    "except:\n",
    "    print(\"unable to load data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a89278c-2823-4e36-8746-908718c80748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save():\n",
    "            model.save_weights(path+\"model.weights.h5\")\n",
    "            obj_save(loss_mean, path+\"loss\")\n",
    "            obj_save(q_mean, path+\"q\")\n",
    "            obj_save(rewards, path+\"rewards\")\n",
    "            print(\"saved progress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7355fab-87a0-4bf6-9558-f6c3bcc2ac5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 28s 28ms/step - loss: 2.0023 - qv: 18.1228 - reward: -0.0048 - avg_action: 0.4390         \n",
      "  21/1000 [..............................] - ETA: 44s - loss: 1.4680 - qv: 34.9212 - reward: -0.2206 - avg_action: 0.0952    "
     ]
    }
   ],
   "source": [
    "safe_after_eps = 10\n",
    "eps_counter=0\n",
    "\n",
    "while True:\n",
    "    eps_counter+=1\n",
    "    try:\n",
    "        loss = []\n",
    "        q = []\n",
    "        rewards_tmp = []\n",
    "        actions = []\n",
    "        progbar = tf.keras.utils.Progbar(ep_len)\n",
    "        for i in range(ep_len):\n",
    "            c_loss, c_q, c_rewards, c_action = run()\n",
    "            loss.append(c_loss)\n",
    "            q.append(c_q)\n",
    "            #rewards_tmp.append(c_rewards)\n",
    "            rewards.append(c_rewards)\n",
    "            actions.append(c_action)\n",
    "\n",
    "            progbar.update(i+1, values = [(\"loss\", c_loss), (\"qv\", c_q), (\"reward\", c_rewards), (\"avg_action\", c_action)])\n",
    "\n",
    "        loss_mean.append(np.mean(loss))\n",
    "        q_mean.append(np.mean(q))\n",
    "        #rewards.append(np.mean(rewards_tmp))\n",
    "        \n",
    "        #progbar.update(ep_len, values = [(\"loss\", np.mean(loss)), (\"qv\", np.mean(q)), (\"reward\", np.mean(rewards)), (\"avg_action\", np.mean(actions))])\n",
    "\n",
    "        target_model.set_weights(model.get_weights())\n",
    "\n",
    "        if(eps_counter >= safe_after_eps):\n",
    "            eps_counter = 0\n",
    "            save()\n",
    "\n",
    "\n",
    "    except    KeyboardInterrupt:\n",
    "        print(\"\")\n",
    "        print(\"exit\")\n",
    "        save()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792e7414-ae3f-447f-bdc6-9b4ef97f5d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c09e849-898b-4636-bb36-53b91b1932da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413cb153-79a3-4643-bf57-0c50ee5af6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
