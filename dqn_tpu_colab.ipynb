{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dercodeKoenig/hft_dqn/blob/main/dqn_tpu_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge5XpxfFyLY5",
        "outputId": "6220339f-2e60-4d53-a000-3087a49b3df5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6jeBaiBXD8RZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9e16665-a7de-4be4-b11f-071bf2a08c1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'hft_dqn' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dercodeKoenig/hft_dqn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd hft_dqn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMrPWQCZUFA8",
        "outputId": "05682fe4-eaba-43a9-e0e7-a87ad48ae9a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hft_dqn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download bpwqsdd/us-futures-1-minute-candlesticks\n",
        "!unzip us-futures-1-minute-candlesticks.zip"
      ],
      "metadata": {
        "id": "ok4E21f6EDcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df50f5f6-0565-49b2-b5e6-31ee996a7d90"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/bpwqsdd/us-futures-1-minute-candlesticks\n",
            "License(s): unknown\n",
            "us-futures-1-minute-candlesticks.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  us-futures-1-minute-candlesticks.zip\n",
            "replace ES_2? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: ES_2                    \n",
            "  inflating: NQ_2                    \n",
            "  inflating: YM_2                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "import multiprocessing as mp\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from save_and_load import *\n",
        "from Candle import Candle\n",
        "from MultiTimeframeCandleManager import MultiTimeframeCandleManager\n",
        "\n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "L21glaCtURvZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "        cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"local\")\n",
        "        tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "        tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "        strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "        print(\"use tpu strategy\")\n",
        "except:\n",
        "        print(\"use gpu strategy\")\n",
        "        strategy = tf.distribute.MirroredStrategy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7bXsNCzUTJG",
        "outputId": "ef5f57d5-f476-492c-9318-01554c503565"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use tpu strategy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 0.99\n",
        "batch_size = 1024\n",
        "\n",
        "path = \"/content/drive/MyDrive/dqn_t1/\"\n",
        "\n",
        "ep_len = 1000\n",
        "\n",
        "m1 = np.eye(2, dtype=\"float32\")\n",
        "num_model_inputs = 6"
      ],
      "metadata": {
        "id": "a2VwZnVRUVAa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "\n",
        "  chart_m15 = tf.keras.layers.Input(shape = (60,4))\n",
        "  chart_m5 = tf.keras.layers.Input(shape = (60,4))\n",
        "  chart_m1 = tf.keras.layers.Input(shape = (60,4))\n",
        "\n",
        "  pdas = tf.keras.layers.Input(shape = (19,))\n",
        "\n",
        "  current_position = tf.keras.layers.Input(shape = (1,))\n",
        "  #scaled_open_profit = tf.keras.layers.Input(shape = (1,))\n",
        "\n",
        "  minutes = tf.keras.layers.Input(shape = (1,))\n",
        "  minutes_embed = tf.keras.layers.Embedding(input_dim=60*24, output_dim=8)(minutes)\n",
        "  minutes_embed_flat = tf.keras.layers.Flatten()(minutes_embed)\n",
        "\n",
        "  f15 = tf.keras.layers.Flatten()(chart_m15)\n",
        "  f5 = tf.keras.layers.Flatten()(chart_m5)\n",
        "  f1 = tf.keras.layers.Flatten()(chart_m1)\n",
        "\n",
        "  #c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, scaled_open_profit])\n",
        "  c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position])\n",
        "\n",
        "  lrelu = tf.keras.layers.LeakyReLU(0.05)\n",
        "\n",
        "  d = tf.keras.layers.Dense(1024*2)(c)\n",
        "  d = lrelu(d)\n",
        "  d = tf.keras.layers.Dense(1024*2)(d)\n",
        "  d = lrelu(d)\n",
        "\n",
        "  value = tf.keras.layers.Dense(1, activation=\"linear\")(d)\n",
        "  advantage = tf.keras.layers.Dense(2, activation=\"linear\")(d)\n",
        "\n",
        "  q_values = tf.keras.layers.Lambda(\n",
        "    lambda inputs: inputs[0] + (inputs[1] - tf.reduce_mean(inputs[1], axis=1, keepdims=True))\n",
        "  )([value, advantage])\n",
        "\n",
        "\n",
        "\n",
        "  model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = q_values)\n",
        "  target_model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = q_values)\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate = 0.000001)\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "l18Ml6uEUYpJ",
        "outputId": "2972d923-f284-49d7-8fe9-43f595426828"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │         \u001b[38;5;34m11,520\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m748\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │      \u001b[38;5;34m1,533,952\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
              "│                           │                        │                │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │      \u001b[38;5;34m4,196,352\u001b[0m │ leaky_re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │          \u001b[38;5;34m2,049\u001b[0m │ leaky_re_lu[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │          \u001b[38;5;34m4,098\u001b[0m │ leaky_re_lu[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">11,520</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">748</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,533,952</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
              "│                           │                        │                │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,196,352</span> │ leaky_re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │ leaky_re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,098</span> │ leaky_re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,747,971\u001b[0m (21.93 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,747,971</span> (21.93 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,747,971\u001b[0m (21.93 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,747,971</span> (21.93 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def relative (value, center, r):\n",
        "        return (value - center) / r\n",
        "\n",
        "def ret_to_scaled_inputs(ret):\n",
        "\n",
        "    midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
        "\n",
        "    center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
        "    r = max(1,(midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
        "\n",
        "    pda_rel = []\n",
        "    pda_rel.append(relative(midnight_open, center, r))\n",
        "    for pda in pdas:\n",
        "        pda_rel.append(relative(pda, center, r))\n",
        "    pda_np = np.array(pda_rel)\n",
        "\n",
        "    current_minutes = current_time.hour * 60 + current_time.minute\n",
        "\n",
        "    charts_array = []\n",
        "    for candlesticks in charts:\n",
        "        charts_array.append([])\n",
        "        for candle in candlesticks:\n",
        "            o = relative(candle.o, center, r)\n",
        "            h = relative(candle.h, center, r)\n",
        "            l = relative(candle.l, center, r)\n",
        "            c = relative(candle.c, center, r)\n",
        "            charts_array[-1].append([o,h,l,c])\n",
        "\n",
        "    m15_np = np.array(charts_array[0])\n",
        "    m5_np = np.array(charts_array[1])\n",
        "    m1_np = np.array(charts_array[2])\n",
        "\n",
        "    return [m15_np, m5_np, m1_np, pda_np, current_minutes]"
      ],
      "metadata": {
        "id": "FcYLtHh3Ubka"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data(candles, cmm):\n",
        "\n",
        "    m = MultiTimeframeCandleManager()\n",
        "\n",
        "    last_close = 0\n",
        "    last_state = None\n",
        "    last_action = 0\n",
        "\n",
        "    sarts = []\n",
        "\n",
        "    for index in range(len(candles)):\n",
        "\n",
        "        ret = m.push_m1_candle(candles[index])\n",
        "        midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
        "        center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
        "        r = max(1,(midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
        "\n",
        "\n",
        "        if(len(m.m15_candles) == 60):\n",
        "\n",
        "            state = ret_to_scaled_inputs(ret)\n",
        "            m15_np, m5_np, m1_np, pda_np, current_minutes = state\n",
        "\n",
        "            if(last_state != None):\n",
        "\n",
        "                terminal = 0\n",
        "                if(index+1 == len(candles)):\n",
        "                    terminal = 1\n",
        "\n",
        "                current_close = state[2][-1][3]\n",
        "                last_close = last_state[2][-1][3]\n",
        "\n",
        "                ### last position -1\n",
        "                state_short = last_state + [-1]\n",
        "                ## action was -1\n",
        "                new_state = state + [-1]\n",
        "                reward = ((current_close - last_close) * -1) / r\n",
        "                sarts.append([state_short, 0, reward, terminal, new_state])\n",
        "                ## action was 1\n",
        "                new_state = state + [1]\n",
        "                reward = ((current_close - last_close) * 1 - cmm) / r\n",
        "                sarts.append([state_short, 1, reward, terminal, new_state])\n",
        "\n",
        "\n",
        "                ### last position 1\n",
        "                state_long = last_state + [1]\n",
        "                ## action was -1\n",
        "                new_state = state + [-1]\n",
        "                reward = ((current_close - last_close) * -1 - cmm) / r\n",
        "                sarts.append([state_long, 0, reward, terminal, new_state])\n",
        "                ## action was 1\n",
        "                new_state = state + [1]\n",
        "                reward = ((current_close - last_close) * 1) / r\n",
        "                sarts.append([state_long, 1, reward, terminal, new_state])\n",
        "\n",
        "\n",
        "            last_state = state\n",
        "\n",
        "    return sarts"
      ],
      "metadata": {
        "id": "eUZyDobFUdGi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_candles(file_path, multiplier):\n",
        "    candles = obj_load(file_path)\n",
        "    return generate_data(candles, multiplier)\n",
        "\n",
        "tasks = [\n",
        "    (\"NQ_2\", 0.5),\n",
        "    (\"ES_2\", 0.5),\n",
        "    (\"YM_2\", 1.5)\n",
        "]\n",
        "\n",
        "# Create a pool of workers\n",
        "with mp.Pool(processes=len(tasks)) as pool:\n",
        "    # Map tasks to the pool\n",
        "    results = pool.starmap(process_candles, tasks)\n",
        "\n",
        "# Combine the results into sarts_memory\n",
        "sarts_memory = []\n",
        "for result in tqdm(results):\n",
        "        sarts_memory.extend(result)\n",
        "\n",
        "del results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQrqRUHMUnhE",
        "outputId": "4f86911f-0671-4520-a24d-d9801d7eec59"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loadingloadingloading   NQ_2YM_2ES_2\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.48it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sarts_memory = deque(sarts_memory)\n",
        "\n",
        "batches = []\n",
        "num_batches = int(len(sarts_memory) / batch_size)\n",
        "\n",
        "for _ in tqdm(range(num_batches)):\n",
        "\n",
        "    sarts_sample = [sarts_memory.popleft() for _ in range(batch_size)]  # Fast removal\n",
        "\n",
        "    states = [x[0] for x in sarts_sample]\n",
        "    actions = [x[1] for x in sarts_sample]\n",
        "    rewards = np.array([x[2] for x in sarts_sample], dtype=\"float32\")\n",
        "    terminals = np.array([x[3] for x in sarts_sample], dtype=\"float32\")\n",
        "    next_states = [x[4] for x in sarts_sample]\n",
        "\n",
        "    next_states_array = []\n",
        "    for i in range(num_model_inputs):\n",
        "        next_states_array.append(np.array([x[i] for x in next_states], dtype = \"float32\"))\n",
        "\n",
        "\n",
        "    states_array = []\n",
        "    for i in range(num_model_inputs):\n",
        "        states_array.append(np.array([x[i] for x in states], dtype = \"float32\"))\n",
        "\n",
        "\n",
        "    masks = np.array(m1[actions], dtype=\"float32\")\n",
        "\n",
        "    batches.append([states_array, masks, rewards, terminals, next_states_array])\n",
        "\n",
        "del sarts_memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBTYKzVh20rG",
        "outputId": "c8ef5a9e-3c3d-4b0c-cd7e-f8941f77b57b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23118/23118 [03:11<00:00, 120.57it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function()\n",
        "def get_target_q(next_states, rewards, terminals):\n",
        "            estimated_q_values_next = target_model(next_states)\n",
        "            q_batch = tf.math.reduce_max(estimated_q_values_next, axis=1)\n",
        "            target_q_values = q_batch * gamma * (1-terminals) + rewards\n",
        "            return target_q_values\n",
        "\n",
        "@tf.function()\n",
        "def tstep(data):\n",
        "    states, masks, rewards, terminals, next_states = data\n",
        "\n",
        "    target_q_values = get_target_q(next_states, rewards, terminals)\n",
        "\n",
        "    with tf.GradientTape() as t:\n",
        "        model_return = model(states, training=True)\n",
        "        mask_return = model_return * masks\n",
        "        estimated_q_values = tf.math.reduce_sum(mask_return, axis=1)\n",
        "        #print(estimated_q_values, mask_return, model_return, masks)\n",
        "        loss_e = tf.math.square(target_q_values - estimated_q_values)\n",
        "        loss = tf.reduce_mean(loss_e)\n",
        "\n",
        "\n",
        "    gradient = t.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
        "\n",
        "    return loss, tf.reduce_mean(estimated_q_values)\n",
        "\n",
        "\n",
        "batch_index = 0\n",
        "def tpu_data_get_func(_n):\n",
        "    global batch_index\n",
        "    batch_index+=1\n",
        "    if(batch_index >= len(batches)):\n",
        "        batch_index = 0\n",
        "    return batches[batch_index]\n",
        "\n",
        "\n",
        "def run():\n",
        "\n",
        "    distributed_data = (strategy.experimental_distribute_values_from_function(tpu_data_get_func))\n",
        "    loss, q = strategy.reduce(tf.distribute.ReduceOp.MEAN, strategy.run(tstep, args = (distributed_data,)), axis = None)\n",
        "\n",
        "    return loss, q"
      ],
      "metadata": {
        "id": "JPL5sfU5UhQh"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_name = \"model_small.weights.h5\"\n",
        "\n",
        "\n",
        "loss_mean = []\n",
        "q_mean = []\n",
        "\n",
        "try:\n",
        "    model.load_weights(path+model_save_name)\n",
        "    target_model.load_weights(path+model_save_name)\n",
        "    print(\"loaded weights\")\n",
        "    loss_mean = obj_load(path+\"loss\")\n",
        "    q_mean = obj_load(path+\"q\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(\"unable to load data\")\n",
        "\n",
        "def save():\n",
        "            model.save_weights(path+model_save_name)\n",
        "            obj_save(loss_mean, path+\"loss\")\n",
        "            obj_save(q_mean, path+\"q\")\n",
        "            print(\"saved progress\")\n",
        "            upload_model_to_server()\n",
        "\n",
        "\n",
        "from ftplib import FTP\n",
        "\n",
        "def upload_model_to_server():\n",
        "    # FTP server details\n",
        "    ftp_server = 'benundmarvpromotions.lima-ftp.de'\n",
        "    ftp_user = 'benundmarvpromotions'\n",
        "    ftp_password = 'gWEhrtjanrgy'\n",
        "\n",
        "    file_to_upload = path+model_save_name\n",
        "    remote_path = '/test/' + model_save_name\n",
        "\n",
        "    # Connect to the FTP server\n",
        "    ftp = FTP(ftp_server)\n",
        "    ftp.login(user=ftp_user, passwd=ftp_password)\n",
        "\n",
        "    ftp.cwd(\"/\")\n",
        "\n",
        "    # Open the file in binary mode and upload it\n",
        "    with open(file_to_upload, 'rb') as file:\n",
        "        ftp.storbinary(f'STOR {remote_path}', file, blocksize = 1024*1024)\n",
        "\n",
        "    # Close the connection\n",
        "    ftp.quit()\n",
        "\n",
        "    print(\"File uploaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MdxGBAlU7_6",
        "outputId": "5e838743-e0b7-4798-bc63-69c9accb40b7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded weights\n",
            "loading /content/drive/MyDrive/dqn_t1/loss\n",
            "loading /content/drive/MyDrive/dqn_t1/q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "safe_after_eps = 30\n",
        "eps_counter=0\n",
        "\n",
        "while True:\n",
        "    eps_counter+=1\n",
        "    try:\n",
        "        loss = []\n",
        "        q = []\n",
        "        rewards_tmp = []\n",
        "        actions = []\n",
        "        progbar = tf.keras.utils.Progbar(ep_len)\n",
        "        for i in range(ep_len):\n",
        "\n",
        "            c_loss, c_q = run()\n",
        "            loss.append(c_loss)\n",
        "            q.append(c_q)\n",
        "\n",
        "            #progbar.update(i+1, values = [(\"loss\", c_loss), (\"qv\", c_q)])\n",
        "\n",
        "        loss_mean.append(np.mean(loss))\n",
        "        q_mean.append(np.mean(q))\n",
        "\n",
        "        progbar.update(ep_len, values = [(\"loss\", np.mean(loss)), (\"qv\", np.mean(q))])\n",
        "\n",
        "        target_model.set_weights(model.get_weights())\n",
        "\n",
        "        if(eps_counter >= safe_after_eps):\n",
        "            eps_counter = 0\n",
        "            save()\n",
        "\n",
        "        if time.time() - start_time > 60*60*8.5:\n",
        "            break\n",
        "\n",
        "\n",
        "    except    KeyboardInterrupt:\n",
        "        print(\"\")\n",
        "        print(\"exit\")\n",
        "        save()\n",
        "        break\n"
      ],
      "metadata": {
        "id": "RiilLOnoVDYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a0074f-a0e1-4e84-d339-9acb16fb286e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 55ms/step - loss: 12.5641 - qv: 62.4977\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 63.9925 - qv: 48.1112\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 95.4309 - qv: 57.0879\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 883.5432 - qv: 61.0321\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 55ms/step - loss: 30.3170 - qv: 53.7789\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 54.0432 - qv: 64.0708\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 23.1816 - qv: 59.7661\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 84129.6719 - qv: 214.4107\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 68.3849 - qv: 66.0445\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 49.1753 - qv: 64.4407\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 36.2136 - qv: 62.2974\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 45.9519 - qv: 70.0846\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 23.7037 - qv: 63.3620\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 114.7903 - qv: 65.6684\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 91.9374 - qv: 76.1974\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 2180.4546 - qv: 75.8525\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 57ms/step - loss: 51.1199 - qv: 69.6485\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 66.0318 - qv: 84.5229\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 61ms/step - loss: 35.3664 - qv: 74.5470\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 61ms/step - loss: 52374.5312 - qv: 318.1510\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 56ms/step - loss: 95.6041 - qv: 86.4356\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 54.7539 - qv: 76.9326\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - loss: 76.0171 - qv: 82.8510\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 53.3470 - qv: 87.1064\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 61ms/step - loss: 35.6285 - qv: 76.5738\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 61ms/step - loss: 215.5016 - qv: 90.3911\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 4150.1328 - qv: 101.1900\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 68.1891 - qv: 79.7727\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - loss: 108.9318 - qv: 99.5871\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 58.9876 - qv: 91.8989\n",
            "saved progress\n",
            "File uploaded successfully!\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 61ms/step - loss: 5338.4390 - qv: 406.6425\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 61ms/step - loss: 54.2598 - qv: 94.2185\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 39.0292 - qv: 91.2093\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 39.8025 - qv: 83.7242\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 66.7157 - qv: 91.6194\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 34.4494 - qv: 83.3052\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 155.3354 - qv: 84.5372\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 119.7989 - qv: 97.6977\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 3622.4866 - qv: 99.2479\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 64.8495 - qv: 89.3104\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 103.4050 - qv: 106.8263\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 61ms/step - loss: 52.9151 - qv: 94.6149\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - loss: 117101.0156 - qv: 408.5367\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 100.9245 - qv: 106.3527\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 63.9465 - qv: 99.7122\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 87.9803 - qv: 97.6589\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 91.2954 - qv: 111.0571\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 61ms/step - loss: 53.9583 - qv: 95.2800\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 61ms/step - loss: 220.6237 - qv: 111.0220\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 154.1129 - qv: 121.5105\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - loss: 5703.7739 - qv: 103.5309\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 61ms/step - loss: 153.9119 - qv: 123.0393\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 55ms/step - loss: 98.1282 - qv: 118.8255\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 213793.7188 - qv: 483.7026\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 54ms/step - loss: 141.6210 - qv: 121.3420\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 61ms/step - loss: 104.9115 - qv: 119.7146\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 61.5288 - qv: 107.4927\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 104.2506 - qv: 119.0793\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 61ms/step - loss: 60.7369 - qv: 110.3832\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 61ms/step - loss: 220.2088 - qv: 109.5396\n",
            "saved progress\n",
            "File uploaded successfully!\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 177.6598 - qv: 124.3652\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 61ms/step - loss: 7208.0781 - qv: 131.3255\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 95.6358 - qv: 114.0432\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 61ms/step - loss: 163.3312 - qv: 135.6222\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 61ms/step - loss: 76.1389 - qv: 117.9689\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 61ms/step - loss: 224339.7188 - qv: 544.2053\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 54ms/step - loss: 157.6378 - qv: 133.8953\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 91.0135 - qv: 124.5114\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 95.5024 - qv: 121.5453\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 84.7128 - qv: 129.5234\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 63.1764 - qv: 119.2098\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 280.0737 - qv: 123.3127\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 282.1051 - qv: 149.2563\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - loss: 8418.9443 - qv: 123.7384\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 137.2439 - qv: 143.7683\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 137.9613 - qv: 150.4646\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 72.0746 - qv: 119.6175\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 38138.9648 - qv: 610.4744\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 61ms/step - loss: 211.4813 - qv: 150.3895\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 88.2391 - qv: 124.3807\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 54ms/step - loss: 175.2883 - qv: 145.5539\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - loss: 96.9796 - qv: 133.9160\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 56ms/step - loss: 264.6551 - qv: 133.9650\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 144.4345 - qv: 142.8013\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 61ms/step - loss: 8958.9727 - qv: 153.2356\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 82.5641 - qv: 127.0558\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 118.9194 - qv: 146.0050\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 57ms/step - loss: 58.1629 - qv: 132.5471\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 11100.7207 - qv: 558.1511\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - loss: 90.0729 - qv: 136.2384\n",
            "saved progress\n",
            "File uploaded successfully!\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 56.6600 - qv: 126.1001\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 88.7375 - qv: 120.6908\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 57ms/step - loss: 128.5494 - qv: 134.1695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9IlD1W8aVGAa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}