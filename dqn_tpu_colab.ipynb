{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "mount_file_id": "1-5RnyKtMQQDJck4hUPd6Ho6GVFrdGICJ",
      "authorship_tag": "ABX9TyNgCUHupsropVfOpIGAzLp7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dercodeKoenig/hft_dqn/blob/main/dqn_tpu_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6jeBaiBXD8RZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4824fdeb-8a60-4136-9c23-38ae9b1f3e3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'drive/.shortcut-targets-by-id': Operation canceled\n",
            "rm: cannot remove 'drive/.file-revisions-by-id': Operation canceled\n",
            "rm: cannot remove 'drive/MyDrive': Operation canceled\n",
            "rm: cannot remove 'drive/.Trash-0/files': No such file or directory\n",
            "rm: cannot remove 'drive/.Trash-0/info': No such file or directory\n",
            "rm: cannot remove 'drive/.Encrypted/.shortcut-targets-by-id': Operation canceled\n",
            "rm: cannot remove 'drive/.Encrypted/MyDrive': Operation canceled\n",
            "Cloning into 'hft_dqn'...\n",
            "remote: Enumerating objects: 143, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 143 (delta 34), reused 31 (delta 13), pack-reused 80 (from 1)\u001b[K\n",
            "Receiving objects: 100% (143/143), 61.29 MiB | 20.12 MiB/s, done.\n",
            "Resolving deltas: 100% (67/67), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -r *\n",
        "!git clone https://github.com/dercodeKoenig/hft_dqn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd hft_dqn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMrPWQCZUFA8",
        "outputId": "d3457748-db67-4aa8-8783-940573610384"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hft_dqn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download bpwqsdd/us-futures-1-minute-candlesticks\n",
        "!unzip us-futures-1-minute-candlesticks.zip"
      ],
      "metadata": {
        "id": "ok4E21f6EDcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bdbb55f-7413-4f92-e14e-e73e80f37621"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/bpwqsdd/us-futures-1-minute-candlesticks\n",
            "License(s): unknown\n",
            "Downloading us-futures-1-minute-candlesticks.zip to /content/hft_dqn\n",
            " 92% 55.0M/59.6M [00:00<00:00, 182MB/s]\n",
            "100% 59.6M/59.6M [00:00<00:00, 167MB/s]\n",
            "Archive:  us-futures-1-minute-candlesticks.zip\n",
            "  inflating: ES_2                    \n",
            "  inflating: NQ_2                    \n",
            "  inflating: YM_2                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm model2.weights.h5\n",
        "#!wget testserver.lima-city.at/model2.weights.h5"
      ],
      "metadata": {
        "id": "fCyVO7cCUOe_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "import multiprocessing as mp\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from save_and_load import *\n",
        "from Candle import Candle\n",
        "from MultiTimeframeCandleManager import MultiTimeframeCandleManager\n",
        "\n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "L21glaCtURvZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "        cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"local\")\n",
        "        tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "        tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "        strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "        print(\"use tpu strategy\")\n",
        "except:\n",
        "        print(\"use gpu strategy\")\n",
        "        strategy = tf.distribute.MirroredStrategy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7bXsNCzUTJG",
        "outputId": "67fcb770-1904-4056-bded-4b3b8c7030b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use gpu strategy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 0.99\n",
        "batch_size = 1024\n",
        "\n",
        "path = \"/content/drive/MyDrive/dqn_t1\"\n",
        "\n",
        "ep_len = 1000\n",
        "\n",
        "m1 = np.eye(2, dtype=\"float32\")\n",
        "num_model_inputs = 6"
      ],
      "metadata": {
        "id": "a2VwZnVRUVAa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "\n",
        "  chart_m15 = tf.keras.layers.Input(shape = (60,4))\n",
        "  chart_m5 = tf.keras.layers.Input(shape = (60,4))\n",
        "  chart_m1 = tf.keras.layers.Input(shape = (60,4))\n",
        "\n",
        "  pdas = tf.keras.layers.Input(shape = (19,))\n",
        "\n",
        "  current_position = tf.keras.layers.Input(shape = (1,))\n",
        "  #scaled_open_profit = tf.keras.layers.Input(shape = (1,))\n",
        "\n",
        "  minutes = tf.keras.layers.Input(shape = (1,))\n",
        "  minutes_embed = tf.keras.layers.Embedding(input_dim=60*24, output_dim=8)(minutes)\n",
        "  minutes_embed_flat = tf.keras.layers.Flatten()(minutes_embed)\n",
        "\n",
        "  f15 = tf.keras.layers.Flatten()(chart_m15)\n",
        "  f5 = tf.keras.layers.Flatten()(chart_m5)\n",
        "  f1 = tf.keras.layers.Flatten()(chart_m1)\n",
        "\n",
        "  #c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, scaled_open_profit])\n",
        "  c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position])\n",
        "\n",
        "  lrelu = tf.keras.layers.LeakyReLU(0.05)\n",
        "\n",
        "  d = tf.keras.layers.Dense(1024*2)(c)\n",
        "  d = lrelu(d)\n",
        "  d = tf.keras.layers.Dense(1024*2)(d)\n",
        "  d = lrelu(d)\n",
        "\n",
        "  value = tf.keras.layers.Dense(1, activation=\"linear\")(d)\n",
        "  advantage = tf.keras.layers.Dense(2, activation=\"linear\")(d)\n",
        "\n",
        "  q_values = tf.keras.layers.Lambda(\n",
        "    lambda inputs: inputs[0] + (inputs[1] - tf.reduce_mean(inputs[1], axis=1, keepdims=True))\n",
        "  )([value, advantage])\n",
        "\n",
        "\n",
        "\n",
        "  model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = q_values)\n",
        "  target_model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = q_values)\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate = 0.000001)\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "l18Ml6uEUYpJ",
        "outputId": "c4e50fb1-12cf-4f4c-de56-b7b79cafbc74"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │         \u001b[38;5;34m11,520\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m748\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │      \u001b[38;5;34m1,533,952\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
              "│                           │                        │                │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │      \u001b[38;5;34m4,196,352\u001b[0m │ leaky_re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │          \u001b[38;5;34m2,049\u001b[0m │ leaky_re_lu[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │          \u001b[38;5;34m4,098\u001b[0m │ leaky_re_lu[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">11,520</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">748</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,533,952</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
              "│                           │                        │                │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,196,352</span> │ leaky_re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │ leaky_re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,098</span> │ leaky_re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,747,971\u001b[0m (21.93 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,747,971</span> (21.93 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,747,971\u001b[0m (21.93 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,747,971</span> (21.93 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def relative (value, center, r):\n",
        "        return (value - center) / r\n",
        "\n",
        "def ret_to_scaled_inputs(ret):\n",
        "\n",
        "    midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
        "\n",
        "    center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
        "    r = max(1,(midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
        "\n",
        "    pda_rel = []\n",
        "    pda_rel.append(relative(midnight_open, center, r))\n",
        "    for pda in pdas:\n",
        "        pda_rel.append(relative(pda, center, r))\n",
        "    pda_np = np.array(pda_rel)\n",
        "\n",
        "    current_minutes = current_time.hour * 60 + current_time.minute\n",
        "\n",
        "    charts_array = []\n",
        "    for candlesticks in charts:\n",
        "        charts_array.append([])\n",
        "        for candle in candlesticks:\n",
        "            o = relative(candle.o, center, r)\n",
        "            h = relative(candle.h, center, r)\n",
        "            l = relative(candle.l, center, r)\n",
        "            c = relative(candle.c, center, r)\n",
        "            charts_array[-1].append([o,h,l,c])\n",
        "\n",
        "    m15_np = np.array(charts_array[0])\n",
        "    m5_np = np.array(charts_array[1])\n",
        "    m1_np = np.array(charts_array[2])\n",
        "\n",
        "    return [m15_np, m5_np, m1_np, pda_np, current_minutes]"
      ],
      "metadata": {
        "id": "FcYLtHh3Ubka"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data(candles, cmm):\n",
        "\n",
        "    m = MultiTimeframeCandleManager()\n",
        "\n",
        "    last_close = 0\n",
        "    last_state = None\n",
        "    last_action = 0\n",
        "\n",
        "    sarts = []\n",
        "\n",
        "    for index in range(len(candles)):\n",
        "\n",
        "        ret = m.push_m1_candle(candles[index])\n",
        "        midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
        "        center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
        "        r = max(1,(midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
        "\n",
        "\n",
        "        if(len(m.m15_candles) == 60):\n",
        "\n",
        "            state = ret_to_scaled_inputs(ret)\n",
        "            m15_np, m5_np, m1_np, pda_np, current_minutes = state\n",
        "\n",
        "            if(last_state != None):\n",
        "\n",
        "                terminal = 0\n",
        "                if(index+1 == len(candles)):\n",
        "                    terminal = 1\n",
        "\n",
        "                current_close = state[2][-1][3]\n",
        "                last_close = last_state[2][-1][3]\n",
        "\n",
        "                ### last position -1\n",
        "                state_short = last_state + [-1]\n",
        "                ## action was -1\n",
        "                new_state = state + [-1]\n",
        "                reward = ((current_close - last_close) * -1) / r\n",
        "                sarts.append([state_short, 0, reward, terminal, new_state])\n",
        "                ## action was 1\n",
        "                new_state = state + [1]\n",
        "                reward = ((current_close - last_close) * 1 - cmm) / r\n",
        "                sarts.append([state_short, 1, reward, terminal, new_state])\n",
        "\n",
        "\n",
        "                ### last position 1\n",
        "                state_long = last_state + [1]\n",
        "                ## action was -1\n",
        "                new_state = state + [-1]\n",
        "                reward = ((current_close - last_close) * -1 - cmm) / r\n",
        "                sarts.append([state_long, 0, reward, terminal, new_state])\n",
        "                ## action was 1\n",
        "                new_state = state + [1]\n",
        "                reward = ((current_close - last_close) * 1) / r\n",
        "                sarts.append([state_long, 1, reward, terminal, new_state])\n",
        "\n",
        "\n",
        "            last_state = state\n",
        "\n",
        "    return sarts"
      ],
      "metadata": {
        "id": "eUZyDobFUdGi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_candles(file_path, multiplier):\n",
        "    candles = obj_load(file_path)\n",
        "    return generate_data(candles, multiplier)\n",
        "\n",
        "tasks = [\n",
        "    (\"NQ_2\", 0.5),\n",
        "    (\"ES_2\", 0.5),\n",
        "    (\"YM_2\", 1.5)\n",
        "]\n",
        "\n",
        "# Create a pool of workers\n",
        "with mp.Pool(processes=len(tasks)) as pool:\n",
        "    # Map tasks to the pool\n",
        "    results = pool.starmap(process_candles, tasks)\n",
        "\n",
        "# Combine the results into sarts_memory\n",
        "sarts_memory = []\n",
        "for result in tqdm(results):\n",
        "        sarts_memory.extend(result)\n",
        "\n",
        "#sarts_memory = np.array(sarts_memory, dtype=\"object\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQrqRUHMUnhE",
        "outputId": "0e2dfdc9-f613-4497-b8de-760f022fc043"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loadingloadingloading   ES_2NQ_2\n",
            "YM_2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 317.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batches = []\n",
        "for i in tqdm(range(int(len(sarts_memory) / batch_size))):\n",
        "\n",
        "    sarts_sample = sarts_memory[i*batch_size:(i+1)*batch_size]\n",
        "\n",
        "\n",
        "    states = [x[0] for x in sarts_sample]\n",
        "    actions = [x[1] for x in sarts_sample]\n",
        "    rewards = np.array([x[2] for x in sarts_sample], dtype=\"float32\")\n",
        "    terminals = np.array([x[3] for x in sarts_sample], dtype=\"float32\")\n",
        "    next_states = [x[4] for x in sarts_sample]\n",
        "\n",
        "    next_states_array = []\n",
        "    for i in range(num_model_inputs):\n",
        "        next_states_array.append(np.array([x[i] for x in next_states], dtype = \"float32\"))\n",
        "\n",
        "\n",
        "    states_array = []\n",
        "    for i in range(num_model_inputs):\n",
        "        states_array.append(np.array([x[i] for x in states], dtype = \"float32\"))\n",
        "\n",
        "\n",
        "    masks = np.array(m1[actions], dtype=\"float32\")\n",
        "\n",
        "    batches.append([states_array, masks, rewards, terminals, next_states_array])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJdwHcuoU4iw",
        "outputId": "eee290eb-2a52-4bb7-a35c-4c00902ec1a9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 107/107 [00:02<00:00, 52.96it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function()\n",
        "def get_target_q(next_states, rewards, terminals):\n",
        "            estimated_q_values_next = target_model(next_states)\n",
        "            q_batch = tf.math.reduce_max(estimated_q_values_next, axis=1)\n",
        "            target_q_values = q_batch * gamma * (1-terminals) + rewards\n",
        "            return target_q_values\n",
        "\n",
        "@tf.function()\n",
        "def tstep(data):\n",
        "    states, masks, rewards, terminals, next_states = data\n",
        "\n",
        "    target_q_values = get_target_q(next_states, rewards, terminals)\n",
        "\n",
        "    with tf.GradientTape() as t:\n",
        "        model_return = model(states, training=True)\n",
        "        mask_return = model_return * masks\n",
        "        estimated_q_values = tf.math.reduce_sum(mask_return, axis=1)\n",
        "        #print(estimated_q_values, mask_return, model_return, masks)\n",
        "        loss_e = tf.math.square(target_q_values - estimated_q_values)\n",
        "        loss = tf.reduce_mean(loss_e)\n",
        "\n",
        "\n",
        "    gradient = t.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
        "\n",
        "    return loss, tf.reduce_mean(estimated_q_values)\n",
        "\n",
        "\n",
        "batch_index = 0\n",
        "def tpu_data_get_func(_n):\n",
        "    global batch_index\n",
        "    batch_index+=1\n",
        "    if(batch_index >= len(batches)):\n",
        "        batch_index = 0\n",
        "    return batches[batch_index]\n",
        "\n",
        "\n",
        "def run():\n",
        "\n",
        "    distributed_data = (strategy.experimental_distribute_values_from_function(tpu_data_get_func))\n",
        "    loss, q = strategy.reduce(tf.distribute.ReduceOp.MEAN, strategy.run(tstep, args = (distributed_data,)), axis = None)\n",
        "\n",
        "    return loss, q"
      ],
      "metadata": {
        "id": "JPL5sfU5UhQh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_name = \"model_small.weights.h5\"\n",
        "\n",
        "\n",
        "loss_mean = []\n",
        "q_mean = []\n",
        "\n",
        "try:\n",
        "    model.load_weights(path+model_save_name)\n",
        "    target_model.load_weights(path+model_save_name)\n",
        "    print(\"loaded weights\")\n",
        "    loss_mean = obj_load(path+\"loss\")\n",
        "    q_mean = obj_load(path+\"q\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(\"unable to load data\")\n",
        "\n",
        "def save():\n",
        "            model.save_weights(path+model_save_name)\n",
        "            obj_save(loss_mean, path+\"loss\")\n",
        "            obj_save(q_mean, path+\"q\")\n",
        "            print(\"saved progress\")\n",
        "            upload_model_to_server()\n",
        "\n",
        "\n",
        "from ftplib import FTP\n",
        "\n",
        "def upload_model_to_server():\n",
        "    # FTP server details\n",
        "    ftp_server = 'benundmarvpromotions.lima-ftp.de'\n",
        "    ftp_user = 'benundmarvpromotions'\n",
        "    ftp_password = 'gWEhrtjanrgy'\n",
        "\n",
        "    file_to_upload = path+model_save_name\n",
        "    remote_path = '/test/' + model_save_name\n",
        "\n",
        "    # Connect to the FTP server\n",
        "    ftp = FTP(ftp_server)\n",
        "    ftp.login(user=ftp_user, passwd=ftp_password)\n",
        "\n",
        "    ftp.cwd(\"/\")\n",
        "\n",
        "    # Open the file in binary mode and upload it\n",
        "    with open(file_to_upload, 'rb') as file:\n",
        "        ftp.storbinary(f'STOR {remote_path}', file, blocksize = 1024*1024)\n",
        "\n",
        "    # Close the connection\n",
        "    ftp.quit()\n",
        "\n",
        "    print(\"File uploaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MdxGBAlU7_6",
        "outputId": "6bf30363-33a4-4d23-b162-d0ae6a0efb45"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] Unable to synchronously open file (unable to open file: name = '/content/drive/MyDrive/dqn_t1model_small.weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
            "unable to load data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "safe_after_eps = 30\n",
        "eps_counter=0\n",
        "\n",
        "while True:\n",
        "    eps_counter+=1\n",
        "    try:\n",
        "        loss = []\n",
        "        q = []\n",
        "        rewards_tmp = []\n",
        "        actions = []\n",
        "        progbar = tf.keras.utils.Progbar(ep_len)\n",
        "        for i in range(ep_len):\n",
        "\n",
        "            c_loss, c_q = run()\n",
        "            loss.append(c_loss)\n",
        "            q.append(c_q)\n",
        "\n",
        "            #progbar.update(i+1, values = [(\"loss\", c_loss), (\"qv\", c_q)])\n",
        "\n",
        "        loss_mean.append(np.mean(loss))\n",
        "        q_mean.append(np.mean(q))\n",
        "\n",
        "        progbar.update(ep_len, values = [(\"loss\", np.mean(loss)), (\"qv\", np.mean(q))])\n",
        "\n",
        "        target_model.set_weights(model.get_weights())\n",
        "\n",
        "        if(eps_counter >= safe_after_eps):\n",
        "            eps_counter = 0\n",
        "            save()\n",
        "\n",
        "        if time.time() - start_time > 60*60*8.5:\n",
        "            break\n",
        "\n",
        "\n",
        "    except    KeyboardInterrupt:\n",
        "        print(\"\")\n",
        "        print(\"exit\")\n",
        "        save()\n",
        "        break\n"
      ],
      "metadata": {
        "id": "RiilLOnoVDYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9IlD1W8aVGAa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}