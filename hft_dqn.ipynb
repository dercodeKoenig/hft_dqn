{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMRtKNIVIPohLPS21pI4UWf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dercodeKoenig/hft_dqn/blob/main/hft_dqn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEZsUGPF3rme",
        "outputId": "eb273c92-9970-4ba2-fbe3-9d2808a6da8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hft_dqn'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 57 (delta 22), reused 47 (delta 15), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (57/57), 3.90 MiB | 3.15 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dercodeKoenig/hft_dqn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd hft_dqn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeM0pqhE6hwP",
        "outputId": "42ddd0c7-dffd-4936-b739-46e072c80ac9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hft_dqn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPtx1rCj3yB9",
        "outputId": "be9f8a62-fd6d-4de1-fc43-42b64955b291"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "import copy\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from save_and_load import *\n",
        "from Candle import Candle\n",
        "from MultiTimeframeCandleManager import MultiTimeframeCandleManager\n",
        "\n",
        "candles = obj_load(\"NQ_1\")\n",
        "len(candles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lYYICMk4TtN",
        "outputId": "eaedf981-e4a3-436e-cc77-cdf88b1a336b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading NQ_1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 0.99\n",
        "memory_len = 50000\n",
        "batch_size = 64\n",
        "\n",
        "ep_len = 1000\n",
        "\n",
        "m1 = np.eye(2, dtype=\"float32\")\n",
        "num_model_inputs = 7\n"
      ],
      "metadata": {
        "id": "oxQB14ka4VP1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chart_m15 = tf.keras.layers.Input(shape = (60,4))\n",
        "chart_m5 = tf.keras.layers.Input(shape = (60,4))\n",
        "chart_m1 = tf.keras.layers.Input(shape = (60,4))\n",
        "\n",
        "pdas = tf.keras.layers.Input(shape = (10,))\n",
        "\n",
        "current_position = tf.keras.layers.Input(shape = (1,))\n",
        "scaled_open_profit = tf.keras.layers.Input(shape = (1,))\n",
        "\n",
        "minutes = tf.keras.layers.Input(shape = (1,))\n",
        "minutes_embed = tf.keras.layers.Embedding(input_dim=60*24, output_dim=8)(minutes)\n",
        "minutes_embed_flat = tf.keras.layers.Flatten()(minutes_embed)\n",
        "\n",
        "f15 = tf.keras.layers.Flatten()(chart_m15)\n",
        "f5 = tf.keras.layers.Flatten()(chart_m5)\n",
        "f1 = tf.keras.layers.Flatten()(chart_m1)\n",
        "\n",
        "c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, scaled_open_profit])\n",
        "\n",
        "d = tf.keras.layers.Dense(1024, \"tanh\")(c)\n",
        "d = tf.keras.layers.Dense(1024, \"relu\")(d)\n",
        "\n",
        "o = tf.keras.layers.Dense(2, \"linear\")(d)\n",
        "\n",
        "model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position, scaled_open_profit], outputs = o)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "bvbm7PEH4Vyr",
        "outputId": "684d6430-15a4-4c21-a637-1a04b7ff2db4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │         \u001b[38;5;34m11,520\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m740\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ input_layer_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │        \u001b[38;5;34m758,784\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m1,049,600\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │          \u001b[38;5;34m2,050\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">11,520</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">740</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">758,784</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,050</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,821,954\u001b[0m (6.95 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,821,954</span> (6.95 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,821,954\u001b[0m (6.95 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,821,954</span> (6.95 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)"
      ],
      "metadata": {
        "id": "FXpvSeUFYo1R"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def relative (value, center, r):\n",
        "        return (value - center) / r\n",
        "\n",
        "def ret_to_scaled_inputs(ret):\n",
        "\n",
        "    midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
        "\n",
        "    center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
        "    r = (midnight_opening_range_high - midnight_opening_range_low) / 2\n",
        "\n",
        "    pda_rel = []\n",
        "    pda_rel.append(relative(midnight_open, center, r))\n",
        "    for pda in pdas:\n",
        "        pda_rel.append(relative(pda, center, r))\n",
        "    pda_np = np.array(pda_rel)\n",
        "\n",
        "    current_minutes = current_time.hour * 60 + current_time.minute\n",
        "\n",
        "    charts_array = []\n",
        "    for candlesticks in charts:\n",
        "        charts_array.append([])\n",
        "        for candle in candlesticks:\n",
        "            o = relative(candle.o, center, r)\n",
        "            h = relative(candle.h, center, r)\n",
        "            l = relative(candle.l, center, r)\n",
        "            c = relative(candle.c, center, r)\n",
        "            charts_array[-1].append([o,h,l,c])\n",
        "\n",
        "    m15_np = np.array(charts_array[0])\n",
        "    m5_np = np.array(charts_array[1])\n",
        "    m1_np = np.array(charts_array[2])\n",
        "\n",
        "    return [m15_np, m5_np, m1_np, pda_np, current_minutes]"
      ],
      "metadata": {
        "id": "38Z6e4Ue6I87"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = MultiTimeframeCandleManager()\n",
        "\n",
        "current_position = 0\n",
        "entry_price = 0\n",
        "\n",
        "equity = 0\n",
        "open_profit = 0\n",
        "equity_L = [0]\n",
        "\n",
        "cmm = 0.5\n",
        "\n",
        "last_close = 0\n",
        "last_state = None\n",
        "last_action = 0\n",
        "\n",
        "index = 0\n",
        "\n",
        "def step():\n",
        "\n",
        "    global index, last_close, last_state, last_action, current_position, entry_price, equity\n",
        "\n",
        "\n",
        "    sarts = None\n",
        "    while  sarts == None:\n",
        "\n",
        "        ret = m.push_m1_candle(candles[index])\n",
        "        midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
        "        center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
        "        r = (midnight_opening_range_high - midnight_opening_range_low) / 2\n",
        "\n",
        "\n",
        "        if(len(m.m15_candles) == 60):\n",
        "\n",
        "            open_profit = (current_close - entry_price) * current_position\n",
        "            scaled_open_profit = open_profit / r\n",
        "\n",
        "            state = ret_to_scaled_inputs(ret) + [current_position, scaled_open_profit]\n",
        "            m15_np, m5_np, m1_np, pda_np, current_minutes, pos, open_profit = state\n",
        "\n",
        "            if(last_state != None):\n",
        "                diff = (equity+open_profit) - equity_L[-1]\n",
        "                equity_L.append(equity+open_profit)\n",
        "                reward =  (diff) / r\n",
        "                terminal = 0\n",
        "                if(index+1 == len(candles)):\n",
        "                    terminal = 1\n",
        "\n",
        "                sarts = last_state, last_action, reward, terminal, state\n",
        "\n",
        "\n",
        "            output = model([\n",
        "                tf.expand_dims(m15_np, 0),\n",
        "                tf.expand_dims(m5_np, 0),\n",
        "                tf.expand_dims(m1_np, 0),\n",
        "                tf.expand_dims(pda_np, 0),\n",
        "                tf.expand_dims(current_minutes, 0),\n",
        "                tf.expand_dims(pos, 0),\n",
        "                tf.expand_dims(open_profit, 0),\n",
        "            ])\n",
        "\n",
        "            last_action = np.argmax(output)\n",
        "            last_close = current_close\n",
        "            last_state = state\n",
        "\n",
        "\n",
        "            if(last_action == 0 and current_position != -1):\n",
        "                equity += open_profit\n",
        "                #print(\"short at\", current_close, \" last position return:\", open_profit, \" equity:\", equity)\n",
        "                current_position = -1\n",
        "                entry_price = current_close\n",
        "                equity -= cmm\n",
        "\n",
        "            if(last_action == 1 and current_position != 1):\n",
        "                equity += open_profit\n",
        "                #print(\"long at\", current_close, \" last position return:\", open_profit, \" equity:\", equity)\n",
        "                current_position = 1\n",
        "                entry_price = current_close\n",
        "                equity -= cmm\n",
        "\n",
        "\n",
        "\n",
        "        index += 1\n",
        "        if(index == len(candles)):\n",
        "            index = 0\n",
        "            current_position = 0\n",
        "            entry_price = 0\n",
        "            last_close = 0\n",
        "            last_state = None\n",
        "            last_action = 0\n",
        "            print(\"env reset\")\n",
        "\n",
        "    return sarts"
      ],
      "metadata": {
        "id": "aVzGqTFD6LjG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function(reduce_retracing=True)\n",
        "def get_target_q(next_states, rewards, terminals):\n",
        "            estimated_q_values_next = model(next_states)\n",
        "            q_batch = tf.math.reduce_max(estimated_q_values_next, axis=1)\n",
        "            target_q_values = q_batch * gamma * (1-terminals) + rewards\n",
        "            return target_q_values\n",
        "\n",
        "@tf.function(reduce_retracing=True)\n",
        "def tstep(states, masks, rewards, terminals, next_states):\n",
        "\n",
        "    target_q_values = get_target_q(next_states, rewards, terminals)\n",
        "\n",
        "    with tf.GradientTape() as t:\n",
        "        model_return = model(states, training=True)\n",
        "        mask_return = model_return * masks\n",
        "        estimated_q_values = tf.math.reduce_sum(mask_return, axis=1)\n",
        "        #print(estimated_q_values, mask_return, model_return, masks)\n",
        "        loss_e = tf.math.square(target_q_values - estimated_q_values)\n",
        "        loss = tf.reduce_mean(loss_e)\n",
        "\n",
        "\n",
        "    gradient = t.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
        "\n",
        "    return loss, tf.reduce_mean(estimated_q_values)"
      ],
      "metadata": {
        "id": "acX4Ztg86Ly9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run():\n",
        "    sarts = step()\n",
        "    sarts_memory.append(sarts)\n",
        "\n",
        "    sarts_sample = random.sample(sarts_memory, min(batch_size, len(sarts_memory)))\n",
        "\n",
        "    states = [x[0] for x in sarts_sample]\n",
        "    actions = [x[1] for x in sarts_sample]\n",
        "    rewards = np.array([x[2] for x in sarts_sample], dtype=\"float32\")\n",
        "    terminals = np.array([x[3] for x in sarts_sample], dtype=\"float32\")\n",
        "    next_states = [x[4] for x in sarts_sample]\n",
        "\n",
        "    next_states_array = []\n",
        "    for i in range(num_model_inputs):\n",
        "        next_states_array.append(np.array([x[i] for x in next_states], dtype = \"float32\"))\n",
        "\n",
        "\n",
        "    states_array = []\n",
        "    for i in range(num_model_inputs):\n",
        "        states_array.append(np.array([x[i] for x in states], dtype = \"float32\"))\n",
        "\n",
        "\n",
        "    masks = np.array(m1[actions], dtype=\"float32\")\n",
        "\n",
        "    loss, q = tstep(states_array, masks, rewards, terminals, next_states_array)\n",
        "\n",
        "    return loss, q, sarts[2], sarts[1]"
      ],
      "metadata": {
        "id": "csDW9UAK6Nre"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sarts_memory = deque(maxlen = memory_len)\n",
        "\n",
        "loss_mean = []\n",
        "q_mean = []\n",
        "rewards_mean = []\n",
        "\n",
        "for _ in range(100):\n",
        "    loss = []\n",
        "    q = []\n",
        "    rewards = []\n",
        "    progbar = tf.keras.utils.Progbar(ep_len)\n",
        "    for i in range(ep_len):\n",
        "        c_loss, c_q, c_rewards, c_action = run()\n",
        "        loss.append(c_loss)\n",
        "        q.append(c_q)\n",
        "        rewards.append(c_rewards)\n",
        "\n",
        "        progbar.update(i+1, values = [(\"loss\", c_loss), (\"qv\", c_q), (\"reward\", c_rewards), (\"avg_action\", c_action)])\n",
        "\n",
        "    loss_mean.append(np.mean(loss))\n",
        "    q_mean.append(np.mean(q))\n",
        "    rewards_mean.append(np.mean(rewards))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sAeWJZ96OvG",
        "outputId": "32be88d4-9ebe-44b3-d330-815d6df53412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 80ms/step - loss: 0.0885 - qv: 3.8926 - reward: -0.0152 - avg_action: 0.3890\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - loss: 0.0900 - qv: 4.6627 - reward: -0.0126 - avg_action: 0.4300\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - loss: 0.6154 - qv: 7.1065 - reward: -0.0115 - avg_action: 0.3070\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 79ms/step - loss: 0.1007 - qv: 5.6358 - reward: -0.0248 - avg_action: 0.4910\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 77ms/step - loss: 0.0703 - qv: 4.4526 - reward: -0.0216 - avg_action: 0.4960\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 80ms/step - loss: 0.0562 - qv: 4.6017 - reward: -0.0145 - avg_action: 0.5030\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - loss: 0.0547 - qv: 4.3726 - reward: -0.0023 - avg_action: 0.3290\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - loss: 0.0549 - qv: 4.3556 - reward: -0.0095 - avg_action: 0.4820\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - loss: 0.0470 - qv: 3.7456 - reward: 0.0029 - avg_action: 0.3860\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 72ms/step - loss: 0.0434 - qv: 3.7248 - reward: -0.0054 - avg_action: 0.4730\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 72ms/step - loss: 0.0410 - qv: 3.4979 - reward: -0.0123 - avg_action: 0.5560\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 72ms/step - loss: 0.0353 - qv: 2.8117 - reward: -0.0143 - avg_action: 0.5870\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 72ms/step - loss: 0.0347 - qv: 2.3178 - reward: -0.0046 - avg_action: 0.4590\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 75ms/step - loss: 0.0316 - qv: 1.7709 - reward: -0.0040 - avg_action: 0.5640\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 72ms/step - loss: 0.0298 - qv: 1.6574 - reward: -0.0018 - avg_action: 0.5070\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 74ms/step - loss: 0.0283 - qv: 1.6038 - reward: -0.0049 - avg_action: 0.3370\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 72ms/step - loss: 0.0252 - qv: 1.4683 - reward: -0.0130 - avg_action: 0.6090\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - loss: 0.0317 - qv: 1.6810 - reward: -0.0098 - avg_action: 0.5130\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - loss: 0.0252 - qv: 1.1484 - reward: -0.0083 - avg_action: 0.5340\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 72ms/step - loss: 0.0256 - qv: 1.2005 - reward: -0.0046 - avg_action: 0.5070\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - loss: 0.1232 - qv: 4.5186 - reward: -0.0048 - avg_action: 0.4630\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 72ms/step - loss: 0.0304 - qv: 1.7319 - reward: -0.0019 - avg_action: 0.5290\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 72ms/step - loss: 0.0267 - qv: 1.2347 - reward: -7.6839e-04 - avg_action: 0.5060\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - loss: 0.0258 - qv: 1.4142 - reward: -0.0091 - avg_action: 0.2600\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 70ms/step - loss: 0.0252 - qv: 1.3625 - reward: -0.0049 - avg_action: 0.1890\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 69ms/step - loss: 0.0258 - qv: 1.4294 - reward: -0.0069 - avg_action: 0.3100\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 72ms/step - loss: 0.0253 - qv: 1.5997 - reward: -0.0064 - avg_action: 0.4140\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 74ms/step - loss: 0.0224 - qv: 1.3011 - reward: -0.0038 - avg_action: 0.4240\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 72ms/step - loss: 0.0216 - qv: 1.3981 - reward: -0.0096 - avg_action: 0.4420\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - loss: 0.0200 - qv: 1.2113 - reward: -0.0029 - avg_action: 0.6110\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 77ms/step - loss: 0.0334 - qv: 2.4470 - reward: -0.0028 - avg_action: 0.6090\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 78ms/step - loss: 0.0218 - qv: 1.1510 - reward: 0.0029 - avg_action: 0.5310\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 83ms/step - loss: 0.0251 - qv: 1.2712 - reward: 6.6760e-04 - avg_action: 0.5360\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 82ms/step - loss: 0.0217 - qv: 1.4203 - reward: -0.0043 - avg_action: 0.4350\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 84ms/step - loss: 0.0248 - qv: 1.5564 - reward: -0.0048 - avg_action: 0.4000\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 83ms/step - loss: 0.0215 - qv: 1.1282 - reward: -0.0189 - avg_action: 0.5780\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 81ms/step - loss: 0.0384 - qv: 3.0830 - reward: -0.0063 - avg_action: 0.4460\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 82ms/step - loss: 0.0212 - qv: 1.9093 - reward: -0.0052 - avg_action: 0.5730\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 83ms/step - loss: 0.0206 - qv: 1.5032 - reward: -0.0033 - avg_action: 0.3970\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 78ms/step - loss: 0.0215 - qv: 1.1983 - reward: -0.0074 - avg_action: 0.5620\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 80ms/step - loss: 0.0269 - qv: 1.5368 - reward: -0.0079 - avg_action: 0.5250\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 81ms/step - loss: 0.0231 - qv: 1.5614 - reward: -0.0029 - avg_action: 0.4850\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 82ms/step - loss: 0.0228 - qv: 1.3813 - reward: -0.0050 - avg_action: 0.4190\n",
            "\u001b[1m  14/1000\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35\u001b[0m 97ms/step - loss: 0.0143 - qv: 1.7139 - reward: -0.0224 - avg_action: 0.9286"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(equity_L)\n",
        "equity"
      ],
      "metadata": {
        "id": "GSYnf6FC6P4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vlJjQSh76bP7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}