{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PEZsUGPF3rme",
    "outputId": "31dce657-8741-49e0-e6ab-2a46287ce9be"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/dercodeKoenig/hft_dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FeM0pqhE6hwP",
    "outputId": "2d233b9f-7293-4f95-f86a-dfba5ed37b9a"
   },
   "outputs": [],
   "source": [
    "#%cd hft_dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPtx1rCj3yB9",
    "outputId": "a469cc39-52bb-4088-e9b5-3a545ad72964"
   },
   "outputs": [],
   "source": [
    "#!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0lYYICMk4TtN",
    "outputId": "2119ba6f-4728-4290-8da0-e32b6c77e2bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading NQ_1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "850000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from save_and_load import *\n",
    "from Candle import Candle\n",
    "from MultiTimeframeCandleManager import MultiTimeframeCandleManager\n",
    "\n",
    "candles = obj_load(\"NQ_1\")\n",
    "len(candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oxQB14ka4VP1"
   },
   "outputs": [],
   "source": [
    "gamma = 0.95\n",
    "memory_len = 100000\n",
    "batch_size = 512\n",
    "e = -1\n",
    "\n",
    "\n",
    "ep_len = 1000\n",
    "\n",
    "m1 = np.eye(2, dtype=\"float32\")\n",
    "num_model_inputs = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 929
    },
    "id": "bvbm7PEH4Vyr",
    "outputId": "8cfe3131-8246-4e22-9206-2d3ceb857d30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 8)         11520       ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 240)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 240)          0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 240)          0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 19)]         0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 8)            0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 749)          0           ['flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]',              \n",
      "                                                                  'flatten_3[0][0]',              \n",
      "                                                                  'input_4[0][0]',                \n",
      "                                                                  'flatten[0][0]',                \n",
      "                                                                  'input_5[0][0]',                \n",
      "                                                                  'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4096)         3072000     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 4096)         0           ['dense[0][0]',                  \n",
      "                                                                  'dense_1[0][0]',                \n",
      "                                                                  'dense_2[0][0]',                \n",
      "                                                                  'dense_3[0][0]',                \n",
      "                                                                  'dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4096)         16781312    ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 4096)         16781312    ['leaky_re_lu[1][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 4096)         16781312    ['leaky_re_lu[2][0]']            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 4096)         16781312    ['leaky_re_lu[3][0]']            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 2)            8194        ['leaky_re_lu[4][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 70,216,962\n",
      "Trainable params: 70,216,962\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "chart_m15 = tf.keras.layers.Input(shape = (60,4))\n",
    "chart_m5 = tf.keras.layers.Input(shape = (60,4))\n",
    "chart_m1 = tf.keras.layers.Input(shape = (60,4))\n",
    "\n",
    "pdas = tf.keras.layers.Input(shape = (19,))\n",
    "\n",
    "current_position = tf.keras.layers.Input(shape = (1,))\n",
    "scaled_open_profit = tf.keras.layers.Input(shape = (1,))\n",
    "\n",
    "minutes = tf.keras.layers.Input(shape = (1,))\n",
    "minutes_embed = tf.keras.layers.Embedding(input_dim=60*24, output_dim=8)(minutes)\n",
    "minutes_embed_flat = tf.keras.layers.Flatten()(minutes_embed)\n",
    "\n",
    "f15 = tf.keras.layers.Flatten()(chart_m15)\n",
    "f5 = tf.keras.layers.Flatten()(chart_m5)\n",
    "f1 = tf.keras.layers.Flatten()(chart_m1)\n",
    "\n",
    "c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, scaled_open_profit])\n",
    "\n",
    "lrelu = tf.keras.layers.LeakyReLU(0.1)\n",
    "d = tf.keras.layers.Dense(4096)(c)\n",
    "d = lrelu(d)\n",
    "d = tf.keras.layers.Dense(4096)(d)\n",
    "d = lrelu(d)\n",
    "d = tf.keras.layers.Dense(4096)(d)\n",
    "d = lrelu(d)\n",
    "d = tf.keras.layers.Dense(4096)(d)\n",
    "d = lrelu(d)\n",
    "d = tf.keras.layers.Dense(4096)(d)\n",
    "d = lrelu(d)\n",
    "\n",
    "o = tf.keras.layers.Dense(2, \"linear\")(d)\n",
    "\n",
    "model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position, scaled_open_profit], outputs = o)\n",
    "target_model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position, scaled_open_profit], outputs = o)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FXpvSeUFYo1R"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2RkJZHJWXkGY",
    "outputId": "8037803c-cfb3-43b7-aa45-06aa5a2830ad"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_weights(\"model.weights.h5\")\n",
    "    target_model.load_weights(\"model.weights.h5\")\n",
    "except:\n",
    "    print(\"unable to load weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "38Z6e4Ue6I87"
   },
   "outputs": [],
   "source": [
    "\n",
    "def relative (value, center, r):\n",
    "        return (value - center) / r\n",
    "\n",
    "def ret_to_scaled_inputs(ret):\n",
    "\n",
    "    midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "\n",
    "    center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
    "    r = (midnight_opening_range_high - midnight_opening_range_low) / 2\n",
    "\n",
    "    pda_rel = []\n",
    "    pda_rel.append(relative(midnight_open, center, r))\n",
    "    for pda in pdas:\n",
    "        pda_rel.append(relative(pda, center, r))\n",
    "    pda_np = np.array(pda_rel)\n",
    "\n",
    "    current_minutes = current_time.hour * 60 + current_time.minute\n",
    "\n",
    "    charts_array = []\n",
    "    for candlesticks in charts:\n",
    "        charts_array.append([])\n",
    "        for candle in candlesticks:\n",
    "            o = relative(candle.o, center, r)\n",
    "            h = relative(candle.h, center, r)\n",
    "            l = relative(candle.l, center, r)\n",
    "            c = relative(candle.c, center, r)\n",
    "            charts_array[-1].append([o,h,l,c])\n",
    "\n",
    "    m15_np = np.array(charts_array[0])\n",
    "    m5_np = np.array(charts_array[1])\n",
    "    m1_np = np.array(charts_array[2])\n",
    "\n",
    "    return [m15_np, m5_np, m1_np, pda_np, current_minutes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "aVzGqTFD6LjG"
   },
   "outputs": [],
   "source": [
    "m = MultiTimeframeCandleManager()\n",
    "\n",
    "current_position = 0\n",
    "entry_price = 0\n",
    "\n",
    "equity = 0\n",
    "open_profit = 0\n",
    "equity_L = [0]\n",
    "\n",
    "cmm = 0.5\n",
    "\n",
    "last_close = 0\n",
    "last_state = None\n",
    "last_action = 0\n",
    "\n",
    "index = 0\n",
    "\n",
    "def step():\n",
    "\n",
    "    global index, last_close, last_state, last_action, current_position, entry_price, equity\n",
    "\n",
    "\n",
    "    sarts = None\n",
    "    while  sarts == None:\n",
    "\n",
    "        ret = m.push_m1_candle(candles[index])\n",
    "        midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "        center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
    "        r = (midnight_opening_range_high - midnight_opening_range_low) / 2\n",
    "\n",
    "\n",
    "        if(len(m.m15_candles) == 60):\n",
    "\n",
    "            open_profit = (current_close - entry_price) * current_position\n",
    "            scaled_open_profit = open_profit / r\n",
    "\n",
    "            state = ret_to_scaled_inputs(ret) + [current_position, scaled_open_profit]\n",
    "            m15_np, m5_np, m1_np, pda_np, current_minutes, pos, open_profit = state\n",
    "\n",
    "            if(last_state != None):\n",
    "                diff = (equity+open_profit) - equity_L[-1]\n",
    "                equity_L.append(equity+open_profit)\n",
    "                reward =  (diff) / r\n",
    "                terminal = 0\n",
    "                if(index+1 == len(candles)):\n",
    "                    terminal = 1\n",
    "\n",
    "                sarts = last_state, last_action, reward, terminal, state\n",
    "\n",
    "\n",
    "            if(random.randint(0,100) > e):\n",
    "                output = model([\n",
    "                    tf.expand_dims(m15_np, 0),\n",
    "                    tf.expand_dims(m5_np, 0),\n",
    "                    tf.expand_dims(m1_np, 0),\n",
    "                    tf.expand_dims(pda_np, 0),\n",
    "                    tf.expand_dims(current_minutes, 0),\n",
    "                    tf.expand_dims(pos, 0),\n",
    "                    tf.expand_dims(open_profit, 0),\n",
    "                ])\n",
    "\n",
    "                last_action = np.argmax(output)\n",
    "            else:\n",
    "                last_action = random.randint(0,1)\n",
    "\n",
    "            last_close = current_close\n",
    "            last_state = state\n",
    "\n",
    "\n",
    "            if(last_action == 0 and current_position != -1):\n",
    "                equity += open_profit\n",
    "                #print(\"short at\", current_close, \" last position return:\", open_profit, \" equity:\", equity)\n",
    "                current_position = -1\n",
    "                entry_price = current_close\n",
    "                equity -= cmm\n",
    "\n",
    "            if(last_action == 1 and current_position != 1):\n",
    "                equity += open_profit\n",
    "                #print(\"long at\", current_close, \" last position return:\", open_profit, \" equity:\", equity)\n",
    "                current_position = 1\n",
    "                entry_price = current_close\n",
    "                equity -= cmm\n",
    "\n",
    "\n",
    "\n",
    "        index += 1\n",
    "        if(index == len(candles)):\n",
    "            index = 0\n",
    "            current_position = 0\n",
    "            entry_price = 0\n",
    "            last_close = 0\n",
    "            last_state = None\n",
    "            last_action = 0\n",
    "            print(\"env reset\")\n",
    "\n",
    "    return sarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "acX4Ztg86Ly9"
   },
   "outputs": [],
   "source": [
    "@tf.function(reduce_retracing=True)\n",
    "def get_target_q(next_states, rewards, terminals):\n",
    "            estimated_q_values_next = target_model(next_states)\n",
    "            q_batch = tf.math.reduce_max(estimated_q_values_next, axis=1)\n",
    "            target_q_values = q_batch * gamma * (1-terminals) + rewards\n",
    "            return target_q_values\n",
    "\n",
    "@tf.function(reduce_retracing=True)\n",
    "def tstep(states, masks, rewards, terminals, next_states):\n",
    "\n",
    "    target_q_values = get_target_q(next_states, rewards, terminals)\n",
    "\n",
    "    with tf.GradientTape() as t:\n",
    "        model_return = model(states, training=True)\n",
    "        mask_return = model_return * masks\n",
    "        estimated_q_values = tf.math.reduce_sum(mask_return, axis=1)\n",
    "        #print(estimated_q_values, mask_return, model_return, masks)\n",
    "        loss_e = tf.math.square(target_q_values - estimated_q_values)\n",
    "        loss = tf.reduce_mean(loss_e)\n",
    "\n",
    "\n",
    "    gradient = t.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
    "\n",
    "    return loss, tf.reduce_mean(estimated_q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "csDW9UAK6Nre"
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    sarts = step()\n",
    "    sarts_memory.append(sarts)\n",
    "\n",
    "    sarts_sample = random.sample(sarts_memory, min(batch_size, len(sarts_memory)))\n",
    "\n",
    "    states = [x[0] for x in sarts_sample]\n",
    "    actions = [x[1] for x in sarts_sample]\n",
    "    rewards = np.array([x[2] for x in sarts_sample], dtype=\"float32\")\n",
    "    terminals = np.array([x[3] for x in sarts_sample], dtype=\"float32\")\n",
    "    next_states = [x[4] for x in sarts_sample]\n",
    "\n",
    "    next_states_array = []\n",
    "    for i in range(num_model_inputs):\n",
    "        next_states_array.append(np.array([x[i] for x in next_states], dtype = \"float32\"))\n",
    "\n",
    "\n",
    "    states_array = []\n",
    "    for i in range(num_model_inputs):\n",
    "        states_array.append(np.array([x[i] for x in states], dtype = \"float32\"))\n",
    "\n",
    "\n",
    "    masks = np.array(m1[actions], dtype=\"float32\")\n",
    "\n",
    "    loss, q = tstep(states_array, masks, rewards, terminals, next_states_array)\n",
    "\n",
    "    return loss, q, sarts[2], sarts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading loss\n",
      "loading q\n",
      "loading rewards\n"
     ]
    }
   ],
   "source": [
    "sarts_memory = deque(maxlen = memory_len)\n",
    "\n",
    "loss_mean = []\n",
    "q_mean = []\n",
    "rewards = []\n",
    "\n",
    "try:\n",
    "    loss_mean = obj_load(\"loss\")\n",
    "    q_mean = obj_load(\"q\")\n",
    "    rewards = obj_load(\"rewards\")\n",
    "except:\n",
    "    print(\"unable to load data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7sAeWJZ96OvG",
    "outputId": "a5e58e80-406f-434e-d8a6-a9c9c0c63258"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.0182 - qv: 0.2553 - reward: -0.0050 - avg_action: 0.8310\n",
      "1000/1000 [==============================] - 142s 142ms/step - loss: 0.0104 - qv: 0.3195 - reward: -0.0050 - avg_action: 0.8330\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "t0 = time.time()\n",
    "safe_after_eps = 10\n",
    "eps_counter=0\n",
    "\n",
    "while True:\n",
    "    eps_counter+=1\n",
    "    try:\n",
    "        loss = []\n",
    "        q = []\n",
    "        rewards_tmp = []\n",
    "        actions = []\n",
    "        progbar = tf.keras.utils.Progbar(ep_len)\n",
    "        for i in range(ep_len):\n",
    "            c_loss, c_q, c_rewards, c_action = run()\n",
    "            loss.append(c_loss)\n",
    "            q.append(c_q)\n",
    "            #rewards_tmp.append(c_rewards)\n",
    "            rewards.append(c_rewards)\n",
    "            actions.append(c_action)\n",
    "    \n",
    "            #progbar.update(i+1, values = [(\"loss\", c_loss), (\"qv\", c_q), (\"reward\", c_rewards), (\"avg_action\", c_action)])\n",
    "    \n",
    "        loss_mean.append(np.mean(loss))\n",
    "        q_mean.append(np.mean(q))\n",
    "        #rewards.append(np.mean(rewards_tmp))\n",
    "        \n",
    "    \n",
    "        progbar.update(ep_len, values = [(\"loss\", np.mean(loss)), (\"qv\", np.mean(q)), (\"reward\", np.mean(rewards)), (\"avg_action\", np.mean(actions))])\n",
    "    \n",
    "        target_model.set_weights(model.get_weights())\n",
    "    \n",
    "        if(eps_counter >= safe_after_eps):\n",
    "            eps_counter = 0\n",
    "            model.save_weights(\"model.weights.h5\")\n",
    "            obj_save(loss_mean, \"loss\")\n",
    "            obj_save(q_mean, \"q\")\n",
    "            obj_save(rewards, \"rewards\")\n",
    "            print(\"saved progress\")\n",
    "    \n",
    "    except    KeyboardInterrupt:\n",
    "        print(\"\")\n",
    "        print(\"exit\")\n",
    "        model.save_weights(\"model.weights.h5\")\n",
    "        obj_save(loss_mean, \"loss\")\n",
    "        obj_save(q_mean, \"q\")\n",
    "        obj_save(rewards, \"rewards\")\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vlJjQSh76bP7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GSYnf6FC6P4R"
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#plt.plot(equity_L)\n",
    "#equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fc8GculHXkGh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qTvbON6VXkGh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
