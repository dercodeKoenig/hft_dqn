{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9571adab-eaaa-46b1-ab98-57cda59914ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 08:23:39.228042: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-14 08:23:39.256604: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-14 08:23:39.822028: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ../candle_data/NQ_1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "from MultiTimeframeCandleManager import *\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from save_and_load import *\n",
    "from Candle import Candle\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import (\n",
    "        Input, Lambda, Concatenate, Dense, Embedding, Dropout, LSTM, \n",
    "        MultiHeadAttention, LayerNormalization, LeakyReLU, GlobalAveragePooling1D, Add\n",
    "    )\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "#candles = obj_load(\"/content/NQ_2\")[-100000:]\n",
    "candles = obj_load(\"../candle_data/NQ_1\")[-20000:]\n",
    "len(candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06aa0bfa-c7d0-4b11-9878-44061a621133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.20.0-dev0+selfbuilt\n",
      "CUDA version TF was built with: 12.8.1\n",
      "cuDNN version TF was built with: 9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"CUDA version TF was built with:\", tf.sysconfig.get_build_info()[\"cuda_version\"])\n",
    "print(\"cuDNN version TF was built with:\", tf.sysconfig.get_build_info()[\"cudnn_version\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8940351f-c25f-4dab-ba74-a404f3775b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    l = 480\n",
    "    \n",
    "    def process_chart_with_time_position(chart_input, name):\n",
    "        # Extract OHLC and clip values\n",
    "        ohlc = Lambda(lambda x: tf.clip_by_value(x[:, :, :4], -1000.0, 1000.0),\n",
    "                      name=f'{name}_clip_ohlc')(chart_input)\n",
    "        \n",
    "        # Extract time column and cast to int\n",
    "        t = Lambda(lambda x: x[:, :, 4:5], name=f'{name}_extract_time')(chart_input)\n",
    "        t_int = Lambda(lambda x: tf.cast(tf.squeeze(x, axis=-1), tf.int32),\n",
    "                       name=f'{name}_cast_time')(t)\n",
    "    \n",
    "        # Time embedding\n",
    "        time_embed_layer = Embedding(input_dim=24*60, output_dim=8, name=f'{name}_time_embed')\n",
    "        t_embed = time_embed_layer(t_int)\n",
    "    \n",
    "        # Position embedding (based on sequence length from chart_input shape)\n",
    "        seq_length = chart_input.shape[1]\n",
    "        positions = tf.range(seq_length)\n",
    "        position_embed = Embedding(input_dim=seq_length, output_dim=8,\n",
    "                                   name=f'{name}_pos_embed')(positions)\n",
    "\n",
    "        # Add batch dimension so shape matches (batch, seq_length, 8)\n",
    "        position_embed = tf.expand_dims(position_embed, axis=0)  # (1, 480, 8)\n",
    "        position_embed = Lambda(lambda x: K.tile(x[0], [K.shape(x[1])[0], 1, 1]))([position_embed, chart_input])\n",
    "        \n",
    "        # Combine time and position embeddings\n",
    "        enhanced_time = Add(name=f'{name}_add_time_pos')([t_embed, position_embed])\n",
    "    \n",
    "        # Concatenate OHLC(4) + enhanced_time(8) → 12 dims\n",
    "        return Concatenate(name=f'{name}_concat')([ohlc, enhanced_time])\n",
    "\n",
    "    \n",
    "    def relational_attention_block(x, num_heads=8, key_dim=64, name_prefix=\"\"):\n",
    "        \"\"\"Self-attention to capture relationships between candles\"\"\"\n",
    "        # Multi-head self-attention\n",
    "        attention_out = MultiHeadAttention(\n",
    "            num_heads=num_heads, \n",
    "            key_dim=key_dim,\n",
    "            name=f'{name_prefix}_attention'\n",
    "        )(x, x)\n",
    "        \n",
    "        # Residual connection + layer norm\n",
    "        x_normed = LayerNormalization(name=f'{name_prefix}_norm1')(x + attention_out)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        ff_dim = x.shape[-1] * 2\n",
    "        ff = Dense(ff_dim, activation='gelu', name=f'{name_prefix}_ff1')(x_normed)\n",
    "        ff = Dense(x.shape[-1], name=f'{name_prefix}_ff2')(ff)\n",
    "        \n",
    "        # Second residual connection + layer norm\n",
    "        output = LayerNormalization(name=f'{name_prefix}_norm2')(x_normed + ff)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def process_timeframe_with_attention(chart_input, pdas_repeated, name):\n",
    "        \"\"\"Process each timeframe with attention mechanisms\"\"\"\n",
    "        # Concatenate chart with PDAs\n",
    "        x = Concatenate(axis=-1, name=f'{name}_concat_pdas')([chart_input, pdas_repeated])\n",
    "        \n",
    "        # Initial feature extraction - reduce dimensions gradually\n",
    "        x = Dense(512, name=f'{name}_dense1')(x)\n",
    "        x = LayerNormalization(name=f'{name}_norm_init')(x)\n",
    "        x = LeakyReLU(0.1, name=f'{name}_relu1')(x)\n",
    "        x = Dropout(0.1, name=f'{name}_dropout1')(x)\n",
    "        \n",
    "        x = Dense(256, name=f'{name}_dense2')(x)\n",
    "        x = LayerNormalization(name=f'{name}_norm2')(x)\n",
    "        x = LeakyReLU(0.1, name=f'{name}_relu2')(x)\n",
    "        \n",
    "        # Apply attention blocks to capture relational patterns\n",
    "        x = relational_attention_block(x, num_heads=8, key_dim=64, name_prefix=f'{name}_attn1')\n",
    "        x = relational_attention_block(x, num_heads=8, key_dim=64, name_prefix=f'{name}_attn2')\n",
    "        x = relational_attention_block(x, num_heads=8, key_dim=64, name_prefix=f'{name}_attn3')\n",
    "        x = relational_attention_block(x, num_heads=8, key_dim=64, name_prefix=f'{name}_attn4')\n",
    "        x = relational_attention_block(x, num_heads=8, key_dim=64, name_prefix=f'{name}_attn5')\n",
    "        x = relational_attention_block(x, num_heads=8, key_dim=64, name_prefix=f'{name}_attn6')\n",
    "        \n",
    "        # Final sequence compression with LSTM (single layer is often enough after attention)\n",
    "        x = LSTM(256, return_sequences=False, name=f'{name}_lstm')(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    ### Inputs\n",
    "    input_chart_m15 = Input(shape=(l,5), name='chart_m15')\n",
    "    input_chart_m5  = Input(shape=(l,5), name='chart_m5')\n",
    "    input_chart_m1  = Input(shape=(l,5), name='chart_m1')\n",
    "    \n",
    "    pdas = Input(shape=(3*3 + 3*3 + 1 + 12*5 + 5*3,), name='pdas')\n",
    "    pdas = Lambda(lambda x: tf.clip_by_value(x, -1000.0, 1000.0), name='clip_pdas')(pdas)\n",
    "    \n",
    "    #minutes = Input(shape=(1,), name='minutes')\n",
    "    \n",
    "    ### Process each chart with enhanced time/position embeddings\n",
    "    chart_m15 = process_chart_with_time_position(input_chart_m15, 'm15')\n",
    "    chart_m5  = process_chart_with_time_position(input_chart_m5, 'm5')\n",
    "    chart_m1  = process_chart_with_time_position(input_chart_m1, 'm1')\n",
    "    \n",
    "    # Repeat PDAs for concatenation\n",
    "    pdas_repeated = Lambda(\n",
    "        lambda inputs: tf.repeat(tf.expand_dims(inputs, axis=1), repeats=l, axis=1),\n",
    "        name='repeat_pdas'\n",
    "    )(pdas)\n",
    "    \n",
    "    ### Process each timeframe with attention\n",
    "    m15_features = process_timeframe_with_attention(chart_m15, pdas_repeated, 'm15')\n",
    "    m5_features = process_timeframe_with_attention(chart_m5, pdas_repeated, 'm5') \n",
    "    m1_features = process_timeframe_with_attention(chart_m1, pdas_repeated, 'm1')\n",
    "\n",
    "    ### Final combination and prediction\n",
    "    # Combine all enhanced features with original PDAs\n",
    "    c = Concatenate(name='final_concat')([pdas, m1_features, m5_features, m15_features])\n",
    "    \n",
    "    # Final prediction layers - smaller than before since attention does heavy lifting\n",
    "    d = Dense(2048, name='pred_dense1')(c)\n",
    "    d = LayerNormalization(name='pred_norm1')(d)\n",
    "    d = LeakyReLU(0.1, name='pred_relu1')(d)\n",
    "    d = Dropout(0.1, name='pred_dropout1')(d)\n",
    "    \n",
    "    d = Dense(1024, name='pred_dense2')(d)\n",
    "    d = LayerNormalization(name='pred_norm2')(d)\n",
    "    d = LeakyReLU(0.1, name='pred_relu2')(d)\n",
    "    d = Dropout(0.1, name='pred_dropout2')(d)\n",
    "    \n",
    "    d = Dense(512, name='pred_dense3')(d)\n",
    "    d = LayerNormalization(name='pred_norm3')(d)\n",
    "    d = LeakyReLU(0.1, name='pred_relu3')(d)\n",
    "    \n",
    "    # Stabilization layer before final prediction\n",
    "    d = Dense(256, activation='tanh', name='pre_softmax_tanh')(d)\n",
    "    \n",
    "    # Final prediction\n",
    "    output = Dense(3, activation=\"softmax\", dtype=\"float32\", name='output')(d)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[input_chart_m15, input_chart_m5, input_chart_m1, pdas], \n",
    "                  outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02d079fc-4fd6-47b4-a3f7-5ba821b08a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 08:23:40.266885: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2025-08-14 08:23:40.266899: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:160] env: CUDA_VISIBLE_DEVICES=\"-1\"\n",
      "2025-08-14 08:23:40.266901: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] CUDA_VISIBLE_DEVICES is set to -1 - this hides all GPUs from CUDA\n",
      "2025-08-14 08:23:40.266903: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-08-14 08:23:40.266905: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: rtx5090server\n",
      "2025-08-14 08:23:40.266906: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: rtx5090server\n",
      "2025-08-14 08:23:40.266938: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 570.158.1\n",
      "2025-08-14 08:23:40.266947: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 570.158.1\n",
      "2025-08-14 08:23:40.266948: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:284] kernel version seems to match DSO: 570.158.1\n"
     ]
    }
   ],
   "source": [
    "model = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8c8abad-02de-4c76-83be-4e6a55042591",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a88f530-f860-4c74-b928-fd38e0cda70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Order:\n",
    "    def __init__(self, limit, stop, tp, direction):\n",
    "        self.entry = limit\n",
    "        self.tp = tp\n",
    "        self.sl = stop\n",
    "        self.direction = direction\n",
    "\n",
    "class Position:\n",
    "    def __init__(self, entry, stop, tp, direction):\n",
    "        self.entry = entry\n",
    "        self.tp = tp\n",
    "        self.sl = stop\n",
    "        self.direction = direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "205c0fa0-4633-4e2c-803d-5f0e97105423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(index):\n",
    "\n",
    "        global current_position, current_order, slm, m, outputs, all_candles, cmm, equity, equity_L\n",
    "    \n",
    "        ret = m.push_m1_candle(candles[index])\n",
    "        midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "        center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
    "        r = max(0.0001, (midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
    "\n",
    "\n",
    "\n",
    "        current_candle_m1 = charts[2][-1]\n",
    "        #### check tp before filling order so that the same m1 candle will not trigger tp - it is not sure if the candle hit first limit and later tp or reve3rse\n",
    "        if current_position.direction == 1:\n",
    "            if current_candle_m1.h >= current_position.tp:\n",
    "                pnl = (current_position.tp - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "        if current_position.direction == -1:\n",
    "            if current_candle_m1.l <= current_position.tp:\n",
    "                pnl = (current_position.tp - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "        #### check order\n",
    "        if current_order != None:\n",
    "            if  current_order.direction == 1:\n",
    "                if current_candle_m1.l < current_order.entry:\n",
    "                    current_position = Position(current_order.entry, current_order.sl, current_order.tp, current_order.direction)\n",
    "                    #print(\"fill long order:\",current_order.entry, current_order.sl, current_order.tp)\n",
    "                    equity -= cmm\n",
    "                    current_order = None\n",
    "        if current_order != None:\n",
    "            if  current_order.direction == -1:\n",
    "                if current_candle_m1.h > current_order.entry:\n",
    "                    current_position = Position(current_order.entry, current_order.sl, current_order.tp, current_order.direction)\n",
    "                    #print(\"fill short order:\",current_order.entry, current_order.sl, current_order.tp)\n",
    "                    equity -= cmm\n",
    "                    current_order = None\n",
    "\n",
    "        #### check sl\n",
    "        if current_position.direction == 1:\n",
    "            if current_candle_m1.l <= current_position.sl:\n",
    "                pnl = (current_position.sl - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "        if current_position.direction == -1:\n",
    "            if current_candle_m1.h >= current_position.sl:\n",
    "                pnl = (current_position.sl - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if(len(m.m15_candles) == 480):\n",
    "\n",
    "\n",
    "            open_profit = (current_close - current_position.entry) * current_position.direction\n",
    "\n",
    "            scaled_entry_diff  =  0\n",
    "            scaled_sl_diff  =  0\n",
    "            if(current_position.direction != 0):\n",
    "                scaled_entry_diff = (current_close - current_position.entry) / r\n",
    "                scaled_sl_diff = (current_close - current_position.sl) / r\n",
    "\n",
    "            state = ret_to_scaled_inputs(ret) + [np.array([current_position.direction, scaled_entry_diff, scaled_sl_diff])]\n",
    "            m15_np, m5_np, m1_np, pda_np, pos_info = state\n",
    "\n",
    "            equity_L.append(equity+open_profit)\n",
    "            all_candles.append(charts[2][-1])\n",
    "\n",
    "\n",
    "            if True:#current_minutes >= 9*60+29 and current_minutes < 16*60:\n",
    "                output = inference_step(\n",
    "                    tf.expand_dims(m15_np, 0),\n",
    "                    tf.expand_dims(m5_np, 0),\n",
    "                    tf.expand_dims(m1_np, 0),\n",
    "                    tf.expand_dims(pda_np, 0),\n",
    "                    #tf.expand_dims(pos_info, 0)\n",
    "                )\n",
    "\n",
    "              \n",
    "                last_action = np.argmax(output)\n",
    "                #last_action = np.argmax([output[0][0], output[0][1]])\n",
    "                outputs.append(output[0])\n",
    "            else:\n",
    "                last_action = 2\n",
    "\n",
    "\n",
    "            avg_candle_range = np.mean([ i.h - i.l for i in list(charts[2])])\n",
    "\n",
    "            if(last_action == 2):\n",
    "                #equity += open_profit\n",
    "                #current_position = Position(0,0,0,0)\n",
    "                #print(\"close position:\", open_profit)\n",
    "                current_order = None\n",
    "\n",
    "            if(last_action == 0 and current_position.direction == 1):\n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "            if(last_action == 0):\n",
    "                last_candle_low = charts[2][-2].l\n",
    "                if ( last_candle_low < current_close ):\n",
    "                    last_candle_low = None\n",
    "\n",
    "                pdas = m.normal_pdas ## (low, high)\n",
    "\n",
    "                ## ignore pdas with low below close\n",
    "                pdas_filtered = []\n",
    "                for pda in pdas:\n",
    "                        if(pda[0] > current_close):\n",
    "                            pdas_filtered.append(pda)\n",
    "                ### sort\n",
    "                sorted_by_high = sorted(pdas_filtered, key = lambda x:x[1])\n",
    "                sorted_by_low = sorted(pdas_filtered, key = lambda x:x[0])\n",
    "\n",
    "                if(len(pdas_filtered) > 2):\n",
    "\n",
    "                    ### entry is lowest i can get or immediate rebalance\n",
    "                    entry = sorted_by_low[0][0]\n",
    "                    if(last_candle_low != None):\n",
    "                        entry = min(entry, last_candle_low)\n",
    "\n",
    "\n",
    "                    #sl = entry + avg_candle_range * slm\n",
    "                    sl = sorted_by_low[2][1]\n",
    "                    tp = entry  -  avg_candle_range * tpm\n",
    "\n",
    "                    if current_position.direction == 0:\n",
    "                        current_order = Order(entry, sl, tp, -1)\n",
    "                        #print(\"set short order:\",entry,sl,tp)\n",
    "                    if current_position.direction == -1:\n",
    "                        #current_position.sl = sl\n",
    "                        current_position.tp = tp\n",
    "\n",
    "\n",
    "\n",
    "            if(last_action == 1 and current_position.direction == -1):\n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "            if(last_action == 1):\n",
    "                last_candle_high = charts[2][-2].h\n",
    "                if ( last_candle_high > current_close ):\n",
    "                    last_candle_high = None\n",
    "                pdas = m.normal_pdas ## (low, high)\n",
    "\n",
    "                ## ignore pdas with low below close\n",
    "                pdas_filtered = []\n",
    "                for pda in pdas:\n",
    "                        if(pda[1] < current_close):\n",
    "                            pdas_filtered.append(pda)\n",
    "                ### sort\n",
    "                sorted_by_high = sorted(pdas_filtered, key = lambda x:x[1], reverse=True)\n",
    "                sorted_by_low = sorted(pdas_filtered, key = lambda x:x[0], reverse=True)\n",
    "\n",
    "                if(len(pdas_filtered) > 2):\n",
    "                    ### entry is lowest i can get or immediate rebalance\n",
    "                    entry = sorted_by_high[0][1]\n",
    "                    if(last_candle_high != None):\n",
    "                        entry = max(entry, last_candle_high)\n",
    "\n",
    "                    #sl = entry - avg_candle_range * slm\n",
    "                    sl = sorted_by_high[2][0]\n",
    "                    tp = entry  +  avg_candle_range * tpm\n",
    "\n",
    "                    if current_position.direction == 0:\n",
    "                        current_order = Order(entry, sl, tp, 1)\n",
    "                        #print(\"set long order:\",entry,sl,tp)\n",
    "                    if current_position.direction == 1:\n",
    "                        #current_position.sl = sl\n",
    "                        current_position.tp = tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba768b3d-5492-45d2-bebb-bd871a205786",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n",
      "\n",
      " 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 6668/20000 [00:01<00:02, 5866.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.0\n",
      "\n",
      " 0.0\n",
      "\n",
      " 17.25\n",
      "\n",
      " 76.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7044/20000 [00:20<00:50, 254.56it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 80.5\n",
      "\n",
      " 128.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 7289/20000 [00:32<01:43, 122.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 38.5\n",
      "\n",
      " -4.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 7504/20000 [00:43<03:07, 66.68it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 12.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 7593/20000 [00:48<03:58, 52.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -11.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 7704/20000 [00:53<09:20, 21.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -31.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 7803/20000 [00:58<10:26, 19.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -31.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 7842/20000 [01:00<10:15, 19.76it/s]"
     ]
    }
   ],
   "source": [
    "m = MultiTimeframeCandleManager()\n",
    "\n",
    "#slm = 2\n",
    "#tpm = 6\n",
    "\n",
    "slm = 2\n",
    "tpm = 6\n",
    "\n",
    "\n",
    "current_position = Position(0,0,0,0)\n",
    "current_order = None\n",
    "\n",
    "equity = 0\n",
    "equity_L = [0]\n",
    "\n",
    "outputs = []\n",
    "all_candles = []\n",
    "\n",
    "cmm = 0.5\n",
    "\n",
    "@tf.function()\n",
    "def inference_step(m15_np, m5_np, m1_np, pda_np):\n",
    "    return model([\n",
    "        m15_np,\n",
    "        m5_np,\n",
    "        m1_np,\n",
    "        pda_np\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "for index in tqdm(range(len(candles))):\n",
    "#for index in tqdm(range(11000)):\n",
    "    step(index)\n",
    "    if( index % 100 == 0 ):\n",
    "        print(\"\\n\", equity_L[-1])\n",
    "\n",
    "print(equity_L[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a17a05-cc8b-40b2-b624-b63b8b0636c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_candles(candles):\n",
    "    for index in range(len(candles)):\n",
    "        candle = candles[index]\n",
    "        c = \"green\" if candle.c > candle.o else \"black\"\n",
    "        plt.plot([index, index], [candle.l, candle.h], linewidth=1, color = \"black\")\n",
    "        plt.plot([index, index], [candle.c, candle.o], linewidth=3, color = c)\n",
    "index+=1\n",
    "#step(index)\n",
    "plot_candles(m.m1_candles)\n",
    "if(current_position.direction != 0):\n",
    "    plt.axhline(current_position.entry, color = \"g\" if current_position.direction == 1 else \"r\")\n",
    "    plt.axhline(current_position.sl, color = \"orange\")\n",
    "    plt.axhline(current_position.tp, color = \"orange\")\n",
    "if(current_order != None):\n",
    "    plt.axhline(current_order.entry, color = \"g\" if current_order.direction == 1 else \"r\")\n",
    "    plt.axhline(current_order.sl, color = \"orange\")\n",
    "    plt.axhline(current_order.tp, color = \"orange\")\n",
    "print(current_position.direction, equity_L[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f3804-c7bd-4c57-98cf-c7bc56c76996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(outputs)\n",
    "plt.plot([x[0] for x in outputs[-400:]], color=\"r\")\n",
    "plt.plot([x[1] for x in outputs[-400:]], color=\"g\")\n",
    "plt.plot([x[2] for x in outputs[-400:]], color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f317aa-0ed9-40a3-bd68-dc30f4efe8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x.c for x in all_candles])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53e4ba0-df8e-442b-b25f-65b8973d9779",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(equity_L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea24ca3-ba5d-4db3-be5c-3a7006c658d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x[1]-x[0] for x in outputs], color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99342324-c865-4383-b677-5c873a293af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f311d534-986c-4a88-a5e0-d2da8237bad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
