{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d5d27d-eb74-46b3-a080-4704d93e59fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "import os\n",
    "from MultiTimeframeCandleManager import MultiTimeframeCandleManager\n",
    "from datetime import datetime, timedelta\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from save_and_load import *\n",
    "from Candle import Candle\n",
    "import matplotlib.pyplot as plt\n",
    "#from tensorflow.keras import mixed_precision\n",
    "#mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "try:\n",
    "    cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"local\")\n",
    "    tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
    "    strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
    "    print(\"use tpu strategy\")\n",
    "except:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "strategy\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "gamma = 0.99\n",
    "memory_len = 6000000\n",
    "sarts_memory = deque(maxlen = memory_len)\n",
    "batch_size = 256\n",
    "e = 2\n",
    "slm = 1.5\n",
    "\n",
    "min_memory_size = 100000\n",
    "\n",
    "num_actions = 3\n",
    "\n",
    "path = \"./\"\n",
    "\n",
    "ep_len = 2000\n",
    "\n",
    "m1 = np.eye(num_actions, dtype=\"float32\")\n",
    "num_model_inputs = 6\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "try:\n",
    "    sarts_cache = obj_load(path+\"sarts_cache\")\n",
    "    for i in tqdm(sarts_cache):\n",
    "        sarts_memory.append(i)\n",
    "    del sarts_cache\n",
    "except Exception as error:\n",
    "    print(\"no sarts cache loaded\")\n",
    "    print(error)\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "\n",
    "  lrelu = tf.keras.layers.LeakyReLU(0.05)\n",
    "\n",
    "\n",
    "  chart_m15 = tf.keras.layers.Input(shape = (60,4))\n",
    "  chart_m5 = tf.keras.layers.Input(shape = (60,4))\n",
    "  chart_m1 = tf.keras.layers.Input(shape = (60,4))\n",
    "\n",
    "  pdas = tf.keras.layers.Input(shape = (3*3+3*3+1+12*5+5*3,))\n",
    "\n",
    "  current_position = tf.keras.layers.Input(shape = (3,))\n",
    "\n",
    "  minutes = tf.keras.layers.Input(shape = (1,))\n",
    "  minutes_embed = tf.keras.layers.Embedding(input_dim=60*24, output_dim=8)(minutes)\n",
    "  minutes_embed_flat = tf.keras.layers.Flatten()(minutes_embed)\n",
    "\n",
    "  f15 = tf.keras.layers.Flatten()(chart_m15)\n",
    "  f5 = tf.keras.layers.Flatten()(chart_m5)\n",
    "  f1 = tf.keras.layers.Flatten()(chart_m1)\n",
    "\n",
    "  pdas_repeated = tf.keras.layers.Lambda(\n",
    "  lambda inputs: tf.repeat(tf.expand_dims(inputs, axis = 1), repeats=60, axis=1)\n",
    "  )(pdas)\n",
    "\n",
    "  concatenated_m5_at = tf.keras.layers.Concatenate(axis=-1)([chart_m5, pdas_repeated])\n",
    "  m5_at = tf.keras.layers.Dense(1024)(concatenated_m5_at)\n",
    "  m5_at = lrelu(m5_at)\n",
    "  m5_at = tf.keras.layers.Dense(1024)(m5_at)\n",
    "  m5_at = lrelu(m5_at)\n",
    "  m5_at = tf.keras.layers.Dense(128)(m5_at)\n",
    "  m5_at = lrelu(m5_at)\n",
    "  m5_at = tf.keras.layers.LSTM(512)(m5_at)\n",
    "\n",
    "  concatenated_m1_at = tf.keras.layers.Concatenate(axis=-1)([chart_m1, pdas_repeated])\n",
    "  m1_at = tf.keras.layers.Dense(1024)(concatenated_m1_at)\n",
    "  m1_at = lrelu(m1_at)\n",
    "  m1_at = tf.keras.layers.Dense(1024)(m1_at)\n",
    "  m1_at = lrelu(m1_at)\n",
    "  m1_at = tf.keras.layers.Dense(128)(m1_at)\n",
    "  m1_at = lrelu(m1_at)\n",
    "  m1_at = tf.keras.layers.LSTM(512)(m1_at)\n",
    "\n",
    "    \n",
    "  #c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, scaled_open_profit])\n",
    "  c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, m1_at, m5_at])\n",
    "\n",
    "  d = tf.keras.layers.Dense(4096*4)(c)\n",
    "  d = lrelu(d)\n",
    "  d = tf.keras.layers.Dense(4096*4)(d)\n",
    "  d = lrelu(d)\n",
    "  d = tf.keras.layers.Dense(4096*2)(d)\n",
    "  d = lrelu(d)\n",
    "  d = tf.keras.layers.Dense(4096*1)(d)\n",
    "  d = lrelu(d)\n",
    "\n",
    "\n",
    "  value = tf.keras.layers.Dense(1, activation=\"linear\")(d)\n",
    "  advantage = tf.keras.layers.Dense(num_actions, activation=\"linear\")(d)\n",
    "\n",
    "  q_values = tf.keras.layers.Lambda(\n",
    "  lambda inputs: inputs[0] + (inputs[1] - tf.reduce_mean(inputs[1], axis=1, keepdims=True))\n",
    "  )([value, advantage])\n",
    "\n",
    "  outputs = tf.keras.layers.Activation('linear', dtype='float32')(q_values)\n",
    "\n",
    "  model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = outputs)\n",
    "  target_model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = outputs)\n",
    "\n",
    "\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate = 0.000001)\n",
    "\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "def relative (value, center, r):\n",
    "        return (value - center) / r\n",
    "\n",
    "def ret_to_scaled_inputs(ret):\n",
    "\n",
    "    midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "\n",
    "\n",
    "    center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
    "    r = max(0.0001,(midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
    "\n",
    "    pda_rel = []\n",
    "    pda_rel.append(relative(midnight_open, center, r))\n",
    "    for pda in pdas[0:9+9+15]:\n",
    "        pda_rel.append(relative(pda, center, r))\n",
    "    for index in range(9+9+15,9+9+15+5*12):\n",
    "        ## highs lows are like this [h, h_taken, l, l_taken]\n",
    "        ## the bools should not be scaled\n",
    "        if (index - 9+9+15) % 2 == 0:\n",
    "            pda_rel.append(relative(pdas[index], center, r))\n",
    "        else:\n",
    "            pda_rel.append(pdas[index])\n",
    "\n",
    "    pda_np = np.array(pda_rel)\n",
    "\n",
    "    current_minutes = current_time.hour * 60 + current_time.minute\n",
    "\n",
    "    charts_array = []\n",
    "    for candlesticks in charts:\n",
    "        charts_array.append([])\n",
    "        for candle in candlesticks:\n",
    "            o = relative(candle.o, center, r)\n",
    "            h = relative(candle.h, center, r)\n",
    "            l = relative(candle.l, center, r)\n",
    "            c = relative(candle.c, center, r)\n",
    "            charts_array[-1].append([o,h,l,c])\n",
    "\n",
    "    m15_np = np.array(charts_array[0])\n",
    "    m5_np = np.array(charts_array[1])\n",
    "    m1_np = np.array(charts_array[2])\n",
    "\n",
    "    return [m15_np, m5_np, m1_np, pda_np, current_minutes]\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "class Order:\n",
    "    def __init__(self, limit, stop, tp, direction):\n",
    "        self.entry = limit\n",
    "        self.tp = tp\n",
    "        self.sl = stop\n",
    "        self.direction = direction\n",
    "\n",
    "class Position:\n",
    "    def __init__(self, entry, stop, tp, direction):\n",
    "        self.entry = entry\n",
    "        self.tp = tp\n",
    "        self.sl = stop\n",
    "        self.direction = direction\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "equity = 0\n",
    "equity_L = [0]\n",
    "\n",
    "inputs = [\n",
    "    (\"NQ_2\", 0.75),\n",
    "    (\"ES_2\", 0.5),\n",
    "    (\"YM_2\", 1.5),\n",
    "    #(\"EURUSD_2\", 0.00015),\n",
    "    #(\"GBPUSD_2\", 0.00015)\n",
    "]\n",
    "\n",
    "candles = []\n",
    "cmm = 0\n",
    "\n",
    "input_index = random.randint(0,len(inputs)-1)\n",
    "def reset():\n",
    "    global index, last_state, last_action, current_position, current_order, equity, m, candles, cmm, input_index\n",
    "\n",
    "    ob = inputs[input_index]\n",
    "    candles = obj_load(ob[0])\n",
    "    cmm = ob[1]\n",
    "    input_index+=1\n",
    "    if(input_index >= len(inputs)):\n",
    "        input_index = 0\n",
    "\n",
    "    m = MultiTimeframeCandleManager()\n",
    "\n",
    "    current_position = Position(0,0,0,0)\n",
    "    current_order = None\n",
    "\n",
    "    last_state = None\n",
    "    last_action = 0\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    print(\"env reset, using data:\", ob)\n",
    "\n",
    "\n",
    "@tf.function()\n",
    "def inference_step(m15_np, m5_np, m1_np, pda_np, current_minutes, pos_info):\n",
    "    return model([\n",
    "        m15_np,\n",
    "        m5_np,\n",
    "        m1_np,\n",
    "        pda_np,\n",
    "        current_minutes,\n",
    "        pos_info,\n",
    "    ])\n",
    "\n",
    "\n",
    "def step():\n",
    "\n",
    "    global index, last_state, last_action, current_position, current_order, equity, m\n",
    "\n",
    "\n",
    "    sarts = None\n",
    "    while  sarts == None:\n",
    "\n",
    "        ret = m.push_m1_candle(candles[index])\n",
    "        midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "        center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
    "        r = max(0.0001, (midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
    "\n",
    "\n",
    "\n",
    "        current_candle_m1 = charts[2][-1]\n",
    "        #### check tp before filling order so that the same m1 candle will not trigger tp - it is not sure if the candle hit first limit and later tp or reve3rse\n",
    "        if current_position.direction == 1:\n",
    "            if current_candle_m1.h >= current_position.tp:\n",
    "                pnl = (current_position.tp - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "        if current_position.direction == -1:\n",
    "            if current_candle_m1.l <= current_position.tp:\n",
    "                pnl = (current_position.tp - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "        #### check order\n",
    "        if current_order != None:\n",
    "            if  current_order.direction == 1:\n",
    "                if current_candle_m1.l < current_order.entry:\n",
    "                    current_position = Position(current_order.entry, current_order.sl, current_order.tp, current_order.direction)\n",
    "                    #print(\"fill long order:\",current_order.entry, current_order.sl, current_order.tp)\n",
    "                    equity -= cmm\n",
    "                    current_order = None\n",
    "        if current_order != None:\n",
    "            if  current_order.direction == -1:\n",
    "                if current_candle_m1.h > current_order.entry:\n",
    "                    current_position = Position(current_order.entry, current_order.sl, current_order.tp, current_order.direction)\n",
    "                    #print(\"fill short order:\",current_order.entry, current_order.sl, current_order.tp)\n",
    "                    equity -= cmm\n",
    "                    current_order = None\n",
    "\n",
    "        #### check sl\n",
    "        if current_position.direction == 1:\n",
    "            if current_candle_m1.l <= current_position.sl:\n",
    "                pnl = (current_position.sl - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "        if current_position.direction == -1:\n",
    "            if current_candle_m1.h >= current_position.sl:\n",
    "                pnl = (current_position.sl - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if(len(m.ndogs) == 5 and len(m.fps) == 3 and len(m.opening_range_gaps) == 3 and len(m.asia_highs_lows) == 3 and len(m.london_highs_lows) == 3 and len(m.ny_am_highs_lows) == 3 and len(m.ny_lunch_highs_lows) == 3 and len(m.ny_pm_highs_lows) == 3):\n",
    "\n",
    "\n",
    "            open_profit = (current_close - current_position.entry) * current_position.direction\n",
    "\n",
    "            scaled_entry_diff  =  0\n",
    "            scaled_sl_diff  =  0\n",
    "            if(current_position.direction != 0):\n",
    "                scaled_entry_diff = (current_close - current_position.entry) / r\n",
    "                scaled_sl_diff = (current_close - current_position.sl) / r\n",
    "\n",
    "            state = ret_to_scaled_inputs(ret) + [np.array([current_position.direction, scaled_entry_diff, scaled_sl_diff])]\n",
    "            m15_np, m5_np, m1_np, pda_np, current_minutes, pos_info = state\n",
    "\n",
    "            if(last_state != None):\n",
    "                diff = (equity+open_profit) - equity_L[-1]\n",
    "                equity_L.append(equity+open_profit)\n",
    "                reward =  (diff) / r\n",
    "                reward = min(max(reward, -10), 10)\n",
    "                terminal = 0\n",
    "                if(index+1 == len(candles)):\n",
    "                    terminal = 1\n",
    "\n",
    "                sarts = last_state, last_action, reward, terminal, state\n",
    "\n",
    "\n",
    "            if current_minutes >= 16*60+30 and current_minutes < 18*60:\n",
    "                last_action = 2\n",
    "            \n",
    "            elif(random.randint(0,100) >= e):\n",
    "                with tf.device(\"/TPU:0\"):\n",
    "                    output = inference_step(\n",
    "                        tf.expand_dims(m15_np, 0),\n",
    "                        tf.expand_dims(m5_np, 0),\n",
    "                        tf.expand_dims(m1_np, 0),\n",
    "                        tf.expand_dims(pda_np, 0),\n",
    "                        tf.expand_dims(current_minutes, 0),\n",
    "                        tf.expand_dims(pos_info, 0)\n",
    "                    )\n",
    "                    last_action = np.argmax(output)\n",
    "            else:\n",
    "                last_action = random.randint(0,num_actions-1)\n",
    "\n",
    "            last_state = state\n",
    "\n",
    "            current_order = None\n",
    "\n",
    "            avg_candle_range = np.mean([ i.h - i.l for i in list(charts[2])[55:60]])\n",
    "\n",
    "            if(last_action == 2 and current_position.direction != 0):\n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "            if(last_action == 0 and current_position.direction == 1):\n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "            if(last_action == 0 and current_position.direction == 0):\n",
    "                last_candle_low = charts[2][-2].l\n",
    "                if ( last_candle_low < current_close ):\n",
    "                    last_candle_low = None\n",
    "\n",
    "                pdas = m.normal_pdas ## (low, high)\n",
    "\n",
    "                ## ignore pdas with low below close\n",
    "                pdas_filtered = []\n",
    "                for pda in pdas:\n",
    "                        if(pda[0] > current_close):\n",
    "                            pdas_filtered.append(pda)\n",
    "                ### sort\n",
    "                sorted_by_high = sorted(pdas_filtered, key = lambda x:x[1])\n",
    "                sorted_by_low = sorted(pdas_filtered, key = lambda x:x[0])\n",
    "\n",
    "                if(len(pdas_filtered) > 0):\n",
    "\n",
    "                    ### entry is lowest i can get or immediate rebalance\n",
    "                    entry = sorted_by_low[0][0]\n",
    "                    if(last_candle_low != None):\n",
    "                        entry = min(entry, last_candle_low)\n",
    "\n",
    "\n",
    "                    sl = entry + avg_candle_range * slm\n",
    "                    tp = entry  -  abs(entry-sl) * 1000\n",
    "\n",
    "\n",
    "                    current_order = Order(entry, sl, tp, -1)\n",
    "                    #print(\"set short order:\",entry,sl,tp)\n",
    "\n",
    "\n",
    "\n",
    "            if(last_action == 1 and current_position.direction == -1):\n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "            if(last_action == 1 and current_position.direction == 0):\n",
    "                last_candle_high = charts[2][-2].h\n",
    "                if ( last_candle_high > current_close ):\n",
    "                    last_candle_high = None\n",
    "                pdas = m.normal_pdas ## (low, high)\n",
    "\n",
    "                ## ignore pdas with low below close\n",
    "                pdas_filtered = []\n",
    "                for pda in pdas:\n",
    "                        if(pda[1] < current_close):\n",
    "                            pdas_filtered.append(pda)\n",
    "                ### sort\n",
    "                sorted_by_high = sorted(pdas_filtered, key = lambda x:x[1], reverse=True)\n",
    "                sorted_by_low = sorted(pdas_filtered, key = lambda x:x[0], reverse=True)\n",
    "\n",
    "                if(len(pdas_filtered) > 0):\n",
    "                    ### entry is lowest i can get or immediate rebalance\n",
    "                    entry = sorted_by_high[0][1]\n",
    "                    if(last_candle_high != None):\n",
    "                        entry = max(entry, last_candle_high)\n",
    "\n",
    "                    sl = entry - avg_candle_range * slm\n",
    "                    tp = entry  +  abs(entry-sl) * 1000\n",
    "\n",
    "                    current_order = Order(entry, sl, tp, 1)\n",
    "                    #print(\"set long order:\",entry,sl,tp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        index += 1\n",
    "        if(index == len(candles)):\n",
    "            reset()\n",
    "\n",
    "    return sarts\n",
    "\n",
    "reset()\n",
    "index = random.randint(0,len(candles)-100000)\n",
    "print(\"start at index\", index)\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def get_target_q(next_states, rewards, terminals):\n",
    "            estimated_q_values_next = target_model(next_states)\n",
    "            q_batch = tf.math.reduce_max(estimated_q_values_next, axis=1)\n",
    "            target_q_values = q_batch * gamma * (1-terminals) + rewards\n",
    "            return target_q_values\n",
    "\n",
    "@tf.function(jit_compile=True) # my gpu does not support this\n",
    "def tstep(data):\n",
    "    states, masks, rewards, terminals, next_states = data\n",
    "\n",
    "    target_q_values = get_target_q(next_states, rewards, terminals)\n",
    "\n",
    "    with tf.GradientTape() as t:\n",
    "        model_return = model(states, training=True)\n",
    "        mask_return = model_return * masks\n",
    "        estimated_q_values = tf.math.reduce_sum(mask_return, axis=1)\n",
    "        #print(estimated_q_values, mask_return, model_return, masks)\n",
    "        loss_e = tf.math.square(target_q_values - estimated_q_values)\n",
    "        loss = tf.reduce_mean(loss_e)\n",
    "\n",
    "\n",
    "    gradient = t.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
    "\n",
    "    return loss, tf.reduce_mean(estimated_q_values)\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "sarts_index = 0\n",
    "def get_data(n):\n",
    "        global sarts_index\n",
    "        #sarts_index = random.randint(0, len(sarts_memory) - batch_size)\n",
    "        sarts_sample = [sarts_memory[i] for i in range(sarts_index, sarts_index + batch_size)]\n",
    "        sarts_index+=batch_size\n",
    "        if(sarts_index+batch_size >= len(sarts_memory)):\n",
    "            sarts_index = 0\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        states = [x[0] for x in sarts_sample]\n",
    "        actions = [x[1] for x in sarts_sample]\n",
    "        rewards = np.array([x[2] for x in sarts_sample], dtype=\"float32\")\n",
    "        terminals = np.array([x[3] for x in sarts_sample], dtype=\"float32\")\n",
    "        next_states = [x[4] for x in sarts_sample]\n",
    "\n",
    "        next_states_array = []\n",
    "        for i in range(num_model_inputs):\n",
    "            next_states_array.append(np.array([x[i] for x in next_states], dtype = \"float32\"))\n",
    "\n",
    "\n",
    "        states_array = []\n",
    "        for i in range(num_model_inputs):\n",
    "            states_array.append(np.array([x[i] for x in states], dtype = \"float32\"))\n",
    "\n",
    "\n",
    "        masks = np.array(m1[actions], dtype=\"float32\")\n",
    "\n",
    "\n",
    "        return states_array, masks, rewards, terminals, next_states_array\n",
    "\n",
    "def run():\n",
    "    sarts = step()\n",
    "    sarts_memory.append(sarts)\n",
    "\n",
    "    if(len(sarts_memory) > min_memory_size):\n",
    "\n",
    "        distributed_data = (strategy.experimental_distribute_values_from_function(get_data))\n",
    "        loss, q = strategy.reduce(tf.distribute.ReduceOp.MEAN, strategy.run(tstep, args = (distributed_data,)), axis = None)\n",
    "\n",
    "        return loss, q, sarts[2], sarts[1]\n",
    "\n",
    "    else :\n",
    "        return 0,0, sarts[2], sarts[1]\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "loss_mean = []\n",
    "q_mean = []\n",
    "rewards = []\n",
    "\n",
    "try:\n",
    "    model.load_weights(path+\"model.weights.h5\")\n",
    "    target_model.load_weights(path+\"model.weights.h5\")\n",
    "\n",
    "    loss_mean = obj_load(path+\"loss\")\n",
    "    q_mean = obj_load(path+\"q\")\n",
    "    rewards = obj_load(path+\"rewards\")\n",
    "except Exception as a:\n",
    "    print(a)\n",
    "    print(\"unable to load data\")\n",
    "\n",
    "\n",
    "def save():\n",
    "            model.save_weights(path+\"model.weights.h5\")\n",
    "            obj_save(loss_mean, path+\"loss\")\n",
    "            obj_save(q_mean, path+\"q\")\n",
    "            obj_save(rewards, path+\"rewards\")\n",
    "            print(\"saved progress\")\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "save_eps = 20\n",
    "eps_c = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        #eps_c += 1\n",
    "        loss = []\n",
    "        q = []\n",
    "        rewards_tmp = []\n",
    "        actions = []\n",
    "        progbar = tf.keras.utils.Progbar(ep_len)\n",
    "        for i in range(ep_len):\n",
    "            c_loss, c_q, c_rewards, c_action = run()\n",
    "            loss.append(c_loss)\n",
    "            q.append(c_q)\n",
    "            rewards_tmp.append(c_rewards)\n",
    "            actions.append(c_action)\n",
    "\n",
    "            #progbar.update(i+1, values = [(\"loss\", c_loss), (\"qv\", c_q), (\"reward\", c_rewards), (\"avg_action\", c_action)])\n",
    "\n",
    "        loss_mean.append(np.mean(loss))\n",
    "        q_mean.append(np.mean(q))\n",
    "        #rewards.append(np.mean(rewards_tmp))\n",
    "        rewards.extend(rewards_tmp)\n",
    "\n",
    "        progbar.update(ep_len, values = [(\"loss\", np.mean(loss)), (\"qv\", np.mean(q)), (\"reward\", np.mean(rewards_tmp)), (\"avg_action\", np.mean(actions))])\n",
    "\n",
    "        target_model.set_weights(model.get_weights())\n",
    "\n",
    "\n",
    "        \n",
    "        if(eps_c >=save_eps):\n",
    "          eps_c=0\n",
    "          save()\n",
    "\n",
    "    except    KeyboardInterrupt:\n",
    "        print(\"\")\n",
    "        print(\"exit\")\n",
    "        break\n",
    "\n",
    "save()\n",
    "\n",
    "\n",
    "obj_save(list(sarts_memory), path+\"sarts_cache\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
