{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b197691-b458-4cbf-943f-14c353d9da30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MultiTimeframeCandleManager import MultiTimeframeCandleManager\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from save_and_load import *\n",
    "from Candle import Candle\n",
    "import matplotlib.pyplot as plt\n",
    "#from tensorflow.keras import mixed_precision\n",
    "#mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a46f09d-bcd5-4f57-a637-d75e36e4bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.995\n",
    "memory_len = 500000\n",
    "sarts_memory = deque(maxlen = memory_len)\n",
    "batch_size = 32\n",
    "e = 2\n",
    "\n",
    "min_memory_size = 128\n",
    "\n",
    "num_actions = 3\n",
    "\n",
    "path = \"./\"\n",
    "\n",
    "ep_len = 1000\n",
    "\n",
    "m1 = np.eye(num_actions, dtype=\"float32\")\n",
    "num_model_inputs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "390662b5-22d2-4aa9-a457-d598fdb81fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 79)]         0           []                               \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 1, 79)        0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " tf.repeat (TFOpLambda)         (None, 60, 79)       0           ['tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 60, 83)       0           ['input_3[0][0]',                \n",
      "                                                                  'tf.repeat[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 60, 83)       0           ['input_2[0][0]',                \n",
      "                                                                  'tf.repeat[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 60, 83)       0           ['input_1[0][0]',                \n",
      "                                                                  'tf.repeat[0][0]']              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 60, 256)      21504       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 60, 256)      21504       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 60, 256)      21504       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 60, 256)      65792       ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 60, 256)      65792       ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 60, 256)      65792       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 8)         11520       ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 60, 256)      65792       ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 60, 256)      65792       ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 60, 256)      65792       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 240)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 240)          0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 240)          0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 8)            0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " gru_2 (GRU)                    (None, 128)          148224      ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, 128)          148224      ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, 128)          148224      ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 1194)         0           ['flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]',              \n",
      "                                                                  'flatten_3[0][0]',              \n",
      "                                                                  'input_4[0][0]',                \n",
      "                                                                  'flatten[0][0]',                \n",
      "                                                                  'input_5[0][0]',                \n",
      "                                                                  'gru_2[0][0]',                  \n",
      "                                                                  'gru_1[0][0]',                  \n",
      "                                                                  'gru[0][0]']                    \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 8192)         9789440     ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 8192)         0           ['dense_9[0][0]',                \n",
      "                                                                  'dense_10[0][0]',               \n",
      "                                                                  'dense_11[0][0]',               \n",
      "                                                                  'dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 8192)         67117056    ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 8192)         67117056    ['leaky_re_lu[1][0]']            \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 8192)         67117056    ['leaky_re_lu[2][0]']            \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 1)            8193        ['leaky_re_lu[3][0]']            \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 3)            24579       ['leaky_re_lu[3][0]']            \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 3)            0           ['dense_13[0][0]',               \n",
      "                                                                  'dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 3)            0           ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 212,088,836\n",
      "Trainable params: 212,088,836\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lrelu = tf.keras.layers.LeakyReLU(0.05)\n",
    "\n",
    "\n",
    "chart_m15 = tf.keras.layers.Input(shape = (60,4))\n",
    "chart_m5 = tf.keras.layers.Input(shape = (60,4))\n",
    "chart_m1 = tf.keras.layers.Input(shape = (60,4))\n",
    "\n",
    "pdas = tf.keras.layers.Input(shape = (19+12*5,))\n",
    "\n",
    "current_position = tf.keras.layers.Input(shape = (3,))\n",
    "\n",
    "minutes = tf.keras.layers.Input(shape = (1,))\n",
    "minutes_embed = tf.keras.layers.Embedding(input_dim=60*24, output_dim=8)(minutes)\n",
    "minutes_embed_flat = tf.keras.layers.Flatten()(minutes_embed)\n",
    "\n",
    "f15 = tf.keras.layers.Flatten()(chart_m15)\n",
    "f5 = tf.keras.layers.Flatten()(chart_m5)\n",
    "f1 = tf.keras.layers.Flatten()(chart_m1)\n",
    "\n",
    "pdas_repeated = tf.repeat(tf.expand_dims(pdas, axis = 1), repeats=60, axis=1)  \n",
    "\n",
    "concatenated_m15_at = tf.keras.layers.Concatenate(axis=-1)([chart_m15, pdas_repeated])\n",
    "m15_at = tf.keras.layers.Dense(256)(concatenated_m15_at)\n",
    "m15_at = lrelu(m15_at)\n",
    "m15_at = tf.keras.layers.Dense(256)(m15_at)\n",
    "m15_at = lrelu(m15_at)\n",
    "m15_at = tf.keras.layers.Dense(256)(m15_at)\n",
    "m15_at = lrelu(m15_at)\n",
    "m15_rnn = tf.keras.layers.GRU(128)(m15_at)\n",
    "\n",
    "concatenated_m5_at = tf.keras.layers.Concatenate(axis=-1)([chart_m5, pdas_repeated])\n",
    "m5_at = tf.keras.layers.Dense(256)(concatenated_m5_at)\n",
    "m5_at = lrelu(m5_at)\n",
    "m5_at = tf.keras.layers.Dense(256)(m5_at)\n",
    "m5_at = lrelu(m5_at)\n",
    "m5_at = tf.keras.layers.Dense(256)(m5_at)\n",
    "m5_at = lrelu(m5_at)\n",
    "m5_rnn = tf.keras.layers.GRU(128)(m5_at)\n",
    "\n",
    "concatenated_m1_at = tf.keras.layers.Concatenate(axis=-1)([chart_m1, pdas_repeated])\n",
    "m1_at = tf.keras.layers.Dense(256)(concatenated_m1_at)\n",
    "m1_at = lrelu(m1_at)\n",
    "m1_at = tf.keras.layers.Dense(256)(m1_at)\n",
    "m1_at = lrelu(m1_at)\n",
    "m1_at = tf.keras.layers.Dense(256)(m1_at)\n",
    "m1_at = lrelu(m1_at)\n",
    "m1_rnn = tf.keras.layers.GRU(128)(m1_at)\n",
    "\n",
    "#c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, scaled_open_profit])\n",
    "c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, m1_rnn, m5_rnn, m15_rnn])\n",
    "\n",
    "d = tf.keras.layers.Dense(1024*8)(c)\n",
    "d = lrelu(d)\n",
    "d = tf.keras.layers.Dense(1024*8)(d)\n",
    "d = lrelu(d)\n",
    "d = tf.keras.layers.Dense(1024*8)(d)\n",
    "d = lrelu(d)\n",
    "d = tf.keras.layers.Dense(1024*8)(d)\n",
    "d = lrelu(d)\n",
    "\n",
    "\n",
    "value = tf.keras.layers.Dense(1, activation=\"linear\")(d)\n",
    "advantage = tf.keras.layers.Dense(num_actions, activation=\"linear\")(d)\n",
    "\n",
    "q_values = tf.keras.layers.Lambda(\n",
    "lambda inputs: inputs[0] + (inputs[1] - tf.reduce_mean(inputs[1], axis=1, keepdims=True))\n",
    ")([value, advantage])\n",
    "\n",
    "outputs = tf.keras.layers.Activation('linear', dtype='float32')(q_values)\n",
    "\n",
    "model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = outputs)\n",
    "target_model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f52b75ca-6d6e-4059-80f2-8db39463a3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f069d41-781f-439b-b12a-59bd3e1f29e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def relative (value, center, r):\n",
    "        return (value - center) / r\n",
    "\n",
    "def ret_to_scaled_inputs(ret):\n",
    "\n",
    "    midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "    \n",
    "\n",
    "    center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
    "    r = max(0.0001,(midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
    "\n",
    "    pda_rel = []\n",
    "    pda_rel.append(relative(midnight_open, center, r))\n",
    "    for pda in pdas[0:18]:\n",
    "        pda_rel.append(relative(pda, center, r))\n",
    "    for index in range(18,18+5*12):\n",
    "        ## highs lows are like this [h, h_taken, l, l_taken]\n",
    "        ## the bools should not be scaled\n",
    "        if (index - 18) % 2 == 0:\n",
    "            pda_rel.append(relative(pdas[index], center, r))\n",
    "        else:\n",
    "            pda_rel.append(pdas[index])\n",
    "    \n",
    "    pda_np = np.array(pda_rel)\n",
    "\n",
    "    current_minutes = current_time.hour * 60 + current_time.minute\n",
    "\n",
    "    charts_array = []\n",
    "    for candlesticks in charts:\n",
    "        charts_array.append([])\n",
    "        for candle in candlesticks:\n",
    "            o = relative(candle.o, center, r)\n",
    "            h = relative(candle.h, center, r)\n",
    "            l = relative(candle.l, center, r)\n",
    "            c = relative(candle.c, center, r)\n",
    "            charts_array[-1].append([o,h,l,c])\n",
    "\n",
    "    m15_np = np.array(charts_array[0])\n",
    "    m5_np = np.array(charts_array[1])\n",
    "    m1_np = np.array(charts_array[2])\n",
    "\n",
    "    return [m15_np, m5_np, m1_np, pda_np, current_minutes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cd5699d-6072-4afe-8e58-f529f228ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Order:\n",
    "    def __init__(self, limit, stop, tp, direction):\n",
    "        self.entry = limit\n",
    "        self.tp = tp\n",
    "        self.sl = stop\n",
    "        self.direction = direction\n",
    "\n",
    "class Position:\n",
    "    def __init__(self, entry, stop, tp, direction):\n",
    "        self.entry = entry\n",
    "        self.tp = tp\n",
    "        self.sl = stop\n",
    "        self.direction = direction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c1b7326-2b0f-49e6-86b1-815fd4ef4c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading EURUSD_2\n",
      "env reset, using data: ('EURUSD_2', 0.00015)\n"
     ]
    }
   ],
   "source": [
    "equity = 0\n",
    "equity_L = [0]\n",
    "\n",
    "inputs = [\n",
    "    (\"NQ_2\", 1),\n",
    "    (\"ES_2\", 0.75),\n",
    "    (\"YM_2\", 1.5),\n",
    "    (\"EURUSD_2\", 0.00015),\n",
    "    (\"GBPUSD_2\", 0.00015)\n",
    "]\n",
    "\n",
    "candles = []\n",
    "cmm = 0\n",
    "def reset():\n",
    "    global index, last_state, last_action, current_position, current_order, equity, m, candles, cmm\n",
    "\n",
    "    ob = random.choice(inputs)\n",
    "    candles = obj_load(ob[0])\n",
    "    cmm = ob[1]\n",
    "\n",
    "    m = MultiTimeframeCandleManager()\n",
    "\n",
    "    current_position = Position(0,0,0,0)\n",
    "    current_order = None\n",
    "\n",
    "    last_state = None\n",
    "    last_action = 0\n",
    "\n",
    "    index = 0\n",
    "    \n",
    "    print(\"env reset, using data:\", ob)\n",
    "\n",
    "def step():\n",
    "\n",
    "    global index, last_state, last_action, current_position, current_order, equity, m\n",
    "\n",
    "\n",
    "    sarts = None\n",
    "    while  sarts == None:\n",
    "\n",
    "        ret = m.push_m1_candle(candles[index])\n",
    "        midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "        center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
    "        r = max(0.0001, (midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
    "\n",
    "\n",
    "\n",
    "        current_candle_m1 = charts[2][-1]\n",
    "        #### check tp before filling order so that the same m1 candle will not trigger tp - it is not sure if the candle hit first limit and later tp or reve3rse        \n",
    "        if current_position.direction == 1:\n",
    "            if current_candle_m1.h >= current_position.tp:\n",
    "                pnl = (current_position.tp - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "        if current_position.direction == -1:\n",
    "            if current_candle_m1.l <= current_position.tp:\n",
    "                pnl = (current_position.tp - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "                \n",
    "        #### check order\n",
    "        if current_order != None:\n",
    "            if  current_order.direction == 1:\n",
    "                if current_candle_m1.l < current_order.entry:\n",
    "                    current_position = Position(current_order.entry, current_order.sl, current_order.tp, current_order.direction)\n",
    "                    #print(\"fill long order:\",current_order.entry, current_order.sl, current_order.tp)\n",
    "                    equity -= cmm\n",
    "                    current_order = None\n",
    "        if current_order != None:\n",
    "            if  current_order.direction == -1:\n",
    "                if current_candle_m1.h > current_order.entry:\n",
    "                    current_position = Position(current_order.entry, current_order.sl, current_order.tp, current_order.direction)\n",
    "                    #print(\"fill short order:\",current_order.entry, current_order.sl, current_order.tp)\n",
    "                    equity -= cmm\n",
    "                    current_order = None\n",
    "\n",
    "        #### check sl\n",
    "        if current_position.direction == 1:\n",
    "            if current_candle_m1.l <= current_position.sl:\n",
    "                pnl = (current_position.sl - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "        if current_position.direction == -1:\n",
    "            if current_candle_m1.h >= current_position.sl:\n",
    "                pnl = (current_position.sl - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "        if(len(m.fps) == 3 and len(m.opening_range_gaps) == 3 and len(m.asia_highs_lows) == 3 and len(m.london_highs_lows) == 3 and len(m.ny_am_highs_lows) == 3 and len(m.ny_lunch_highs_lows) == 3 and len(m.ny_pm_highs_lows) == 3):\n",
    "\n",
    "            \n",
    "            open_profit = (current_close - current_position.entry) * current_position.direction\n",
    "\n",
    "            scaled_entry_diff  =  0\n",
    "            scaled_sl_diff  =  0\n",
    "            if(current_position.direction != 0):\n",
    "                scaled_entry_diff = (current_close - current_position.entry) / r\n",
    "                scaled_sl_diff = (current_close - current_position.sl) / r\n",
    "\n",
    "            state = ret_to_scaled_inputs(ret) + [np.array([current_position.direction, scaled_entry_diff, scaled_sl_diff])]\n",
    "            m15_np, m5_np, m1_np, pda_np, current_minutes, pos_info = state\n",
    "\n",
    "            if(last_state != None):\n",
    "                diff = (equity+open_profit) - equity_L[-1]\n",
    "                equity_L.append(equity+open_profit)\n",
    "                reward =  (diff) / r\n",
    "                terminal = 0\n",
    "                if(index+1 == len(candles)):\n",
    "                    terminal = 1\n",
    "\n",
    "                sarts = last_state, last_action, reward, terminal, state\n",
    "\n",
    "\n",
    "            if(random.randint(0,100) > e):\n",
    "                output = model([\n",
    "                    tf.expand_dims(m15_np, 0),\n",
    "                    tf.expand_dims(m5_np, 0),\n",
    "                    tf.expand_dims(m1_np, 0),\n",
    "                    tf.expand_dims(pda_np, 0),\n",
    "                    tf.expand_dims(current_minutes, 0),\n",
    "                    tf.expand_dims(pos_info, 0)\n",
    "                ])\n",
    "\n",
    "                last_action = np.argmax(output)\n",
    "            else:\n",
    "                last_action = random.randint(0,num_actions-1)\n",
    "\n",
    "            last_state = state\n",
    "\n",
    "            current_order = None\n",
    "            \n",
    "            if(last_action == 2 and current_position.direction != 0):    \n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "            \n",
    "            if(last_action == 0 and current_position.direction == 1):    \n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "            if(last_action == 0 and current_position.direction == 0):\n",
    "                last_candle_low = charts[2][-2].l\n",
    "                if ( last_candle_low < current_close ):\n",
    "                    last_candle_low = None\n",
    "                    \n",
    "                pdas = m.normal_pdas ## (low, high)\n",
    "                \n",
    "                ## ignore pdas with low below close\n",
    "                pdas_filtered = []\n",
    "                for pda in pdas:\n",
    "                        if(pda[0] > current_close):\n",
    "                            pdas_filtered.append(pda)\n",
    "                ### sort\n",
    "                sorted_by_high = sorted(pdas_filtered, key = lambda x:x[1])\n",
    "                sorted_by_low = sorted(pdas_filtered, key = lambda x:x[0])\n",
    "\n",
    "                if(len(pdas_filtered) >= 3):\n",
    "                    ### sl is the high of 3 pdas\n",
    "                    sl = sorted_by_high[2][1]\n",
    "\n",
    "                    ### entry is lowest i can get or immediate rebalance\n",
    "                    entry = sorted_by_low[0][0]\n",
    "                    if(last_candle_low != None):\n",
    "                        entry = min(entry, last_candle_low)\n",
    "\n",
    "                    tp = entry  -  abs(entry-sl) * 1000\n",
    "\n",
    "                    current_order = Order(entry, sl, tp, -1)\n",
    "                    #print(\"set short order:\",entry,sl,tp)\n",
    "\n",
    "                    \n",
    "\n",
    "            if(last_action == 1 and current_position.direction == -1):    \n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "            if(last_action == 1 and current_position.direction == 0):\n",
    "                last_candle_high = charts[2][-2].h\n",
    "                if ( last_candle_high > current_close ):\n",
    "                    last_candle_high = None\n",
    "                pdas = m.normal_pdas ## (low, high)\n",
    "                \n",
    "                ## ignore pdas with low below close\n",
    "                pdas_filtered = []\n",
    "                for pda in pdas:\n",
    "                        if(pda[1] < current_close):\n",
    "                            pdas_filtered.append(pda)\n",
    "                ### sort\n",
    "                sorted_by_high = sorted(pdas_filtered, key = lambda x:x[1], reverse=True)\n",
    "                sorted_by_low = sorted(pdas_filtered, key = lambda x:x[0], reverse=True)\n",
    "\n",
    "                if(len(pdas_filtered) >= 3):\n",
    "                    ### sl is the high of 3 pdas\n",
    "                    sl = sorted_by_low[2][0]\n",
    "\n",
    "                    ### entry is lowest i can get or immediate rebalance\n",
    "                    entry = sorted_by_high[0][1]\n",
    "                    if(last_candle_high != None):\n",
    "                        entry = max(entry, last_candle_high)\n",
    "\n",
    "                    tp = entry  +  abs(entry-sl) * 1000\n",
    "\n",
    "                    current_order = Order(entry, sl, tp, 1)\n",
    "                    #print(\"set long order:\",entry,sl,tp)\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        index += 1\n",
    "        if(index == len(candles)):\n",
    "            reset()\n",
    "\n",
    "    return sarts\n",
    "\n",
    "reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b0100b3-b15d-4278-8cdf-56dcb74237b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -2.4999999999998894 -1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_candles(candles):\n",
    "    for index in range(len(candles)):\n",
    "        candle = candles[index]    \n",
    "        c = \"green\" if candle.c > candle.o else \"black\"\n",
    "        plt.plot([index, index], [candle.l, candle.h], linewidth=1, color = \"black\")\n",
    "        plt.plot([index, index], [candle.c, candle.o], linewidth=3, color = c)\n",
    "sarts = step()\n",
    "\n",
    "plot_candles(m.m1_candles)\n",
    "if(current_position.direction != 0):\n",
    "    plt.axhline(current_position.entry, color = \"g\" if current_position.direction == 1 else \"r\")\n",
    "    plt.axhline(current_position.sl, color = \"orange\")\n",
    "\n",
    "if(current_order != None):\n",
    "    plt.axhline(current_order.entry, color = \"g\" if current_order.direction == 1 else \"r\")\n",
    "    plt.axhline(current_order.sl, color = \"orange\")\n",
    "\n",
    "\n",
    "print(sarts[1], sarts[2], current_position.direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d92f99f8-68df-4fbd-bc4d-218a2a43f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def get_target_q(next_states, rewards, terminals):\n",
    "            estimated_q_values_next = target_model(next_states)\n",
    "            q_batch = tf.math.reduce_max(estimated_q_values_next, axis=1)\n",
    "            target_q_values = q_batch * gamma * (1-terminals) + rewards\n",
    "            return target_q_values\n",
    "\n",
    "@tf.function()\n",
    "def tstep(data):\n",
    "    states, masks, rewards, terminals, next_states = data\n",
    "    \n",
    "    target_q_values = get_target_q(next_states, rewards, terminals)\n",
    "\n",
    "    with tf.GradientTape() as t:\n",
    "        model_return = model(states, training=True)\n",
    "        mask_return = model_return * masks\n",
    "        estimated_q_values = tf.math.reduce_sum(mask_return, axis=1)\n",
    "        #print(estimated_q_values, mask_return, model_return, masks)\n",
    "        loss_e = tf.math.square(target_q_values - estimated_q_values)\n",
    "        loss = tf.reduce_mean(loss_e)\n",
    "\n",
    "    \n",
    "    gradient = t.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
    "\n",
    "    return loss, tf.reduce_mean(estimated_q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd706ba5-8f9c-4889-a382-46f25bc9653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(n):\n",
    "        r = random.randint(0, len(sarts_memory) - batch_size)\n",
    "        sarts_sample = [sarts_memory[i] for i in range(r, r + batch_size)]\n",
    "        \n",
    "\n",
    "    \n",
    "        states = [x[0] for x in sarts_sample]\n",
    "        actions = [x[1] for x in sarts_sample]\n",
    "        rewards = np.array([x[2] for x in sarts_sample], dtype=\"float32\")\n",
    "        terminals = np.array([x[3] for x in sarts_sample], dtype=\"float32\")\n",
    "        next_states = [x[4] for x in sarts_sample]\n",
    "    \n",
    "        next_states_array = []\n",
    "        for i in range(num_model_inputs):\n",
    "            next_states_array.append(np.array([x[i] for x in next_states], dtype = \"float32\"))\n",
    "    \n",
    "    \n",
    "        states_array = []\n",
    "        for i in range(num_model_inputs):\n",
    "            states_array.append(np.array([x[i] for x in states], dtype = \"float32\"))\n",
    "    \n",
    "    \n",
    "        masks = np.array(m1[actions], dtype=\"float32\")\n",
    "\n",
    "\n",
    "        return states_array, masks, rewards, terminals, next_states_array\n",
    "\n",
    "def run():\n",
    "    sarts = step()\n",
    "    sarts_memory.append(sarts)\n",
    "\n",
    "    if(len(sarts_memory) > min_memory_size):\n",
    "    \n",
    "        loss, q = tstep(get_data(0))\n",
    "\n",
    "        return loss, q, sarts[2], sarts[1]\n",
    "        \n",
    "    else :\n",
    "        return 0,0, sarts[2], sarts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c5b3f0b-f6a8-4b12-9bc1-74330da8575a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ./loss\n",
      "loading ./q\n",
      "loading ./rewards\n"
     ]
    }
   ],
   "source": [
    "loss_mean = []\n",
    "q_mean = []\n",
    "rewards = []\n",
    "\n",
    "try:\n",
    "    model.load_weights(path+\"model.weights.h5\")\n",
    "    target_model.load_weights(path+\"model.weights.h5\")\n",
    "\n",
    "    loss_mean = obj_load(path+\"loss\")\n",
    "    q_mean = obj_load(path+\"q\")\n",
    "    rewards = obj_load(path+\"rewards\")\n",
    "except:\n",
    "    print(\"unable to load data\")\n",
    "\n",
    "\n",
    "def save():\n",
    "            model.save_weights(path+\"model.weights.h5\")\n",
    "            obj_save(loss_mean, path+\"loss\")\n",
    "            obj_save(q_mean, path+\"q\")\n",
    "            obj_save(rewards, path+\"rewards\")\n",
    "            print(\"saved progress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a15d1bbb-b532-45b5-92bb-3bb84375b744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 447/1000 [============>.................] - ETA: 1:38 - loss: 23.4633 - qv: 174.7260 - reward: -0.2394 - avg_action: 1.0895  \n",
      "exit\n",
      "saved progress\n"
     ]
    }
   ],
   "source": [
    "safe_after_eps = 10\n",
    "eps_counter=0\n",
    "\n",
    "while True:\n",
    "    eps_counter+=1\n",
    "    try:\n",
    "        loss = []\n",
    "        q = []\n",
    "        rewards_tmp = []\n",
    "        actions = []\n",
    "        progbar = tf.keras.utils.Progbar(ep_len)\n",
    "        for i in range(ep_len):\n",
    "            c_loss, c_q, c_rewards, c_action = run()\n",
    "            loss.append(c_loss)\n",
    "            q.append(c_q)\n",
    "            #rewards_tmp.append(c_rewards)\n",
    "            rewards.append(c_rewards)\n",
    "            actions.append(c_action)\n",
    "\n",
    "            progbar.update(i+1, values = [(\"loss\", c_loss), (\"qv\", c_q), (\"reward\", c_rewards), (\"avg_action\", c_action)])\n",
    "\n",
    "        loss_mean.append(np.mean(loss))\n",
    "        q_mean.append(np.mean(q))\n",
    "        #rewards.append(np.mean(rewards_tmp))\n",
    "        \n",
    "        #progbar.update(ep_len, values = [(\"loss\", np.mean(loss)), (\"qv\", np.mean(q)), (\"reward\", np.mean(rewards)), (\"avg_action\", np.mean(actions))])\n",
    "\n",
    "        target_model.set_weights(model.get_weights())\n",
    "\n",
    "        if(eps_counter >= safe_after_eps):\n",
    "            eps_counter = 0\n",
    "            save()\n",
    "\n",
    "\n",
    "    except    KeyboardInterrupt:\n",
    "        print(\"\")\n",
    "        print(\"exit\")\n",
    "        save()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b536a1d7-a655-4d08-9e9d-c8cbf420a885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a89278c-2823-4e36-8746-908718c80748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7355fab-87a0-4bf6-9558-f6c3bcc2ac5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14d4810-1313-47ad-a750-84baabd912b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd0d505-c92c-4d63-b7cf-6b5260508909",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
