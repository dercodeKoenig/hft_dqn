{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b197691-b458-4cbf-943f-14c353d9da30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MultiTimeframeCandleManager import MultiTimeframeCandleManager\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from save_and_load import *\n",
    "from Candle import Candle\n",
    "import matplotlib.pyplot as plt\n",
    "#from tensorflow.keras import mixed_precision\n",
    "#mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a46f09d-bcd5-4f57-a637-d75e36e4bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.995\n",
    "memory_len = 500000\n",
    "sarts_memory = deque(maxlen = memory_len)\n",
    "batch_size = 32\n",
    "e = 2\n",
    "\n",
    "min_memory_size = 128\n",
    "\n",
    "num_actions = 3\n",
    "\n",
    "path = \"./\"\n",
    "\n",
    "ep_len = 1000\n",
    "\n",
    "m1 = np.eye(num_actions, dtype=\"float32\")\n",
    "num_model_inputs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "390662b5-22d2-4aa9-a457-d598fdb81fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 79)]         0           []                               \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 60, 79)       0           ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 60, 83)       0           ['input_9[0][0]',                \n",
      "                                                                  'lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 60, 256)      21504       ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      multiple             0           ['dense_15[0][0]',               \n",
      "                                                                  'dense_16[0][0]',               \n",
      "                                                                  'dense_17[0][0]',               \n",
      "                                                                  'dense_18[0][0]',               \n",
      "                                                                  'dense_19[0][0]',               \n",
      "                                                                  'dense_20[0][0]',               \n",
      "                                                                  'dense_21[0][0]',               \n",
      "                                                                  'dense_22[0][0]',               \n",
      "                                                                  'dense_23[0][0]',               \n",
      "                                                                  'dense_24[0][0]',               \n",
      "                                                                  'dense_25[0][0]',               \n",
      "                                                                  'dense_26[0][0]',               \n",
      "                                                                  'dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 60, 256)      65792       ['leaky_re_lu_1[6][0]']          \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 60, 83)       0           ['input_8[0][0]',                \n",
      "                                                                  'lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 60, 256)      65792       ['leaky_re_lu_1[7][0]']          \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 60, 256)      21504       ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 60, 256)      65792       ['leaky_re_lu_1[3][0]']          \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 60, 83)       0           ['input_7[0][0]',                \n",
      "                                                                  'lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 60, 256)      65792       ['leaky_re_lu_1[4][0]']          \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 60, 256)      21504       ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 60, 256)      65792       ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 60, 256)      65792       ['leaky_re_lu_1[1][0]']          \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 1, 8)         11520       ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 240)          0           ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 240)          0           ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)            (None, 240)          0           ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 8)            0           ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " gru_5 (GRU)                    (None, 128)          148224      ['leaky_re_lu_1[8][0]']          \n",
      "                                                                                                  \n",
      " gru_4 (GRU)                    (None, 128)          148224      ['leaky_re_lu_1[5][0]']          \n",
      "                                                                                                  \n",
      " gru_3 (GRU)                    (None, 128)          148224      ['leaky_re_lu_1[2][0]']          \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 1194)         0           ['flatten_5[0][0]',              \n",
      "                                                                  'flatten_6[0][0]',              \n",
      "                                                                  'flatten_7[0][0]',              \n",
      "                                                                  'input_10[0][0]',               \n",
      "                                                                  'flatten_4[0][0]',              \n",
      "                                                                  'input_11[0][0]',               \n",
      "                                                                  'gru_5[0][0]',                  \n",
      "                                                                  'gru_4[0][0]',                  \n",
      "                                                                  'gru_3[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 8192)         9789440     ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 8192)         67117056    ['leaky_re_lu_1[9][0]']          \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 8192)         67117056    ['leaky_re_lu_1[10][0]']         \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 8192)         67117056    ['leaky_re_lu_1[11][0]']         \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 1)            8193        ['leaky_re_lu_1[12][0]']         \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 3)            24579       ['leaky_re_lu_1[12][0]']         \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 3)            0           ['dense_28[0][0]',               \n",
      "                                                                  'dense_29[0][0]']               \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 3)            0           ['lambda_2[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 212,088,836\n",
      "Trainable params: 212,088,836\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lrelu = tf.keras.layers.LeakyReLU(0.05)\n",
    "\n",
    "\n",
    "chart_m15 = tf.keras.layers.Input(shape = (60,4))\n",
    "chart_m5 = tf.keras.layers.Input(shape = (60,4))\n",
    "chart_m1 = tf.keras.layers.Input(shape = (60,4))\n",
    "\n",
    "pdas = tf.keras.layers.Input(shape = (19+12*5,))\n",
    "\n",
    "current_position = tf.keras.layers.Input(shape = (3,))\n",
    "\n",
    "minutes = tf.keras.layers.Input(shape = (1,))\n",
    "minutes_embed = tf.keras.layers.Embedding(input_dim=60*24, output_dim=8)(minutes)\n",
    "minutes_embed_flat = tf.keras.layers.Flatten()(minutes_embed)\n",
    "\n",
    "f15 = tf.keras.layers.Flatten()(chart_m15)\n",
    "f5 = tf.keras.layers.Flatten()(chart_m5)\n",
    "f1 = tf.keras.layers.Flatten()(chart_m1)\n",
    "\n",
    "pdas_repeated = tf.keras.layers.Lambda(\n",
    "lambda inputs: tf.repeat(tf.expand_dims(inputs, axis = 1), repeats=60, axis=1)\n",
    ")(pdas)\n",
    "\n",
    "concatenated_m15_at = tf.keras.layers.Concatenate(axis=-1)([chart_m15, pdas_repeated])\n",
    "m15_at = tf.keras.layers.Dense(256)(concatenated_m15_at)\n",
    "m15_at = lrelu(m15_at)\n",
    "m15_at = tf.keras.layers.Dense(256)(m15_at)\n",
    "m15_at = lrelu(m15_at)\n",
    "m15_at = tf.keras.layers.Dense(256)(m15_at)\n",
    "m15_at = lrelu(m15_at)\n",
    "m15_rnn = tf.keras.layers.GRU(128)(m15_at)\n",
    "\n",
    "concatenated_m5_at = tf.keras.layers.Concatenate(axis=-1)([chart_m5, pdas_repeated])\n",
    "m5_at = tf.keras.layers.Dense(256)(concatenated_m5_at)\n",
    "m5_at = lrelu(m5_at)\n",
    "m5_at = tf.keras.layers.Dense(256)(m5_at)\n",
    "m5_at = lrelu(m5_at)\n",
    "m5_at = tf.keras.layers.Dense(256)(m5_at)\n",
    "m5_at = lrelu(m5_at)\n",
    "m5_rnn = tf.keras.layers.GRU(128)(m5_at)\n",
    "\n",
    "concatenated_m1_at = tf.keras.layers.Concatenate(axis=-1)([chart_m1, pdas_repeated])\n",
    "m1_at = tf.keras.layers.Dense(256)(concatenated_m1_at)\n",
    "m1_at = lrelu(m1_at)\n",
    "m1_at = tf.keras.layers.Dense(256)(m1_at)\n",
    "m1_at = lrelu(m1_at)\n",
    "m1_at = tf.keras.layers.Dense(256)(m1_at)\n",
    "m1_at = lrelu(m1_at)\n",
    "m1_rnn = tf.keras.layers.GRU(128)(m1_at)\n",
    "\n",
    "#c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, scaled_open_profit])\n",
    "c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, m1_rnn, m5_rnn, m15_rnn])\n",
    "\n",
    "d = tf.keras.layers.Dense(1024*8)(c)\n",
    "d = lrelu(d)\n",
    "d = tf.keras.layers.Dense(1024*8)(d)\n",
    "d = lrelu(d)\n",
    "d = tf.keras.layers.Dense(1024*8)(d)\n",
    "d = lrelu(d)\n",
    "d = tf.keras.layers.Dense(1024*8)(d)\n",
    "d = lrelu(d)\n",
    "\n",
    "\n",
    "value = tf.keras.layers.Dense(1, activation=\"linear\")(d)\n",
    "advantage = tf.keras.layers.Dense(num_actions, activation=\"linear\")(d)\n",
    "\n",
    "q_values = tf.keras.layers.Lambda(\n",
    "lambda inputs: inputs[0] + (inputs[1] - tf.reduce_mean(inputs[1], axis=1, keepdims=True))\n",
    ")([value, advantage])\n",
    "\n",
    "outputs = tf.keras.layers.Activation('linear', dtype='float32')(q_values)\n",
    "\n",
    "model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = outputs)\n",
    "target_model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = outputs)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001)\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f069d41-781f-439b-b12a-59bd3e1f29e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def relative (value, center, r):\n",
    "        return (value - center) / r\n",
    "\n",
    "def ret_to_scaled_inputs(ret):\n",
    "\n",
    "    midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "    \n",
    "\n",
    "    center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
    "    r = max(0.0001,(midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
    "\n",
    "    pda_rel = []\n",
    "    pda_rel.append(relative(midnight_open, center, r))\n",
    "    for pda in pdas[0:18]:\n",
    "        pda_rel.append(relative(pda, center, r))\n",
    "    for index in range(18,18+5*12):\n",
    "        ## highs lows are like this [h, h_taken, l, l_taken]\n",
    "        ## the bools should not be scaled\n",
    "        if (index - 18) % 2 == 0:\n",
    "            pda_rel.append(relative(pdas[index], center, r))\n",
    "        else:\n",
    "            pda_rel.append(pdas[index])\n",
    "    \n",
    "    pda_np = np.array(pda_rel)\n",
    "\n",
    "    current_minutes = current_time.hour * 60 + current_time.minute\n",
    "\n",
    "    charts_array = []\n",
    "    for candlesticks in charts:\n",
    "        charts_array.append([])\n",
    "        for candle in candlesticks:\n",
    "            o = relative(candle.o, center, r)\n",
    "            h = relative(candle.h, center, r)\n",
    "            l = relative(candle.l, center, r)\n",
    "            c = relative(candle.c, center, r)\n",
    "            charts_array[-1].append([o,h,l,c])\n",
    "\n",
    "    m15_np = np.array(charts_array[0])\n",
    "    m5_np = np.array(charts_array[1])\n",
    "    m1_np = np.array(charts_array[2])\n",
    "\n",
    "    return [m15_np, m5_np, m1_np, pda_np, current_minutes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cd5699d-6072-4afe-8e58-f529f228ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Order:\n",
    "    def __init__(self, limit, stop, tp, direction):\n",
    "        self.entry = limit\n",
    "        self.tp = tp\n",
    "        self.sl = stop\n",
    "        self.direction = direction\n",
    "\n",
    "class Position:\n",
    "    def __init__(self, entry, stop, tp, direction):\n",
    "        self.entry = entry\n",
    "        self.tp = tp\n",
    "        self.sl = stop\n",
    "        self.direction = direction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c1b7326-2b0f-49e6-86b1-815fd4ef4c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading EURUSD_2\n",
      "env reset, using data: ('EURUSD_2', 0.00015)\n"
     ]
    }
   ],
   "source": [
    "equity = 0\n",
    "equity_L = [0]\n",
    "\n",
    "inputs = [\n",
    "    (\"NQ_2\", 1),\n",
    "    (\"ES_2\", 0.75),\n",
    "    (\"YM_2\", 1.5),\n",
    "    (\"EURUSD_2\", 0.00015),\n",
    "    (\"GBPUSD_2\", 0.00015)\n",
    "]\n",
    "\n",
    "candles = []\n",
    "cmm = 0\n",
    "def reset():\n",
    "    global index, last_state, last_action, current_position, current_order, equity, m, candles, cmm\n",
    "\n",
    "    ob = random.choice(inputs)\n",
    "    candles = obj_load(ob[0])\n",
    "    cmm = ob[1]\n",
    "\n",
    "    m = MultiTimeframeCandleManager()\n",
    "\n",
    "    current_position = Position(0,0,0,0)\n",
    "    current_order = None\n",
    "\n",
    "    last_state = None\n",
    "    last_action = 0\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    print(\"env reset, using data:\", ob)\n",
    "\n",
    "\n",
    "@tf.function()\n",
    "def inference_step(m15_np, m5_np, m1_np, pda_np, current_minutes, pos_info):\n",
    "    return model([\n",
    "        m15_np, \n",
    "        m5_np, \n",
    "        m1_np, \n",
    "        pda_np, \n",
    "        current_minutes, \n",
    "        pos_info,\n",
    "    ])\n",
    "    \n",
    "\n",
    "def step():\n",
    "\n",
    "    global index, last_state, last_action, current_position, current_order, equity, m\n",
    "\n",
    "\n",
    "    sarts = None\n",
    "    while  sarts == None:\n",
    "\n",
    "        ret = m.push_m1_candle(candles[index])\n",
    "        midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "        center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
    "        r = max(0.0001, (midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
    "\n",
    "\n",
    "\n",
    "        current_candle_m1 = charts[2][-1]\n",
    "        #### check tp before filling order so that the same m1 candle will not trigger tp - it is not sure if the candle hit first limit and later tp or reve3rse\n",
    "        if current_position.direction == 1:\n",
    "            if current_candle_m1.h >= current_position.tp:\n",
    "                pnl = (current_position.tp - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "        if current_position.direction == -1:\n",
    "            if current_candle_m1.l <= current_position.tp:\n",
    "                pnl = (current_position.tp - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "        #### check order\n",
    "        if current_order != None:\n",
    "            if  current_order.direction == 1:\n",
    "                if current_candle_m1.l < current_order.entry:\n",
    "                    current_position = Position(current_order.entry, current_order.sl, current_order.tp, current_order.direction)\n",
    "                    #print(\"fill long order:\",current_order.entry, current_order.sl, current_order.tp)\n",
    "                    equity -= cmm\n",
    "                    current_order = None\n",
    "        if current_order != None:\n",
    "            if  current_order.direction == -1:\n",
    "                if current_candle_m1.h > current_order.entry:\n",
    "                    current_position = Position(current_order.entry, current_order.sl, current_order.tp, current_order.direction)\n",
    "                    #print(\"fill short order:\",current_order.entry, current_order.sl, current_order.tp)\n",
    "                    equity -= cmm\n",
    "                    current_order = None\n",
    "\n",
    "        #### check sl\n",
    "        if current_position.direction == 1:\n",
    "            if current_candle_m1.l <= current_position.sl:\n",
    "                pnl = (current_position.sl - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "        if current_position.direction == -1:\n",
    "            if current_candle_m1.h >= current_position.sl:\n",
    "                pnl = (current_position.sl - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if(len(m.fps) == 3 and len(m.opening_range_gaps) == 3 and len(m.asia_highs_lows) == 3 and len(m.london_highs_lows) == 3 and len(m.ny_am_highs_lows) == 3 and len(m.ny_lunch_highs_lows) == 3 and len(m.ny_pm_highs_lows) == 3):\n",
    "\n",
    "\n",
    "            open_profit = (current_close - current_position.entry) * current_position.direction\n",
    "\n",
    "            scaled_entry_diff  =  0\n",
    "            scaled_sl_diff  =  0\n",
    "            if(current_position.direction != 0):\n",
    "                scaled_entry_diff = (current_close - current_position.entry) / r\n",
    "                scaled_sl_diff = (current_close - current_position.sl) / r\n",
    "\n",
    "            state = ret_to_scaled_inputs(ret) + [np.array([current_position.direction, scaled_entry_diff, scaled_sl_diff])]\n",
    "            m15_np, m5_np, m1_np, pda_np, current_minutes, pos_info = state\n",
    "\n",
    "            if(last_state != None):\n",
    "                diff = (equity+open_profit) - equity_L[-1]\n",
    "                equity_L.append(equity+open_profit)\n",
    "                reward =  (diff) / r\n",
    "                terminal = 0\n",
    "                if(index+1 == len(candles)):\n",
    "                    terminal = 1\n",
    "\n",
    "                sarts = last_state, last_action, reward, terminal, state\n",
    "\n",
    "\n",
    "            if(random.randint(0,100) > e):\n",
    "                #with tf.device(\"/TPU:0\"):\n",
    "                output = inference_step(\n",
    "                        tf.expand_dims(m15_np, 0),\n",
    "                        tf.expand_dims(m5_np, 0),\n",
    "                        tf.expand_dims(m1_np, 0),\n",
    "                        tf.expand_dims(pda_np, 0),\n",
    "                        tf.expand_dims(current_minutes, 0),\n",
    "                        tf.expand_dims(pos_info, 0)\n",
    "                )\n",
    "\n",
    "                last_action = np.argmax(output)\n",
    "            else:\n",
    "                last_action = random.randint(0,num_actions-1)\n",
    "\n",
    "            last_state = state\n",
    "\n",
    "            current_order = None\n",
    "\n",
    "            if(last_action == 2 and current_position.direction != 0):\n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "            if(last_action == 0 and current_position.direction == 1):\n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "            if(last_action == 0 and current_position.direction == 0):\n",
    "                last_candle_low = charts[2][-2].l\n",
    "                if ( last_candle_low < current_close ):\n",
    "                    last_candle_low = None\n",
    "\n",
    "                pdas = m.normal_pdas ## (low, high)\n",
    "\n",
    "                ## ignore pdas with low below close\n",
    "                pdas_filtered = []\n",
    "                for pda in pdas:\n",
    "                        if(pda[0] > current_close):\n",
    "                            pdas_filtered.append(pda)\n",
    "                ### sort\n",
    "                sorted_by_high = sorted(pdas_filtered, key = lambda x:x[1])\n",
    "                sorted_by_low = sorted(pdas_filtered, key = lambda x:x[0])\n",
    "\n",
    "                if(len(pdas_filtered) >= 3):\n",
    "                    ### sl is the high of 3 pdas\n",
    "                    sl = sorted_by_high[2][1]\n",
    "\n",
    "                    ### entry is lowest i can get or immediate rebalance\n",
    "                    entry = sorted_by_low[0][0]\n",
    "                    if(last_candle_low != None):\n",
    "                        entry = min(entry, last_candle_low)\n",
    "\n",
    "                    tp = entry  -  abs(entry-sl) * 1000\n",
    "\n",
    "                    current_order = Order(entry, sl, tp, -1)\n",
    "                    #print(\"set short order:\",entry,sl,tp)\n",
    "\n",
    "\n",
    "\n",
    "            if(last_action == 1 and current_position.direction == -1):\n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "            if(last_action == 1 and current_position.direction == 0):\n",
    "                last_candle_high = charts[2][-2].h\n",
    "                if ( last_candle_high > current_close ):\n",
    "                    last_candle_high = None\n",
    "                pdas = m.normal_pdas ## (low, high)\n",
    "\n",
    "                ## ignore pdas with low below close\n",
    "                pdas_filtered = []\n",
    "                for pda in pdas:\n",
    "                        if(pda[1] < current_close):\n",
    "                            pdas_filtered.append(pda)\n",
    "                ### sort\n",
    "                sorted_by_high = sorted(pdas_filtered, key = lambda x:x[1], reverse=True)\n",
    "                sorted_by_low = sorted(pdas_filtered, key = lambda x:x[0], reverse=True)\n",
    "\n",
    "                if(len(pdas_filtered) >= 3):\n",
    "                    ### sl is the high of 3 pdas\n",
    "                    sl = sorted_by_low[2][0]\n",
    "\n",
    "                    ### entry is lowest i can get or immediate rebalance\n",
    "                    entry = sorted_by_high[0][1]\n",
    "                    if(last_candle_high != None):\n",
    "                        entry = max(entry, last_candle_high)\n",
    "\n",
    "                    tp = entry  +  abs(entry-sl) * 1000\n",
    "\n",
    "                    current_order = Order(entry, sl, tp, 1)\n",
    "                    #print(\"set long order:\",entry,sl,tp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        index += 1\n",
    "        if(index == len(candles)):\n",
    "            reset()\n",
    "\n",
    "    return sarts\n",
    "\n",
    "reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b0100b3-b15d-4278-8cdf-56dcb74237b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.0 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_candles(candles):\n",
    "    for index in range(len(candles)):\n",
    "        candle = candles[index]    \n",
    "        c = \"green\" if candle.c > candle.o else \"black\"\n",
    "        plt.plot([index, index], [candle.l, candle.h], linewidth=1, color = \"black\")\n",
    "        plt.plot([index, index], [candle.c, candle.o], linewidth=3, color = c)\n",
    "sarts = step()\n",
    "\n",
    "plot_candles(m.m1_candles)\n",
    "if(current_position.direction != 0):\n",
    "    plt.axhline(current_position.entry, color = \"g\" if current_position.direction == 1 else \"r\")\n",
    "    plt.axhline(current_position.sl, color = \"orange\")\n",
    "\n",
    "if(current_order != None):\n",
    "    plt.axhline(current_order.entry, color = \"g\" if current_order.direction == 1 else \"r\")\n",
    "    plt.axhline(current_order.sl, color = \"orange\")\n",
    "\n",
    "\n",
    "print(sarts[1], sarts[2], current_position.direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d92f99f8-68df-4fbd-bc4d-218a2a43f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def get_target_q(next_states, rewards, terminals):\n",
    "            estimated_q_values_next = target_model(next_states)\n",
    "            q_batch = tf.math.reduce_max(estimated_q_values_next, axis=1)\n",
    "            target_q_values = q_batch * gamma * (1-terminals) + rewards\n",
    "            return target_q_values\n",
    "\n",
    "@tf.function()\n",
    "def tstep(data):\n",
    "    states, masks, rewards, terminals, next_states = data\n",
    "    \n",
    "    target_q_values = get_target_q(next_states, rewards, terminals)\n",
    "\n",
    "    with tf.GradientTape() as t:\n",
    "        model_return = model(states, training=True)\n",
    "        mask_return = model_return * masks\n",
    "        estimated_q_values = tf.math.reduce_sum(mask_return, axis=1)\n",
    "        #print(estimated_q_values, mask_return, model_return, masks)\n",
    "        loss_e = tf.math.square(target_q_values - estimated_q_values)\n",
    "        loss = tf.reduce_mean(loss_e)\n",
    "\n",
    "    \n",
    "    gradient = t.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
    "\n",
    "    return loss, tf.reduce_mean(estimated_q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd706ba5-8f9c-4889-a382-46f25bc9653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(n):\n",
    "        r = random.randint(0, len(sarts_memory) - batch_size)\n",
    "        sarts_sample = [sarts_memory[i] for i in range(r, r + batch_size)]\n",
    "        \n",
    "\n",
    "    \n",
    "        states = [x[0] for x in sarts_sample]\n",
    "        actions = [x[1] for x in sarts_sample]\n",
    "        rewards = np.array([x[2] for x in sarts_sample], dtype=\"float32\")\n",
    "        terminals = np.array([x[3] for x in sarts_sample], dtype=\"float32\")\n",
    "        next_states = [x[4] for x in sarts_sample]\n",
    "    \n",
    "        next_states_array = []\n",
    "        for i in range(num_model_inputs):\n",
    "            next_states_array.append(np.array([x[i] for x in next_states], dtype = \"float32\"))\n",
    "    \n",
    "    \n",
    "        states_array = []\n",
    "        for i in range(num_model_inputs):\n",
    "            states_array.append(np.array([x[i] for x in states], dtype = \"float32\"))\n",
    "    \n",
    "    \n",
    "        masks = np.array(m1[actions], dtype=\"float32\")\n",
    "\n",
    "\n",
    "        return states_array, masks, rewards, terminals, next_states_array\n",
    "\n",
    "def run():\n",
    "    sarts = step()\n",
    "    sarts_memory.append(sarts)\n",
    "\n",
    "    if(len(sarts_memory) > min_memory_size):\n",
    "    \n",
    "        loss, q = tstep(get_data(0))\n",
    "\n",
    "        return loss, q, sarts[2], sarts[1]\n",
    "        \n",
    "    else :\n",
    "        return 0,0, sarts[2], sarts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c5b3f0b-f6a8-4b12-9bc1-74330da8575a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable to load data\n"
     ]
    }
   ],
   "source": [
    "loss_mean = []\n",
    "q_mean = []\n",
    "rewards = []\n",
    "\n",
    "try:\n",
    "    model.load_weights(path+\"model.weights.h5\")\n",
    "    target_model.load_weights(path+\"model.weights.h5\")\n",
    "\n",
    "    loss_mean = obj_load(path+\"loss\")\n",
    "    q_mean = obj_load(path+\"q\")\n",
    "    rewards = obj_load(path+\"rewards\")\n",
    "except:\n",
    "    print(\"unable to load data\")\n",
    "\n",
    "\n",
    "def save():\n",
    "            model.save_weights(path+\"model.weights.h5\")\n",
    "            obj_save(loss_mean, path+\"loss\")\n",
    "            obj_save(q_mean, path+\"q\")\n",
    "            obj_save(rewards, path+\"rewards\")\n",
    "            print(\"saved progress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a15d1bbb-b532-45b5-92bb-3bb84375b744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 711/1000 [====================>.........] - ETA: 1:03 - loss: 12220.9463 - qv: 10480.6191 - reward: -0.1800 - avg_action: 1.0084   \n",
      "exit\n",
      "saved progress\n"
     ]
    }
   ],
   "source": [
    "safe_after_eps = 10\n",
    "eps_counter=0\n",
    "\n",
    "while True:\n",
    "    eps_counter+=1\n",
    "    try:\n",
    "        loss = []\n",
    "        q = []\n",
    "        rewards_tmp = []\n",
    "        actions = []\n",
    "        progbar = tf.keras.utils.Progbar(ep_len)\n",
    "        for i in range(ep_len):\n",
    "            c_loss, c_q, c_rewards, c_action = run()\n",
    "            loss.append(c_loss)\n",
    "            q.append(c_q)\n",
    "            #rewards_tmp.append(c_rewards)\n",
    "            rewards.append(c_rewards)\n",
    "            actions.append(c_action)\n",
    "\n",
    "            progbar.update(i+1, values = [(\"loss\", c_loss), (\"qv\", c_q), (\"reward\", c_rewards), (\"avg_action\", c_action)])\n",
    "\n",
    "        loss_mean.append(np.mean(loss))\n",
    "        q_mean.append(np.mean(q))\n",
    "        #rewards.append(np.mean(rewards_tmp))\n",
    "        \n",
    "        #progbar.update(ep_len, values = [(\"loss\", np.mean(loss)), (\"qv\", np.mean(q)), (\"reward\", np.mean(rewards)), (\"avg_action\", np.mean(actions))])\n",
    "\n",
    "        target_model.set_weights(model.get_weights())\n",
    "\n",
    "        if(eps_counter >= safe_after_eps):\n",
    "            eps_counter = 0\n",
    "            save()\n",
    "\n",
    "\n",
    "    except    KeyboardInterrupt:\n",
    "        print(\"\")\n",
    "        print(\"exit\")\n",
    "        save()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b536a1d7-a655-4d08-9e9d-c8cbf420a885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a89278c-2823-4e36-8746-908718c80748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7355fab-87a0-4bf6-9558-f6c3bcc2ac5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14d4810-1313-47ad-a750-84baabd912b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd0d505-c92c-4d63-b7cf-6b5260508909",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
