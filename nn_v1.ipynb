{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b016dd-ef7a-4222-9ef6-02f9ecc88d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "import os\n",
    "from MultiTimeframeCandleManager import MultiTimeframeCandleManager\n",
    "from datetime import datetime, timedelta\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from save_and_load import *\n",
    "from Candle import Candle\n",
    "import matplotlib.pyplot as plt\n",
    "#from tensorflow.keras import mixed_precision\n",
    "#mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "try:\n",
    "    cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"local\")\n",
    "    tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
    "    strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
    "    print(\"use tpu strategy\")\n",
    "except:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "strategy\n",
    "\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "\n",
    "  lrelu = tf.keras.layers.LeakyReLU(0.05)\n",
    "\n",
    "\n",
    "  chart_m15 = tf.keras.layers.Input(shape = (60,4))\n",
    "  chart_m5 = tf.keras.layers.Input(shape = (60,4))\n",
    "  chart_m1 = tf.keras.layers.Input(shape = (60,4))\n",
    "\n",
    "  pdas = tf.keras.layers.Input(shape = (3*3+3*3+1+12*5+5*3,))\n",
    "\n",
    "  #current_position = tf.keras.layers.Input(shape = (3,))\n",
    "\n",
    "  minutes = tf.keras.layers.Input(shape = (1,))\n",
    "  minutes_embed = tf.keras.layers.Embedding(input_dim=60*24, output_dim=8)(minutes)\n",
    "  minutes_embed_flat = tf.keras.layers.Flatten()(minutes_embed)\n",
    "\n",
    "  f15 = tf.keras.layers.Flatten()(chart_m15)\n",
    "  f5 = tf.keras.layers.Flatten()(chart_m5)\n",
    "  f1 = tf.keras.layers.Flatten()(chart_m1)\n",
    "\n",
    "  pdas_repeated = tf.keras.layers.Lambda(\n",
    "  lambda inputs: tf.repeat(tf.expand_dims(inputs, axis = 1), repeats=60, axis=1)\n",
    "  )(pdas)\n",
    "\n",
    "  concatenated_m5_at = tf.keras.layers.Concatenate(axis=-1)([chart_m5, pdas_repeated])\n",
    "  m5_at = tf.keras.layers.Dense(256)(concatenated_m5_at)\n",
    "  m5_at = lrelu(m5_at)\n",
    "  m5_at = tf.keras.layers.Dense(128)(m5_at)\n",
    "  m5_at = lrelu(m5_at)\n",
    "  m5_at = tf.keras.layers.Dense(64)(m5_at)\n",
    "  m5_at = lrelu(m5_at)\n",
    "  m5_at = tf.keras.layers.LSTM(128)(m5_at)\n",
    "\n",
    "  concatenated_m1_at = tf.keras.layers.Concatenate(axis=-1)([chart_m1, pdas_repeated])\n",
    "  m1_at = tf.keras.layers.Dense(256)(concatenated_m1_at)\n",
    "  m1_at = lrelu(m1_at)\n",
    "  m1_at = tf.keras.layers.Dense(128)(m1_at)\n",
    "  m1_at = lrelu(m1_at)\n",
    "  m1_at = tf.keras.layers.Dense(64)(m1_at)\n",
    "  m1_at = lrelu(m1_at)\n",
    "  m1_at = tf.keras.layers.LSTM(128)(m1_at)\n",
    "\n",
    "    \n",
    "  #c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, scaled_open_profit])\n",
    "  c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, m1_at, m5_at])\n",
    "\n",
    "  d = tf.keras.layers.Dense(512)(c)\n",
    "  d = lrelu(d)\n",
    "  d = tf.keras.layers.Dense(512)(d)\n",
    "  d = lrelu(d)\n",
    "  d = tf.keras.layers.Dense(512)(d)\n",
    "  d = lrelu(d)\n",
    "  d = tf.keras.layers.Dense(512)(d)\n",
    "  d = lrelu(d)\n",
    "\n",
    "\n",
    "  output = tf.keras.layers.Dense(1, activation=\"linear\")(d)\n",
    "  \n",
    "  model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes], outputs = output)\n",
    "\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001)\n",
    "\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed95ee89-eaa4-4650-8765-8cf16fbffed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def relative (value, center, r):\n",
    "        return (value - center) / r\n",
    "\n",
    "def ret_to_scaled_inputs(ret):\n",
    "\n",
    "    midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "\n",
    "\n",
    "    center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
    "    r = max(0.0001,(midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
    "\n",
    "    pda_rel = []\n",
    "    pda_rel.append(relative(midnight_open, center, r))\n",
    "    for pda in pdas[0:9+9+15]:\n",
    "        pda_rel.append(relative(pda, center, r))\n",
    "    for index in range(9+9+15,9+9+15+5*12):\n",
    "        ## highs lows are like this [h, h_taken, l, l_taken]\n",
    "        ## the bools should not be scaled\n",
    "        if (index - 9+9+15) % 2 == 0:\n",
    "            pda_rel.append(relative(pdas[index], center, r))\n",
    "        else:\n",
    "            pda_rel.append(pdas[index])\n",
    "\n",
    "    pda_np = np.array(pda_rel)\n",
    "\n",
    "    current_minutes = current_time.hour * 60 + current_time.minute\n",
    "\n",
    "    charts_array = []\n",
    "    for candlesticks in charts:\n",
    "        charts_array.append([])\n",
    "        for candle in candlesticks:\n",
    "            o = relative(candle.o, center, r)\n",
    "            h = relative(candle.h, center, r)\n",
    "            l = relative(candle.l, center, r)\n",
    "            c = relative(candle.c, center, r)\n",
    "            charts_array[-1].append([o,h,l,c])\n",
    "\n",
    "    m15_np = np.array(charts_array[0])\n",
    "    m5_np = np.array(charts_array[1])\n",
    "    m1_np = np.array(charts_array[2])\n",
    "\n",
    "    return [m15_np, m5_np, m1_np, pda_np, current_minutes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8c4099-73a3-455a-a889-483d68bbca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "candles = obj_load(\"NQ_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1549375-6c43-4fe6-bb81-1d1f845f452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MultiTimeframeCandleManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165ff0d6-0d6f-4821-938c-874d03346506",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "\n",
    "index = 0\n",
    "\n",
    "for _ in range(10000):\n",
    "    ret = m.push_m1_candle(candles[index])\n",
    "    index += 1\n",
    "\n",
    "for _ in tqdm(range(100000)):\n",
    "    ret = m.push_m1_candle(candles[index])\n",
    "    midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "\n",
    "\n",
    "    avg_candle_range = np.mean([ i.h - i.l for i in list(charts[2])])\n",
    "#avg_candle_range\n",
    "    \n",
    "    slv = avg_candle_range * 3\n",
    "    tpv = avg_candle_range * 6\n",
    "    c = m.m1_candles[-1].c\n",
    "    \n",
    "    slshort = c + slv\n",
    "    tpshort = c - tpv\n",
    "    sllong = c - slv\n",
    "    tplong = c + tpv\n",
    "    \n",
    "    short_stop = False\n",
    "    long_stop = False\n",
    "    short_hit = False\n",
    "    long_hit = False\n",
    "    \n",
    "    for index_forward in range(index+1, index+20):\n",
    "        next_candle = candles[index_forward]\n",
    "        ncl = next_candle.l\n",
    "        nch = next_candle.h\n",
    "    \n",
    "        if short_hit == False and ncl < sllong:\n",
    "            long_stop = True\n",
    "        if long_hit == False and nch > slshort:\n",
    "            short_stop = True\n",
    "    \n",
    "        if short_stop == False and ncl < tpshort:\n",
    "            short_hit = True\n",
    "        if long_stop == False and nch > tplong:\n",
    "            long_hit = True\n",
    "        \n",
    "    #print(long_hit, short_hit, short_stop, long_stop)\n",
    "\n",
    "    x = ret_to_scaled_inputs(ret)\n",
    "    y = 0\n",
    "    if long_hit:\n",
    "        y=1\n",
    "    if short_hit:\n",
    "        y=-1\n",
    "        \n",
    "    train_data.append((x,y))\n",
    "\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f57f46-a9d2-4260-9ba6-4bf969f67a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb78e1a6-4f2a-47ee-b5d4-cdd429afda0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dce5444-32a9-48dd-8829-15108b1ea8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_candles(candles):\n",
    "    for index in range(len(candles)):\n",
    "        candle = candles[index]\n",
    "        c = \"green\" if candle.c > candle.o else \"black\"\n",
    "        plt.plot([index, index], [candle.l, candle.h], linewidth=1, color = \"black\")\n",
    "        plt.plot([index, index], [candle.c, candle.o], linewidth=3, color = c)\n",
    "plot_candles(list(m.m1_candles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbdc51d-f7ae-4345-a477-344788585274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f829f6-d79a-4857-bc23-71a82a3041d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc81d6bb-99e2-4551-978d-8931ec897f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.function(jit_compile=False) # my gpu does not support this\n",
    "def tstep(data):\n",
    "    x, y = data\n",
    "\n",
    "    with tf.GradientTape() as t:\n",
    "        model_return = model(x, training=True)\n",
    "        loss_e = tf.math.square(y - model_return)\n",
    "        loss = tf.reduce_mean(loss_e)\n",
    "\n",
    "\n",
    "    gradient = t.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_index = 0\n",
    "def get_data(n):\n",
    "        global train_index\n",
    "        #sarts_index = random.randint(0, len(sarts_memory) - batch_size)\n",
    "        train_sample = [train_data[i] for i in range(train_index, train_index + batch_size)]\n",
    "        train_index+=batch_size\n",
    "        if(train_index+batch_size >= len(train_data)):\n",
    "            train_index = 0\n",
    "    \n",
    "\n",
    "        states = [x[0] for x in train_sample]\n",
    "        states_array = []\n",
    "        for i in range(len(states[0])):\n",
    "            states_array.append(np.array([x[i] for x in states], dtype = \"float32\"))\n",
    "            \n",
    "        targets = [x[1] for x in train_sample]\n",
    "\n",
    "        return states_array, targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766c5fa1-a220-434b-9462-5010e84e6838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c4ff9a-ced6-44e7-b31e-cab76883b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def run():\n",
    "    distributed_data = (strategy.experimental_distribute_values_from_function(get_data))\n",
    "    loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, strategy.run(tstep, args = (distributed_data,)), axis = None)\n",
    "    return loss\n",
    "\n",
    "losses = []\n",
    "for _ in tqdm(range(100)):\n",
    "    loss = run()\n",
    "    losses.append(loss)\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a234e4-6a16-4152-a18a-e6be263a0758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852df7a3-e6c4-4505-bf0e-f782f3fedcf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
