{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0lYYICMk4TtN",
    "outputId": "c13865b8-da57-408b-8a92-f0cd06dff423"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading NQ_2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from save_and_load import *\n",
    "from Candle import Candle\n",
    "from MultiTimeframeCandleManager import MultiTimeframeCandleManager\n",
    "\n",
    "candles = obj_load(\"NQ_1\")\n",
    "#candles = obj_load(\"NQ_2\")\n",
    "len(candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oxQB14ka4VP1"
   },
   "outputs": [],
   "source": [
    "gamma = 0.99\n",
    "memory_len = 100000\n",
    "batch_size = 128\n",
    "\n",
    "path = \"./\"\n",
    "\n",
    "ep_len = 1000\n",
    "\n",
    "m1 = np.eye(2, dtype=\"float32\")\n",
    "num_model_inputs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bvbm7PEH4Vyr",
    "outputId": "f3a4e3eb-ad4e-4db1-dc28-0c2daa966f0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 8)         11520       ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 240)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 240)          0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 240)          0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 19)]         0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 8)            0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 748)          0           ['flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]',              \n",
      "                                                                  'flatten_3[0][0]',              \n",
      "                                                                  'input_4[0][0]',                \n",
      "                                                                  'flatten[0][0]',                \n",
      "                                                                  'input_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 8192)         6135808     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 8192)         0           ['dense_2[0][0]',                \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 8192)         67117056    ['leaky_re_lu[2][0]']            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1)            8193        ['leaky_re_lu[3][0]']            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 2)            16386       ['leaky_re_lu[3][0]']            \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 2)            0           ['dense_4[0][0]',                \n",
      "                                                                  'dense_5[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 73,288,963\n",
      "Trainable params: 73,288,963\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "chart_m15 = tf.keras.layers.Input(shape = (60,4))\n",
    "chart_m5 = tf.keras.layers.Input(shape = (60,4))\n",
    "chart_m1 = tf.keras.layers.Input(shape = (60,4))\n",
    "\n",
    "pdas = tf.keras.layers.Input(shape = (19,))\n",
    "\n",
    "current_position = tf.keras.layers.Input(shape = (1,))\n",
    "#scaled_open_profit = tf.keras.layers.Input(shape = (1,))\n",
    "\n",
    "minutes = tf.keras.layers.Input(shape = (1,))\n",
    "minutes_embed = tf.keras.layers.Embedding(input_dim=60*24, output_dim=8)(minutes)\n",
    "minutes_embed_flat = tf.keras.layers.Flatten()(minutes_embed)\n",
    "\n",
    "f15 = tf.keras.layers.Flatten()(chart_m15)\n",
    "f5 = tf.keras.layers.Flatten()(chart_m5)\n",
    "f1 = tf.keras.layers.Flatten()(chart_m1)\n",
    "\n",
    "#c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, scaled_open_profit])\n",
    "c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position])\n",
    "\n",
    "lrelu = tf.keras.layers.LeakyReLU(0.05)\n",
    "\n",
    "d = tf.keras.layers.Dense(1024*8)(c)\n",
    "d = lrelu(d)\n",
    "d = tf.keras.layers.Dense(1024*8)(d)\n",
    "d = lrelu(d)\n",
    "\n",
    "value = tf.keras.layers.Dense(1, activation=\"linear\")(d)\n",
    "advantage = tf.keras.layers.Dense(2, activation=\"linear\")(d)\n",
    "\n",
    "q_values = tf.keras.layers.Lambda(\n",
    "    lambda inputs: inputs[0] + (inputs[1] - tf.reduce_mean(inputs[1], axis=1, keepdims=True))\n",
    ")([value, advantage])\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = q_values)\n",
    "target_model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = q_values)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FXpvSeUFYo1R"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001)\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate = 0.0000000001, momentum = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "38Z6e4Ue6I87"
   },
   "outputs": [],
   "source": [
    "\n",
    "def relative (value, center, r):\n",
    "        return (value - center) / r\n",
    "\n",
    "def ret_to_scaled_inputs(ret):\n",
    "\n",
    "    midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "\n",
    "    center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
    "    r = (midnight_opening_range_high - midnight_opening_range_low) / 2\n",
    "\n",
    "    pda_rel = []\n",
    "    pda_rel.append(relative(midnight_open, center, r))\n",
    "    for pda in pdas:\n",
    "        pda_rel.append(relative(pda, center, r))\n",
    "    pda_np = np.array(pda_rel)\n",
    "\n",
    "    current_minutes = current_time.hour * 60 + current_time.minute\n",
    "\n",
    "    charts_array = []\n",
    "    for candlesticks in charts:\n",
    "        charts_array.append([])\n",
    "        for candle in candlesticks:\n",
    "            o = relative(candle.o, center, r)\n",
    "            h = relative(candle.h, center, r)\n",
    "            l = relative(candle.l, center, r)\n",
    "            c = relative(candle.c, center, r)\n",
    "            charts_array[-1].append([o,h,l,c])\n",
    "\n",
    "    m15_np = np.array(charts_array[0])\n",
    "    m5_np = np.array(charts_array[1])\n",
    "    m1_np = np.array(charts_array[2])\n",
    "\n",
    "    return [m15_np, m5_np, m1_np, pda_np, current_minutes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aVzGqTFD6LjG"
   },
   "outputs": [],
   "source": [
    "m = MultiTimeframeCandleManager()\n",
    "\n",
    "cmm = 0.5\n",
    "\n",
    "last_close = 0\n",
    "last_state = None\n",
    "last_action = 0\n",
    "\n",
    "index = 0\n",
    "\n",
    "def step():\n",
    "\n",
    "    global index, last_close, last_state, last_action, current_position, entry_price, equity\n",
    "\n",
    "\n",
    "    sarts = None\n",
    "    while  sarts == None:\n",
    "\n",
    "        ret = m.push_m1_candle(candles[index])\n",
    "        midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "        center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
    "        r = (midnight_opening_range_high - midnight_opening_range_low) / 2\n",
    "\n",
    "\n",
    "        if(len(m.m15_candles) == 60):\n",
    "\n",
    "            state = ret_to_scaled_inputs(ret)\n",
    "            m15_np, m5_np, m1_np, pda_np, current_minutes = state\n",
    "\n",
    "            if(last_state != None):\n",
    "\n",
    "                sarts = []\n",
    "                \n",
    "                terminal = 0\n",
    "                if(index+1 == len(candles)):\n",
    "                    terminal = 1\n",
    "                    \n",
    "                current_close = state[2][-1][3]\n",
    "                last_close = last_state[2][-1][3]\n",
    "\n",
    "                ### last position -1 \n",
    "                state_short = last_state + [-1]\n",
    "                ## action was -1\n",
    "                new_state = state + [-1]\n",
    "                reward = ((current_close - last_close) * -1) / r\n",
    "                sarts.append([state_short, 0, reward, terminal, new_state])\n",
    "                ## action was 1\n",
    "                new_state = state + [1]\n",
    "                reward = ((current_close - last_close) * 1 - cmm) / r\n",
    "                sarts.append([state_short, 1, reward, terminal, new_state])\n",
    "\n",
    "                \n",
    "                ### last position 1 \n",
    "                state_long = last_state + [1]\n",
    "                ## action was -1\n",
    "                new_state = state + [-1]\n",
    "                reward = ((current_close - last_close) * -1 - cmm) / r\n",
    "                sarts.append([state_long, 0, reward, terminal, new_state])\n",
    "                ## action was 1\n",
    "                new_state = state + [1]\n",
    "                reward = ((current_close - last_close) * 1) / r\n",
    "                sarts.append([state_long, 1, reward, terminal, new_state])\n",
    "\n",
    "\n",
    "            last_state = state\n",
    "\n",
    "\n",
    "        index += 1\n",
    "        if(index == len(candles)):\n",
    "            index = 0\n",
    "            current_position = 0\n",
    "            entry_price = 0\n",
    "            last_close = 0\n",
    "            last_state = None\n",
    "            last_action = 0\n",
    "            print(\"env reset\")\n",
    "\n",
    "    return sarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "acX4Ztg86Ly9"
   },
   "outputs": [],
   "source": [
    "@tf.function(reduce_retracing=True)\n",
    "def get_target_q(next_states, rewards, terminals):\n",
    "            estimated_q_values_next = target_model(next_states)\n",
    "            q_batch = tf.math.reduce_max(estimated_q_values_next, axis=1)\n",
    "            target_q_values = q_batch * gamma * (1-terminals) + rewards\n",
    "            return target_q_values\n",
    "\n",
    "@tf.function(reduce_retracing=True)\n",
    "def tstep(states, masks, rewards, terminals, next_states):\n",
    "\n",
    "    target_q_values = get_target_q(next_states, rewards, terminals)\n",
    "\n",
    "    with tf.GradientTape() as t:\n",
    "        model_return = model(states, training=True)\n",
    "        mask_return = model_return * masks\n",
    "        estimated_q_values = tf.math.reduce_sum(mask_return, axis=1)\n",
    "        #print(estimated_q_values, mask_return, model_return, masks)\n",
    "        loss_e = tf.math.square(target_q_values - estimated_q_values)\n",
    "        loss = tf.reduce_mean(loss_e)\n",
    "\n",
    "\n",
    "    gradient = t.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
    "\n",
    "    return loss, tf.reduce_mean(estimated_q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "csDW9UAK6Nre"
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    sarts = step()\n",
    "    sarts_memory.extend(sarts)\n",
    "\n",
    "    sarts_sample = random.sample(sarts_memory, min(batch_size, len(sarts_memory)))\n",
    "\n",
    "    states = [x[0] for x in sarts_sample]\n",
    "    actions = [x[1] for x in sarts_sample]\n",
    "    rewards = np.array([x[2] for x in sarts_sample], dtype=\"float32\")\n",
    "    terminals = np.array([x[3] for x in sarts_sample], dtype=\"float32\")\n",
    "    next_states = [x[4] for x in sarts_sample]\n",
    "\n",
    "    next_states_array = []\n",
    "    for i in range(num_model_inputs):\n",
    "        next_states_array.append(np.array([x[i] for x in next_states], dtype = \"float32\"))\n",
    "\n",
    "\n",
    "    states_array = []\n",
    "    for i in range(num_model_inputs):\n",
    "        states_array.append(np.array([x[i] for x in states], dtype = \"float32\"))\n",
    "\n",
    "\n",
    "    masks = np.array(m1[actions], dtype=\"float32\")\n",
    "\n",
    "    loss, q = tstep(states_array, masks, rewards, terminals, next_states_array)\n",
    "\n",
    "    return loss, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C7cUOXonM-AL",
    "outputId": "10640d42-7478-4bbc-d3c2-b4678788004a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ./loss\n",
      "loading ./q\n"
     ]
    }
   ],
   "source": [
    "sarts_memory = deque(maxlen = memory_len)\n",
    "\n",
    "loss_mean = []\n",
    "q_mean = []\n",
    "\n",
    "try:\n",
    "    model.load_weights(path+\"model.weights.h5\")\n",
    "    target_model.load_weights(path+\"model.weights.h5\")\n",
    "\n",
    "    loss_mean = obj_load(path+\"loss\")\n",
    "    q_mean = obj_load(path+\"q\")\n",
    "except:\n",
    "    print(\"unable to load data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save():\n",
    "            model.save_weights(path+\"model.weights.h5\")\n",
    "            obj_save(loss_mean, path+\"loss\")\n",
    "            obj_save(q_mean, path+\"q\")\n",
    "            print(\"saved progress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7sAeWJZ96OvG",
    "outputId": "b5beb350-7f6f-4b51-d09a-882b795de989"
   },
   "outputs": [],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "safe_after_eps = 10\n",
    "eps_counter=0\n",
    "\n",
    "while True:\n",
    "    eps_counter+=1\n",
    "    try:\n",
    "        loss = []\n",
    "        q = []\n",
    "        rewards_tmp = []\n",
    "        actions = []\n",
    "        progbar = tf.keras.utils.Progbar(ep_len)\n",
    "        for i in range(ep_len):\n",
    "            c_loss, c_q = run()\n",
    "            loss.append(c_loss)\n",
    "            q.append(c_q)\n",
    "            \n",
    "            progbar.update(i+1, values = [(\"loss\", c_loss), (\"qv\", c_q)])\n",
    "\n",
    "        loss_mean.append(np.mean(loss))\n",
    "        q_mean.append(np.mean(q))\n",
    "\n",
    "        target_model.set_weights(model.get_weights())\n",
    "\n",
    "        if(eps_counter >= safe_after_eps):\n",
    "            eps_counter = 0\n",
    "            save()\n",
    "\n",
    "\n",
    "    except    KeyboardInterrupt:\n",
    "        print(\"\")\n",
    "        print(\"exit\")\n",
    "        save()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vlJjQSh76bP7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GSYnf6FC6P4R"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fc8GculHXkGh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qTvbON6VXkGh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
