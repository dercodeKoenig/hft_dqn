{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "O1TcBIpbReKM"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iw9L3PcRHypQ",
    "outputId": "01b21e12-3a71-4343-f3d7-cb52a5f936e8"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/dercodeKoenig/hft_dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_GOXl2HpH0M4",
    "outputId": "ab845936-f71c-42ed-aa2f-22e7ec5408b5"
   },
   "outputs": [],
   "source": [
    "#%cd hft_dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "srO8OLjtH1Zq",
    "outputId": "0d168de5-4e46-4601-b8cb-4946ac519a97"
   },
   "outputs": [],
   "source": [
    "#!pip install kaggle\n",
    "#!kaggle datasets download bpwqsdd/us-futures-1-minute-candlesticks\n",
    "#!unzip us-futures-1-minute-candlesticks.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1b197691-b458-4cbf-943f-14c353d9da30"
   },
   "outputs": [],
   "source": [
    "\n",
    "from MultiTimeframeCandleManager import MultiTimeframeCandleManager\n",
    "from datetime import datetime, timedelta\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from save_and_load import *\n",
    "from Candle import Candle\n",
    "import matplotlib.pyplot as plt\n",
    "#from tensorflow.keras import mixed_precision\n",
    "#mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eu8rj9GMIGCL",
    "outputId": "b8320064-01dc-4d13-c1ba-6495c55eabf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n",
      "INFO:tensorflow:Initializing the TPU system: local\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy at 0x2a4ffcdb8e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"local\")\n",
    "    tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
    "    strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
    "    print(\"use tpu strategy\")\n",
    "except:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1a46f09d-bcd5-4f57-a637-d75e36e4bfe0"
   },
   "outputs": [],
   "source": [
    "gamma = 0.995\n",
    "memory_len = 2000000\n",
    "sarts_memory = deque(maxlen = memory_len)\n",
    "batch_size = 1024\n",
    "e = 2\n",
    "slm = 1.5\n",
    "\n",
    "min_memory_size = batch_size * 20\n",
    "\n",
    "num_actions = 3\n",
    "\n",
    "path = \"./\"\n",
    "\n",
    "ep_len = 50000\n",
    "\n",
    "m1 = np.eye(num_actions, dtype=\"float32\")\n",
    "num_model_inputs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ./sarts_cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 484118/484118 [00:00<00:00, 3376329.50it/s]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sarts_cache = obj_load(path+\"sarts_cache\")\n",
    "    for i in tqdm(sarts_cache):\n",
    "        sarts_memory.append(i)\n",
    "    del sarts_cache\n",
    "except Exception as error:\n",
    "    print(\"no sarts cache loaded\")\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "390662b5-22d2-4aa9-a457-d598fdb81fe2",
    "outputId": "ff1a1f1e-3ec7-44e3-a57e-582f2d520ecd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 94)]         0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 60, 94)       0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 60, 98)       0           ['input_3[0][0]',                \n",
      "                                                                  'lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 60, 128)      12672       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        multiple             0           ['dense[0][0]',                  \n",
      "                                                                  'dense_1[0][0]',                \n",
      "                                                                  'dense_2[0][0]',                \n",
      "                                                                  'dense_3[0][0]',                \n",
      "                                                                  'dense_4[0][0]',                \n",
      "                                                                  'dense_5[0][0]',                \n",
      "                                                                  'dense_6[0][0]',                \n",
      "                                                                  'dense_7[0][0]',                \n",
      "                                                                  'dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 60, 128)      16512       ['leaky_re_lu[3][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 60, 98)       0           ['input_2[0][0]',                \n",
      "                                                                  'lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 60, 32)       4128        ['leaky_re_lu[4][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 60, 128)      12672       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 60, 128)      16512       ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 60, 32)       4128        ['leaky_re_lu[1][0]']            \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 60, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 8)         11520       ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 240)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 240)          0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 240)          0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 8)            0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, 32)           6336        ['leaky_re_lu[5][0]']            \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, 32)           6336        ['leaky_re_lu[2][0]']            \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 889)          0           ['flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]',              \n",
      "                                                                  'flatten_3[0][0]',              \n",
      "                                                                  'input_4[0][0]',                \n",
      "                                                                  'flatten[0][0]',                \n",
      "                                                                  'input_5[0][0]',                \n",
      "                                                                  'gru_1[0][0]',                  \n",
      "                                                                  'gru[0][0]']                    \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 1024)         911360      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1024)         1049600     ['leaky_re_lu[6][0]']            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 1024)         1049600     ['leaky_re_lu[7][0]']            \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            1025        ['leaky_re_lu[8][0]']            \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 3)            3075        ['leaky_re_lu[8][0]']            \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 3)            0           ['dense_9[0][0]',                \n",
      "                                                                  'dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 3)            0           ['lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,105,476\n",
      "Trainable params: 3,105,476\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "  lrelu = tf.keras.layers.LeakyReLU(0.05)\n",
    "\n",
    "\n",
    "  chart_m15 = tf.keras.layers.Input(shape = (60,4))\n",
    "  chart_m5 = tf.keras.layers.Input(shape = (60,4))\n",
    "  chart_m1 = tf.keras.layers.Input(shape = (60,4))\n",
    "\n",
    "  pdas = tf.keras.layers.Input(shape = (3*3+3*3+1+12*5+5*3,))\n",
    "\n",
    "  current_position = tf.keras.layers.Input(shape = (3,))\n",
    "\n",
    "  minutes = tf.keras.layers.Input(shape = (1,))\n",
    "  minutes_embed = tf.keras.layers.Embedding(input_dim=60*24, output_dim=8)(minutes)\n",
    "  minutes_embed_flat = tf.keras.layers.Flatten()(minutes_embed)\n",
    "\n",
    "  f15 = tf.keras.layers.Flatten()(chart_m15)\n",
    "  f5 = tf.keras.layers.Flatten()(chart_m5)\n",
    "  f1 = tf.keras.layers.Flatten()(chart_m1)\n",
    "\n",
    "  pdas_repeated = tf.keras.layers.Lambda(\n",
    "  lambda inputs: tf.repeat(tf.expand_dims(inputs, axis = 1), repeats=60, axis=1)\n",
    "  )(pdas)\n",
    "\n",
    "  concatenated_m5_at = tf.keras.layers.Concatenate(axis=-1)([chart_m5, pdas_repeated])\n",
    "  m5_at = tf.keras.layers.Dense(128)(concatenated_m5_at)\n",
    "  m5_at = lrelu(m5_at)\n",
    "  m5_at = tf.keras.layers.Dense(128)(m5_at)\n",
    "  m5_at = lrelu(m5_at)\n",
    "  m5_at = tf.keras.layers.Dense(32)(m5_at)\n",
    "  m5_at = lrelu(m5_at)\n",
    "  m5_rnn = tf.keras.layers.GRU(32)(m5_at)\n",
    "\n",
    "  concatenated_m1_at = tf.keras.layers.Concatenate(axis=-1)([chart_m1, pdas_repeated])\n",
    "  m1_at = tf.keras.layers.Dense(128)(concatenated_m1_at)\n",
    "  m1_at = lrelu(m1_at)\n",
    "  m1_at = tf.keras.layers.Dense(128)(m1_at)\n",
    "  m1_at = lrelu(m1_at)\n",
    "  m1_at = tf.keras.layers.Dense(32)(m1_at)\n",
    "  m1_at = lrelu(m1_at)\n",
    "  m1_rnn = tf.keras.layers.GRU(32)(m1_at)\n",
    "\n",
    "  #c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, scaled_open_profit])\n",
    "  c = tf.keras.layers.Concatenate()([f15, f5, f1, pdas, minutes_embed_flat, current_position, m1_rnn, m5_rnn])\n",
    "\n",
    "  d = tf.keras.layers.Dense(1024*1)(c)\n",
    "  d = lrelu(d)\n",
    "  d = tf.keras.layers.Dense(1024*1)(d)\n",
    "  d = lrelu(d)\n",
    "  d = tf.keras.layers.Dense(1024*1)(d)\n",
    "  d = lrelu(d)\n",
    "\n",
    "\n",
    "  value = tf.keras.layers.Dense(1, activation=\"linear\")(d)\n",
    "  advantage = tf.keras.layers.Dense(num_actions, activation=\"linear\")(d)\n",
    "\n",
    "  q_values = tf.keras.layers.Lambda(\n",
    "  lambda inputs: inputs[0] + (inputs[1] - tf.reduce_mean(inputs[1], axis=1, keepdims=True))\n",
    "  )([value, advantage])\n",
    "\n",
    "  outputs = tf.keras.layers.Activation('linear', dtype='float32')(q_values)\n",
    "\n",
    "  model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = outputs)\n",
    "  target_model = tf.keras.Model(inputs = [chart_m15, chart_m5, chart_m1, pdas, minutes, current_position], outputs = outputs)\n",
    "\n",
    "\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001)\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8f069d41-781f-439b-b12a-59bd3e1f29e7"
   },
   "outputs": [],
   "source": [
    "\n",
    "def relative (value, center, r):\n",
    "        return (value - center) / r\n",
    "\n",
    "def ret_to_scaled_inputs(ret):\n",
    "\n",
    "    midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "\n",
    "\n",
    "    center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
    "    r = max(0.0001,(midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
    "\n",
    "    pda_rel = []\n",
    "    pda_rel.append(relative(midnight_open, center, r))\n",
    "    for pda in pdas[0:9+9+15]:\n",
    "        pda_rel.append(relative(pda, center, r))\n",
    "    for index in range(9+9+15,9+9+15+5*12):\n",
    "        ## highs lows are like this [h, h_taken, l, l_taken]\n",
    "        ## the bools should not be scaled\n",
    "        if (index - 9+9+15) % 2 == 0:\n",
    "            pda_rel.append(relative(pdas[index], center, r))\n",
    "        else:\n",
    "            pda_rel.append(pdas[index])\n",
    "\n",
    "    pda_np = np.array(pda_rel)\n",
    "\n",
    "    current_minutes = current_time.hour * 60 + current_time.minute\n",
    "\n",
    "    charts_array = []\n",
    "    for candlesticks in charts:\n",
    "        charts_array.append([])\n",
    "        for candle in candlesticks:\n",
    "            o = relative(candle.o, center, r)\n",
    "            h = relative(candle.h, center, r)\n",
    "            l = relative(candle.l, center, r)\n",
    "            c = relative(candle.c, center, r)\n",
    "            charts_array[-1].append([o,h,l,c])\n",
    "\n",
    "    m15_np = np.array(charts_array[0])\n",
    "    m5_np = np.array(charts_array[1])\n",
    "    m1_np = np.array(charts_array[2])\n",
    "\n",
    "    return [m15_np, m5_np, m1_np, pda_np, current_minutes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3cd5699d-6072-4afe-8e58-f529f228ad0b"
   },
   "outputs": [],
   "source": [
    "class Order:\n",
    "    def __init__(self, limit, stop, tp, direction):\n",
    "        self.entry = limit\n",
    "        self.tp = tp\n",
    "        self.sl = stop\n",
    "        self.direction = direction\n",
    "\n",
    "class Position:\n",
    "    def __init__(self, entry, stop, tp, direction):\n",
    "        self.entry = entry\n",
    "        self.tp = tp\n",
    "        self.sl = stop\n",
    "        self.direction = direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0c1b7326-2b0f-49e6-86b1-815fd4ef4c87",
    "outputId": "7f6cdced-9835-4ecd-e0f2-3dc949f78204"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading NQ_2\n",
      "env reset, using data: ('NQ_2', 1)\n"
     ]
    }
   ],
   "source": [
    "equity = 0\n",
    "equity_L = [0]\n",
    "\n",
    "inputs = [\n",
    "    (\"NQ_2\", 1),\n",
    "    (\"ES_2\", 0.75),\n",
    "    (\"YM_2\", 1.5),\n",
    "    (\"EURUSD_2\", 0.00015),\n",
    "    (\"GBPUSD_2\", 0.00015)\n",
    "]\n",
    "\n",
    "candles = []\n",
    "cmm = 0\n",
    "\n",
    "input_index = 0\n",
    "def reset():\n",
    "    global index, last_state, last_action, current_position, current_order, equity, m, candles, cmm, input_index\n",
    "\n",
    "    ob = inputs[input_index]\n",
    "    candles = obj_load(ob[0])\n",
    "    cmm = ob[1]\n",
    "    input_index+=1\n",
    "    if(input_index >= len(inputs)):\n",
    "        input_index = 0\n",
    "\n",
    "    m = MultiTimeframeCandleManager()\n",
    "\n",
    "    current_position = Position(0,0,0,0)\n",
    "    current_order = None\n",
    "\n",
    "    last_state = None\n",
    "    last_action = 0\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    print(\"env reset, using data:\", ob)\n",
    "\n",
    "\n",
    "@tf.function()\n",
    "def inference_step(m15_np, m5_np, m1_np, pda_np, current_minutes, pos_info):\n",
    "    return model([\n",
    "        m15_np,\n",
    "        m5_np,\n",
    "        m1_np,\n",
    "        pda_np,\n",
    "        current_minutes,\n",
    "        pos_info,\n",
    "    ])\n",
    "\n",
    "\n",
    "def step():\n",
    "\n",
    "    global index, last_state, last_action, current_position, current_order, equity, m\n",
    "\n",
    "\n",
    "    sarts = None\n",
    "    while  sarts == None:\n",
    "\n",
    "        ret = m.push_m1_candle(candles[index])\n",
    "        midnight_open, midnight_opening_range_high,midnight_opening_range_low, pdas, current_close, current_time, charts = ret\n",
    "        center = (midnight_opening_range_high + midnight_opening_range_low) / 2\n",
    "        r = max(0.0001, (midnight_opening_range_high - midnight_opening_range_low) / 2)\n",
    "\n",
    "\n",
    "\n",
    "        current_candle_m1 = charts[2][-1]\n",
    "        #### check tp before filling order so that the same m1 candle will not trigger tp - it is not sure if the candle hit first limit and later tp or reve3rse\n",
    "        if current_position.direction == 1:\n",
    "            if current_candle_m1.h >= current_position.tp:\n",
    "                pnl = (current_position.tp - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "        if current_position.direction == -1:\n",
    "            if current_candle_m1.l <= current_position.tp:\n",
    "                pnl = (current_position.tp - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "        #### check order\n",
    "        if current_order != None:\n",
    "            if  current_order.direction == 1:\n",
    "                if current_candle_m1.l < current_order.entry:\n",
    "                    current_position = Position(current_order.entry, current_order.sl, current_order.tp, current_order.direction)\n",
    "                    #print(\"fill long order:\",current_order.entry, current_order.sl, current_order.tp)\n",
    "                    equity -= cmm\n",
    "                    current_order = None\n",
    "        if current_order != None:\n",
    "            if  current_order.direction == -1:\n",
    "                if current_candle_m1.h > current_order.entry:\n",
    "                    current_position = Position(current_order.entry, current_order.sl, current_order.tp, current_order.direction)\n",
    "                    #print(\"fill short order:\",current_order.entry, current_order.sl, current_order.tp)\n",
    "                    equity -= cmm\n",
    "                    current_order = None\n",
    "\n",
    "        #### check sl\n",
    "        if current_position.direction == 1:\n",
    "            if current_candle_m1.l <= current_position.sl:\n",
    "                pnl = (current_position.sl - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "        if current_position.direction == -1:\n",
    "            if current_candle_m1.h >= current_position.sl:\n",
    "                pnl = (current_position.sl - current_position.entry) * current_position.direction\n",
    "                equity += pnl\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if(len(m.ndogs) == 5 and len(m.fps) == 3 and len(m.opening_range_gaps) == 3 and len(m.asia_highs_lows) == 3 and len(m.london_highs_lows) == 3 and len(m.ny_am_highs_lows) == 3 and len(m.ny_lunch_highs_lows) == 3 and len(m.ny_pm_highs_lows) == 3):\n",
    "\n",
    "\n",
    "            open_profit = (current_close - current_position.entry) * current_position.direction\n",
    "\n",
    "            scaled_entry_diff  =  0\n",
    "            scaled_sl_diff  =  0\n",
    "            if(current_position.direction != 0):\n",
    "                scaled_entry_diff = (current_close - current_position.entry) / r\n",
    "                scaled_sl_diff = (current_close - current_position.sl) / r\n",
    "\n",
    "            state = ret_to_scaled_inputs(ret) + [np.array([current_position.direction, scaled_entry_diff, scaled_sl_diff])]\n",
    "            m15_np, m5_np, m1_np, pda_np, current_minutes, pos_info = state\n",
    "\n",
    "            if(last_state != None):\n",
    "                diff = (equity+open_profit) - equity_L[-1]\n",
    "                equity_L.append(equity+open_profit)\n",
    "                reward =  (diff) / r\n",
    "                terminal = 0\n",
    "                if(index+1 == len(candles)):\n",
    "                    terminal = 1\n",
    "\n",
    "                sarts = last_state, last_action, reward, terminal, state\n",
    "\n",
    "\n",
    "            if(random.randint(0,100) > e):\n",
    "                #with tf.device(\"/TPU:0\"):\n",
    "                output = inference_step(\n",
    "                        tf.expand_dims(m15_np, 0),\n",
    "                        tf.expand_dims(m5_np, 0),\n",
    "                        tf.expand_dims(m1_np, 0),\n",
    "                        tf.expand_dims(pda_np, 0),\n",
    "                        tf.expand_dims(current_minutes, 0),\n",
    "                        tf.expand_dims(pos_info, 0)\n",
    "                )\n",
    "\n",
    "                last_action = np.argmax(output)\n",
    "            else:\n",
    "                last_action = random.randint(0,num_actions-1)\n",
    "\n",
    "            last_state = state\n",
    "\n",
    "            current_order = None\n",
    "\n",
    "            avg_candle_range = np.mean([ i.h - i.l for i in list(charts[2])[55:60]])\n",
    "\n",
    "            if(last_action == 2 and current_position.direction != 0):\n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "            if(last_action == 0 and current_position.direction == 1):\n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "            if(last_action == 0 and current_position.direction == 0):\n",
    "                last_candle_low = charts[2][-2].l\n",
    "                if ( last_candle_low < current_close ):\n",
    "                    last_candle_low = None\n",
    "\n",
    "                pdas = m.normal_pdas ## (low, high)\n",
    "\n",
    "                ## ignore pdas with low below close\n",
    "                pdas_filtered = []\n",
    "                for pda in pdas:\n",
    "                        if(pda[0] > current_close):\n",
    "                            pdas_filtered.append(pda)\n",
    "                ### sort\n",
    "                sorted_by_high = sorted(pdas_filtered, key = lambda x:x[1])\n",
    "                sorted_by_low = sorted(pdas_filtered, key = lambda x:x[0])\n",
    "\n",
    "                if(len(pdas_filtered) > 0):\n",
    "\n",
    "                    ### entry is lowest i can get or immediate rebalance\n",
    "                    entry = sorted_by_low[0][0]\n",
    "                    if(last_candle_low != None):\n",
    "                        entry = min(entry, last_candle_low)\n",
    "\n",
    "\n",
    "                    sl = entry + avg_candle_range * slm\n",
    "                    tp = entry  -  abs(entry-sl) * 1000\n",
    "\n",
    "\n",
    "                    current_order = Order(entry, sl, tp, -1)\n",
    "                    #print(\"set short order:\",entry,sl,tp)\n",
    "\n",
    "\n",
    "\n",
    "            if(last_action == 1 and current_position.direction == -1):\n",
    "                equity += open_profit\n",
    "                current_position = Position(0,0,0,0)\n",
    "\n",
    "            if(last_action == 1 and current_position.direction == 0):\n",
    "                last_candle_high = charts[2][-2].h\n",
    "                if ( last_candle_high > current_close ):\n",
    "                    last_candle_high = None\n",
    "                pdas = m.normal_pdas ## (low, high)\n",
    "\n",
    "                ## ignore pdas with low below close\n",
    "                pdas_filtered = []\n",
    "                for pda in pdas:\n",
    "                        if(pda[1] < current_close):\n",
    "                            pdas_filtered.append(pda)\n",
    "                ### sort\n",
    "                sorted_by_high = sorted(pdas_filtered, key = lambda x:x[1], reverse=True)\n",
    "                sorted_by_low = sorted(pdas_filtered, key = lambda x:x[0], reverse=True)\n",
    "\n",
    "                if(len(pdas_filtered) > 0):\n",
    "                    ### entry is lowest i can get or immediate rebalance\n",
    "                    entry = sorted_by_high[0][1]\n",
    "                    if(last_candle_high != None):\n",
    "                        entry = max(entry, last_candle_high)\n",
    "\n",
    "                    sl = entry - avg_candle_range * slm\n",
    "                    tp = entry  +  abs(entry-sl) * 1000\n",
    "\n",
    "                    current_order = Order(entry, sl, tp, 1)\n",
    "                    #print(\"set long order:\",entry,sl,tp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        index += 1\n",
    "        if(index == len(candles)):\n",
    "            reset()\n",
    "\n",
    "    return sarts\n",
    "\n",
    "reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmgpAWSMReK4"
   },
   "source": [
    "def plot_candles(candles):\n",
    "    for index in range(len(candles)):\n",
    "        candle = candles[index]\n",
    "        c = \"green\" if candle.c > candle.o else \"black\"\n",
    "        plt.plot([index, index], [candle.l, candle.h], linewidth=1, color = \"black\")\n",
    "        plt.plot([index, index], [candle.c, candle.o], linewidth=3, color = c)\n",
    "\n",
    "sarts = step()\n",
    "\n",
    "plot_candles(m.m1_candles)\n",
    "if(current_position.direction != 0):\n",
    "    plt.axhline(current_position.entry, color = \"g\" if current_position.direction == 1 else \"r\")\n",
    "    plt.axhline(current_position.sl, color = \"orange\")\n",
    "\n",
    "if(current_order != None):\n",
    "    plt.axhline(current_order.entry, color = \"g\" if current_order.direction == 1 else \"r\")\n",
    "    plt.axhline(current_order.sl, color = \"orange\")\n",
    "\n",
    "\n",
    "print(sarts[1], sarts[2], current_position.direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "d92f99f8-68df-4fbd-bc4d-218a2a43f865"
   },
   "outputs": [],
   "source": [
    "@tf.function(jit_compile=True)\n",
    "def get_target_q(next_states, rewards, terminals):\n",
    "            estimated_q_values_next = target_model(next_states)\n",
    "            q_batch = tf.math.reduce_max(estimated_q_values_next, axis=1)\n",
    "            target_q_values = q_batch * gamma * (1-terminals) + rewards\n",
    "            return target_q_values\n",
    "\n",
    "@tf.function(jit_compile=False) # my gpu does not support this\n",
    "def tstep(data):\n",
    "    states, masks, rewards, terminals, next_states = data\n",
    "\n",
    "    target_q_values = get_target_q(next_states, rewards, terminals)\n",
    "\n",
    "    with tf.GradientTape() as t:\n",
    "        model_return = model(states, training=True)\n",
    "        mask_return = model_return * masks\n",
    "        estimated_q_values = tf.math.reduce_sum(mask_return, axis=1)\n",
    "        #print(estimated_q_values, mask_return, model_return, masks)\n",
    "        loss_e = tf.math.square(target_q_values - estimated_q_values)\n",
    "        loss = tf.reduce_mean(loss_e)\n",
    "\n",
    "\n",
    "    gradient = t.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
    "\n",
    "    return loss, tf.reduce_mean(estimated_q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "fd706ba5-8f9c-4889-a382-46f25bc9653c"
   },
   "outputs": [],
   "source": [
    "\n",
    "sarts_index = 0\n",
    "def get_data(n):\n",
    "        global sarts_index\n",
    "        #sarts_index = random.randint(0, len(sarts_memory) - batch_size)\n",
    "        sarts_sample = [sarts_memory[i] for i in range(sarts_index, sarts_index + batch_size)]\n",
    "        sarts_index+=batch_size\n",
    "        if(sarts_index+batch_size >= len(sarts_memory)):\n",
    "            sarts_index = 0\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        states = [x[0] for x in sarts_sample]\n",
    "        actions = [x[1] for x in sarts_sample]\n",
    "        rewards = np.array([x[2] for x in sarts_sample], dtype=\"float32\")\n",
    "        terminals = np.array([x[3] for x in sarts_sample], dtype=\"float32\")\n",
    "        next_states = [x[4] for x in sarts_sample]\n",
    "\n",
    "        next_states_array = []\n",
    "        for i in range(num_model_inputs):\n",
    "            next_states_array.append(np.array([x[i] for x in next_states], dtype = \"float32\"))\n",
    "\n",
    "\n",
    "        states_array = []\n",
    "        for i in range(num_model_inputs):\n",
    "            states_array.append(np.array([x[i] for x in states], dtype = \"float32\"))\n",
    "\n",
    "\n",
    "        masks = np.array(m1[actions], dtype=\"float32\")\n",
    "\n",
    "\n",
    "        return states_array, masks, rewards, terminals, next_states_array\n",
    "\n",
    "def run():\n",
    "    sarts = step()\n",
    "    sarts_memory.append(sarts)\n",
    "\n",
    "    if(len(sarts_memory) > min_memory_size):\n",
    "\n",
    "        distributed_data = (strategy.experimental_distribute_values_from_function(get_data))\n",
    "        loss, q = strategy.reduce(tf.distribute.ReduceOp.MEAN, strategy.run(tstep, args = (distributed_data,)), axis = None)\n",
    "\n",
    "        return loss, q, sarts[2], sarts[1]\n",
    "\n",
    "    else :\n",
    "        return 0,0, sarts[2], sarts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c5b3f0b-f6a8-4b12-9bc1-74330da8575a",
    "outputId": "2b3bb39e-1cf1-4801-d1cf-179a670ec250"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ./loss\n",
      "loading ./q\n",
      "loading ./rewards\n"
     ]
    }
   ],
   "source": [
    "loss_mean = []\n",
    "q_mean = []\n",
    "rewards = []\n",
    "\n",
    "try:\n",
    "    model.load_weights(path+\"model.weights.h5\")\n",
    "    target_model.load_weights(path+\"model.weights.h5\")\n",
    "\n",
    "    loss_mean = obj_load(path+\"loss\")\n",
    "    q_mean = obj_load(path+\"q\")\n",
    "    rewards = obj_load(path+\"rewards\")\n",
    "except Exception as a:\n",
    "    print(a)\n",
    "    print(\"unable to load data\")\n",
    "\n",
    "\n",
    "def save():\n",
    "            model.save_weights(path+\"model.weights.h5\")\n",
    "            obj_save(loss_mean, path+\"loss\")\n",
    "            obj_save(q_mean, path+\"q\")\n",
    "            obj_save(rewards, path+\"rewards\")\n",
    "            print(\"saved progress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a15d1bbb-b532-45b5-92bb-3bb84375b744",
    "outputId": "6e29f02a-6c38-4218-9479-958c47277b4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  815/50000 [..............................] - ETA: 1:24:46 - loss: 64.0776 - qv: 316.6033 - reward: -0.0271 - avg_action: 1.3632        "
     ]
    }
   ],
   "source": [
    "save_eps = 2\n",
    "eps_c = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        eps_c += 1\n",
    "        loss = []\n",
    "        q = []\n",
    "        rewards_tmp = []\n",
    "        actions = []\n",
    "        progbar = tf.keras.utils.Progbar(ep_len)\n",
    "        for i in range(ep_len):\n",
    "            c_loss, c_q, c_rewards, c_action = run()\n",
    "            loss.append(c_loss)\n",
    "            q.append(c_q)\n",
    "            rewards_tmp.append(c_rewards)\n",
    "            actions.append(c_action)\n",
    "\n",
    "            progbar.update(i+1, values = [(\"loss\", c_loss), (\"qv\", c_q), (\"reward\", c_rewards), (\"avg_action\", c_action)])\n",
    "\n",
    "        loss_mean.append(np.mean(loss))\n",
    "        q_mean.append(np.mean(q))\n",
    "        #rewards.append(np.mean(rewards_tmp))\n",
    "        rewards.extend(rewards_tmp)\n",
    "\n",
    "        #progbar.update(ep_len, values = [(\"loss\", np.mean(loss)), (\"qv\", np.mean(q)), (\"reward\", np.mean(rewards_tmp)), (\"avg_action\", np.mean(actions))])\n",
    "\n",
    "        target_model.set_weights(model.get_weights())\n",
    "\n",
    "\n",
    "        #if time.time() - start_time > 60*60*8.8:\n",
    "            #break\n",
    "        if(eps_c >=save_eps):\n",
    "          eps_c=0\n",
    "          save()\n",
    "\n",
    "    except    KeyboardInterrupt:\n",
    "        print(\"\")\n",
    "        print(\"exit\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b536a1d7-a655-4d08-9e9d-c8cbf420a885",
    "outputId": "2dbc92d5-4b30-4ae0-eb30-292f7c7b4316"
   },
   "outputs": [],
   "source": [
    "save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4a89278c-2823-4e36-8746-908718c80748"
   },
   "outputs": [],
   "source": [
    "obj_save(list(sarts_memory), path+\"sarts_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "include_colab_link": true,
   "provenance": []
  },
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [],
   "dockerImageVersionId": 30841,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
